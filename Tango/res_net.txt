==PROF== Connected to process 11009 (/home/burak/Documents/CudaBenchmarks/Tango-master/GPU/ResNet/res_net)
==PROF== Profiling "executeFirstLayerCUDA" - 1: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 2: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 3: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 4: 0%....50%....100% - 39 passes
==PROF== Profiling "executepoolingCuda" - 5: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 6: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 7: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 8: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 9: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 10: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 11: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 12: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 13: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 14: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 15: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 16: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 17: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 18: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 19: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA_split" - 20: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 21: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 22: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 23: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 24: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 25: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 26: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 27: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 28: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 29: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 30: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 31: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 32: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA_split" - 33: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 34: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 35: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 36: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 37: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 38: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 39: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 40: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 41: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 42: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda_split" - 43: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA_split" - 44: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA_split" - 45: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA_split" - 46: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA_split" - 47: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 48: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 49: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 50: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 51: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 52: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 53: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 54: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 55: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 56: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 57: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 58: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 59: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 60: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 61: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 62: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 63: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 64: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 65: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 66: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 67: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 68: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 69: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 70: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 71: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 72: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 73: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 74: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 75: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 76: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 77: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 78: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 79: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 80: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 81: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 82: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 83: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 84: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 85: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 86: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 87: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 88: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 89: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 90: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 91: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 92: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 93: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 94: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 95: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 96: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 97: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 98: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 99: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 100: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 101: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 102: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 103: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 104: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 105: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 106: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 107: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 108: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 109: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 110: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 111: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 112: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 113: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 114: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 115: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 116: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 117: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 118: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 119: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 120: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 121: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 122: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 123: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 124: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 125: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 126: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 127: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 128: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 129: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 130: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 131: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 132: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 133: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 134: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 135: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 136: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 137: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 138: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 139: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 140: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 141: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 142: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 143: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 144: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 145: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 146: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 147: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 148: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 149: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 150: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 151: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 152: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 153: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 154: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 155: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 156: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 157: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 158: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 159: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 160: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 161: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 162: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 163: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 164: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 165: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 166: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 167: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 168: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 169: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 170: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 171: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 172: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 173: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 174: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 175: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 176: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 177: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 178: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 179: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 180: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 181: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 182: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 183: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 184: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 185: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 186: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 187: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 188: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 189: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 190: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 191: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 192: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 193: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 194: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 195: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 196: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 197: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 198: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 199: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 200: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 201: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 202: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 203: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 204: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 205: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 206: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 207: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 208: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 209: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 210: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 211: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 212: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 213: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 214: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 215: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 216: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 217: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 218: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 219: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 220: 0%....50%....100% - 39 passes
==PROF== Profiling "execute3DconvolutionCuda" - 221: 0%....50%....100% - 39 passes
==PROF== Profiling "executeBnNormLayerCUDA" - 222: 0%....50%....100% - 39 passes
==PROF== Profiling "executeScaleLayerCUDA" - 223: 0%....50%....100% - 39 passes
==PROF== Profiling "executeEltWiseLayerCUDA" - 224: 0%....50%....100% - 39 passes
==PROF== Profiling "executeReLULayerCUDA" - 225: 0%....50%....100% - 39 passes
==PROF== Profiling "poolingAverageCUDA" - 226: 0%....50%....100% - 39 passes
==PROF== Profiling "executeFCLayerCUDA" - 227: 0%....50%....100%Predicted Class (index) = 1
 - 39 passes
==PROF== Disconnected from process 11009
[11009] res_net@127.0.0.1
  executeFirstLayerCUDA(float*, float*, float*, float*, int, int, int, int, int, int, int), 2023-Mar-21 16:31:02, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                     19.630.712
    Memory [%]                                                                           %                          44,77
    SOL DRAM                                                                             %                           1,47
    Duration                                                                       msecond                          14,24
    SOL L1/TEX Cache                                                                     %                          89,54
    SOL L2 Cache                                                                         %                          41,36
    SM Active Cycles                                                                 cycle                  17.949.722,29
    SM [%]                                                                               %                           6,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,11
    Executed Ipc Elapsed                                                        inst/cycle                           0,10
    Issue Slots Busy                                                                     %                           2,82
    Issued Ipc Active                                                           inst/cycle                           0,11
    SM Busy                                                                              %                           2,82
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,79
    Mem Busy                                                                             %                          44,77
    Max Bandwidth                                                                        %                          40,52
    L1/TEX Hit Rate                                                                      %                          51,62
    L2 Hit Rate                                                                          %                          99,11
    Mem Pipes Busy                                                                       %                           6,13
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           2,83
    Issued Warp Per Scheduler                                                                                        0,03
    No Eligible                                                                          %                          97,17
    Active Warps Per Scheduler                                                        warp                           6,76
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 35.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.76 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         239,00
    Warp Cycles Per Executed Instruction                                             cycle                         239,01
    Warp Cycles Per Issue Active                                                      warp                         239,00
    Avg. Active Threads Per Warp                                                                                    27,42
    Avg. Not Predicated Off Threads Per Warp                                                                        26,27
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 213.2 cycles being stalled waiting for the local/global            
          instruction queue to be not full. This represents about 89.2% of the total average of 239.0 cycles between    
          issuing two instructions. Typically this stall occurs only when executing local or global memory              
          instructions extremely frequently. If applicable, consider combining multiple lower-width memory operations   
          into fewer wider memory operations and try interleaving memory operations and math instructions.              

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                     506.532,57
    Executed Instructions                                                             inst                     28.365.824
    Avg. Issued Instructions Per Scheduler                                            inst                     506.551,95
    Issued Instructions                                                               inst                     28.366.909
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             52
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,39
    Achieved Active Warps Per SM                                                      warp                          27,00
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c160             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c170             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c180             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c1a0             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c1c0             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c1e0             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c200             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c220             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c240             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 802816 transactions, got 5576704 (6.95x) at PC 0x7f58a726c260             

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:02, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      1.139.759
    Memory [%]                                                                           %                          20,25
    SOL DRAM                                                                             %                           3,83
    Duration                                                                       usecond                         818,82
    SOL L1/TEX Cache                                                                     %                          21,80
    SOL L2 Cache                                                                         %                          20,25
    SM Active Cycles                                                                 cycle                   1.007.042,43
    SM [%]                                                                               %                          77,05
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 44% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,16
    Executed Ipc Elapsed                                                        inst/cycle                           0,14
    Issue Slots Busy                                                                     %                           4,09
    Issued Ipc Active                                                           inst/cycle                           0,16
    SM Busy                                                                              %                          87,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (87.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           7,34
    Mem Busy                                                                             %                          11,69
    Max Bandwidth                                                                        %                          20,25
    L1/TEX Hit Rate                                                                      %                          90,98
    L2 Hit Rate                                                                          %                          89,32
    Mem Pipes Busy                                                                       %                          20,37
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,10
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,90
    Active Warps Per Scheduler                                                        warp                           6,91
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 24.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.91 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         168,68
    Warp Cycles Per Executed Instruction                                             cycle                         168,78
    Warp Cycles Per Issue Active                                                      warp                         168,68
    Avg. Active Threads Per Warp                                                                                    27,98
    Avg. Not Predicated Off Threads Per Warp                                                                        26,51
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 98.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 58.1% of the total average of 168.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 63.7 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 37.8% of the total average of 168.7 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      41.194,86
    Executed Instructions                                                             inst                      2.306.912
    Avg. Issued Instructions Per Scheduler                                            inst                      41.219,86
    Issued Instructions                                                               inst                      2.308.312
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86,32
    Achieved Active Warps Per SM                                                      warp                          27,62
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7260850               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7260b70               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7260b80               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7260ea0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7260eb0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7261220               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7260540               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a7260840               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:03, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                        328.041
    Memory [%]                                                                           %                          76,08
    SOL DRAM                                                                             %                          13,02
    Duration                                                                       usecond                         238,85
    SOL L1/TEX Cache                                                                     %                          82,39
    SOL L2 Cache                                                                         %                          76,08
    SM Active Cycles                                                                 cycle                     310.590,57
    SM [%]                                                                               %                           5,45
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,09
    Executed Ipc Elapsed                                                        inst/cycle                           0,09
    Issue Slots Busy                                                                     %                           2,33
    Issued Ipc Active                                                           inst/cycle                           0,09
    SM Busy                                                                              %                           2,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          25,04
    Mem Busy                                                                             %                          47,15
    Max Bandwidth                                                                        %                          76,08
    L1/TEX Hit Rate                                                                      %                          79,59
    L2 Hit Rate                                                                          %                          94,82
    Mem Pipes Busy                                                                       %                           5,45
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           2,31
    Issued Warp Per Scheduler                                                                                        0,02
    No Eligible                                                                          %                          97,69
    Active Warps Per Scheduler                                                        warp                           6,49
    Eligible Warps Per Scheduler                                                      warp                           0,05
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 43.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.49 active warps per scheduler, but only an average of 0.05 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         281,62
    Warp Cycles Per Executed Instruction                                             cycle                         282,55
    Warp Cycles Per Issue Active                                                      warp                         281,62
    Avg. Active Threads Per Warp                                                                                    28,16
    Avg. Not Predicated Off Threads Per Warp                                                                        26,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 187.5 cycles being stalled waiting for the local/global            
          instruction queue to be not full. This represents about 66.6% of the total average of 281.6 cycles between    
          issuing two instructions. Typically this stall occurs only when executing local or global memory              
          instructions extremely frequently. If applicable, consider combining multiple lower-width memory operations   
          into fewer wider memory operations and try interleaving memory operations and math instructions.              

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       7.204,57
    Executed Instructions                                                             inst                        403.456
    Avg. Issued Instructions Per Scheduler                                            inst                       7.228,57
    Issued Instructions                                                               inst                        404.800
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          81,94
    Achieved Active Warps Per SM                                                      warp                          26,22
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e270               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e280               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e2c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e300               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e310               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e370               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e240               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725e250               

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:03, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,41
    Elapsed Cycles                                                                   cycle                        137.825
    Memory [%]                                                                           %                          43,41
    SOL DRAM                                                                             %                          19,88
    Duration                                                                       usecond                          97,31
    SOL L1/TEX Cache                                                                     %                          86,83
    SOL L2 Cache                                                                         %                           9,71
    SM Active Cycles                                                                 cycle                     121.400,29
    SM [%]                                                                               %                           6,38
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,21
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           5,34
    Issued Ipc Active                                                           inst/cycle                           0,21
    SM Busy                                                                              %                           5,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          38,29
    Mem Busy                                                                             %                          43,41
    Max Bandwidth                                                                        %                          19,88
    L1/TEX Hit Rate                                                                      %                          87,50
    L2 Hit Rate                                                                          %                          50,06
    Mem Pipes Busy                                                                       %                           6,38
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,47
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          94,53
    Active Warps Per Scheduler                                                        warp                           6,87
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 18.3 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.87 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         125,67
    Warp Cycles Per Executed Instruction                                             cycle                         125,98
    Warp Cycles Per Issue Active                                                      warp                         125,67
    Avg. Active Threads Per Warp                                                                                    28,18
    Avg. Not Predicated Off Threads Per Warp                                                                        24,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 77.2 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 61.5% of the total average of 125.7 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 39.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 31.2% of the total average of 125.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       6.468,57
    Executed Instructions                                                             inst                        362.240
    Avg. Issued Instructions Per Scheduler                                            inst                       6.484,57
    Issued Instructions                                                               inst                        363.136
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          82,79
    Achieved Active Warps Per SM                                                      warp                          26,49
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725b2e0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725b2f0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725b2c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a725b2d0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 72 transactions, got 168 (2.33x) at PC 0x7f58a725b340                     

  executepoolingCuda(float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:03, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        314.759
    Memory [%]                                                                           %                          44,84
    SOL DRAM                                                                             %                           8,64
    Duration                                                                       usecond                         227,94
    SOL L1/TEX Cache                                                                     %                          89,68
    SOL L2 Cache                                                                         %                          20,58
    SM Active Cycles                                                                 cycle                     279.584,79
    SM [%]                                                                               %                          15,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,72
    Executed Ipc Elapsed                                                        inst/cycle                           0,64
    Issue Slots Busy                                                                     %                          17,92
    Issued Ipc Active                                                           inst/cycle                           0,72
    SM Busy                                                                              %                          17,92
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          16,59
    Mem Busy                                                                             %                          44,84
    Max Bandwidth                                                                        %                          20,58
    L1/TEX Hit Rate                                                                      %                          94,30
    L2 Hit Rate                                                                          %                          82,96
    Mem Pipes Busy                                                                       %                           6,67
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          18,00
    Issued Warp Per Scheduler                                                                                        0,18
    No Eligible                                                                          %                          82,00
    Active Warps Per Scheduler                                                        warp                           3,43
    Eligible Warps Per Scheduler                                                      warp                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 5.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          3.43 active warps per scheduler, but only an average of 0.21 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          19,06
    Warp Cycles Per Executed Instruction                                             cycle                          19,07
    Warp Cycles Per Issue Active                                                      warp                          19,06
    Avg. Active Threads Per Warp                                                                                    14,02
    Avg. Not Predicated Off Threads Per Warp                                                                        12,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 13.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 71.8% of the total average of 19.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 14.0 threads being active per cycle. This is further reduced    
          to 12.7 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      50.078,93
    Executed Instructions                                                             inst                      2.804.420
    Avg. Issued Instructions Per Scheduler                                            inst                      50.102,93
    Issued Instructions                                                               inst                      2.805.764
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             52
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 56.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          43,18
    Achieved Active Warps Per SM                                                      warp                          13,82
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 86016 transactions, got 598528 (6.96x) at PC 0x7f58a7268a00               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 86016 transactions, got 598528 (6.96x) at PC 0x7f58a7268a80               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 84480 transactions, got 587840 (6.96x) at PC 0x7f58a7268970               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a72692f0               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:04, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,46
    SM Frequency                                                             cycle/nsecond                           1,42
    Elapsed Cycles                                                                   cycle                      5.978.392
    Memory [%]                                                                           %                          45,85
    SOL DRAM                                                                             %                           1,96
    Duration                                                                       msecond                           4,21
    SOL L1/TEX Cache                                                                     %                          91,70
    SOL L2 Cache                                                                         %                          32,25
    SM Active Cycles                                                                 cycle                   5.603.097,29
    SM [%]                                                                               %                          26,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,14
    Executed Ipc Elapsed                                                        inst/cycle                           1,07
    Issue Slots Busy                                                                     %                          28,52
    Issued Ipc Active                                                           inst/cycle                           1,14
    SM Busy                                                                              %                          28,52
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,66
    Mem Busy                                                                             %                          45,85
    Max Bandwidth                                                                        %                          29,72
    L1/TEX Hit Rate                                                                      %                          77,29
    L2 Hit Rate                                                                          %                          93,75
    Mem Pipes Busy                                                                       %                           8,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          28,81
    Issued Warp Per Scheduler                                                                                        0,29
    No Eligible                                                                          %                          71,19
    Active Warps Per Scheduler                                                        warp                           7,33
    Eligible Warps Per Scheduler                                                      warp                           0,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.33 active warps per scheduler, but only an average of 0.34 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          25,45
    Warp Cycles Per Executed Instruction                                             cycle                          25,45
    Warp Cycles Per Issue Active                                                      warp                          25,45
    Avg. Active Threads Per Warp                                                                                    28,00
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 14.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 57.5% of the total average of 25.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.597.714,29
    Executed Instructions                                                             inst                     89.472.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.597.733,59
    Issued Instructions                                                               inst                     89.473.081
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,04
    Achieved Active Warps Per SM                                                      warp                          27,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 51380224 (7.00x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 114688 transactions, got 802816 (7.00x) at PC 0x7f58a72679b0              

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:04, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,81
    Elapsed Cycles                                                                   cycle                        993.561
    Memory [%]                                                                           %                          23,52
    SOL DRAM                                                                             %                           8,53
    Duration                                                                       usecond                         548,48
    SOL L1/TEX Cache                                                                     %                          24,71
    SOL L2 Cache                                                                         %                          23,52
    SM Active Cycles                                                                 cycle                     714.723,71
    SM [%]                                                                               %                          62,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 37% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,20
    Executed Ipc Elapsed                                                        inst/cycle                           0,14
    Issue Slots Busy                                                                     %                           4,91
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.2%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          16,34
    Mem Busy                                                                             %                          14,00
    Max Bandwidth                                                                        %                          23,52
    L1/TEX Hit Rate                                                                      %                          87,41
    L2 Hit Rate                                                                          %                          95,14
    Mem Pipes Busy                                                                       %                          16,58
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,93
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,07
    Active Warps Per Scheduler                                                        warp                           6,73
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.3 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.73 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         136,72
    Warp Cycles Per Executed Instruction                                             cycle                         136,81
    Warp Cycles Per Issue Active                                                      warp                         136,72
    Avg. Active Threads Per Warp                                                                                    28,13
    Avg. Not Predicated Off Threads Per Warp                                                                        27,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.4% of the total average of 136.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 45.5 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 33.3% of the total average of 136.7 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      35.034,29
    Executed Instructions                                                             inst                      1.961.920
    Avg. Issued Instructions Per Scheduler                                            inst                      35.059,39
    Issued Instructions                                                               inst                      1.963.326
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          83,88
    Achieved Active Warps Per SM                                                      warp                          26,84
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:04, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,66
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        315.762
    Memory [%]                                                                           %                          77,98
    SOL DRAM                                                                             %                          14,14
    Duration                                                                       usecond                         228,10
    SOL L1/TEX Cache                                                                     %                          82,10
    SOL L2 Cache                                                                         %                          77,98
    SM Active Cycles                                                                 cycle                     300.600,64
    SM [%]                                                                               %                           8,55
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,23
    Executed Ipc Elapsed                                                        inst/cycle                           0,22
    Issue Slots Busy                                                                     %                           5,68
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          30,11
    Mem Busy                                                                             %                          53,21
    Max Bandwidth                                                                        %                          77,98
    L1/TEX Hit Rate                                                                      %                          77,51
    L2 Hit Rate                                                                          %                          95,90
    Mem Pipes Busy                                                                       %                           8,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,85
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,15
    Active Warps Per Scheduler                                                        warp                           6,20
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 17.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.20 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         105,98
    Warp Cycles Per Executed Instruction                                             cycle                         106,13
    Warp Cycles Per Issue Active                                                      warp                         105,98
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.4 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 40.0% of the total average of 106.0 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 51.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 48.6% of the total average of 106.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      17.042,29
    Executed Instructions                                                             inst                        954.368
    Avg. Issued Instructions Per Scheduler                                            inst                      17.066,29
    Issued Instructions                                                               inst                        955.712
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,59
    Achieved Active Warps Per SM                                                      warp                          24,19
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56954 transactions, got 397898 (6.99x) at PC 0x7f58a725e110               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56885 transactions, got 397277 (6.98x) at PC 0x7f58a725e0e0               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:05, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      1.533.718
    Memory [%]                                                                           %                          44,66
    SOL DRAM                                                                             %                           0,87
    Duration                                                                       msecond                           1,11
    SOL L1/TEX Cache                                                                     %                          89,33
    SOL L2 Cache                                                                         %                          29,51
    SM Active Cycles                                                                 cycle                   1.383.820,86
    SM [%]                                                                               %                          26,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,15
    Executed Ipc Elapsed                                                        inst/cycle                           1,04
    Issue Slots Busy                                                                     %                          28,87
    Issued Ipc Active                                                           inst/cycle                           1,15
    SM Busy                                                                              %                          28,87
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,67
    Mem Busy                                                                             %                          44,66
    Max Bandwidth                                                                        %                          29,33
    L1/TEX Hit Rate                                                                      %                          77,29
    L2 Hit Rate                                                                          %                          99,65
    Mem Pipes Busy                                                                       %                           8,67
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          28,58
    Issued Warp Per Scheduler                                                                                        0,29
    No Eligible                                                                          %                          71,42
    Active Warps Per Scheduler                                                        warp                           6,99
    Eligible Warps Per Scheduler                                                      warp                           0,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.99 active warps per scheduler, but only an average of 0.34 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          24,45
    Warp Cycles Per Executed Instruction                                             cycle                          24,45
    Warp Cycles Per Issue Active                                                      warp                          24,45
    Avg. Active Threads Per Warp                                                                                    28,00
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 14.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.1% of the total average of 24.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                     399.428,57
    Executed Instructions                                                             inst                     22.368.000
    Avg. Issued Instructions Per Scheduler                                            inst                     399.448,54
    Issued Instructions                                                               inst                     22.369.118
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,08
    Achieved Active Warps Per SM                                                      warp                          27,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 1835008 transactions, got 12845056 (7.00x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a72679b0               

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:05, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,87
    Elapsed Cycles                                                                   cycle                        258.572
    Memory [%]                                                                           %                          22,42
    SOL DRAM                                                                             %                           8,01
    Duration                                                                       usecond                         138,18
    SOL L1/TEX Cache                                                                     %                          23,69
    SOL L2 Cache                                                                         %                          22,42
    SM Active Cycles                                                                 cycle                     180.507,86
    SM [%]                                                                               %                          59,89
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 36% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,20
    Executed Ipc Elapsed                                                        inst/cycle                           0,14
    Issue Slots Busy                                                                     %                           4,91
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          85,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          15,28
    Mem Busy                                                                             %                          12,88
    Max Bandwidth                                                                        %                          22,42
    L1/TEX Hit Rate                                                                      %                          87,94
    L2 Hit Rate                                                                          %                          95,21
    Mem Pipes Busy                                                                       %                          15,99
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,94
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,06
    Active Warps Per Scheduler                                                        warp                           6,71
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.3 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.71 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         135,95
    Warp Cycles Per Executed Instruction                                             cycle                         136,42
    Warp Cycles Per Issue Active                                                      warp                         135,95
    Avg. Active Threads Per Warp                                                                                    28,13
    Avg. Not Predicated Off Threads Per Warp                                                                        27,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.4% of the total average of 135.9  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 44.0 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 32.4% of the total average of 135.9 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       8.836,57
    Executed Instructions                                                             inst                        494.848
    Avg. Issued Instructions Per Scheduler                                            inst                       8.867,52
    Issued Instructions                                                               inst                        496.581
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          83,54
    Achieved Active Warps Per SM                                                      warp                          26,73
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:05, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,41
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         85.616
    Memory [%]                                                                           %                          72,44
    SOL DRAM                                                                             %                          10,30
    Duration                                                                       usecond                          62,24
    SOL L1/TEX Cache                                                                     %                          76,16
    SOL L2 Cache                                                                         %                          72,44
    SM Active Cycles                                                                 cycle                      75.624,36
    SM [%]                                                                               %                           7,88
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,23
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           5,67
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          18,57
    Mem Busy                                                                             %                          47,87
    Max Bandwidth                                                                        %                          72,44
    L1/TEX Hit Rate                                                                      %                          77,65
    L2 Hit Rate                                                                          %                          95,01
    Mem Pipes Busy                                                                       %                           7,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,96
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,04
    Active Warps Per Scheduler                                                        warp                           6,31
    Eligible Warps Per Scheduler                                                      warp                           0,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 16.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.31 active warps per scheduler, but only an average of 0.13 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         105,90
    Warp Cycles Per Executed Instruction                                             cycle                         106,49
    Warp Cycles Per Issue Active                                                      warp                         105,90
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 41.9 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 39.5% of the total average of 105.9 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 51.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 48.8% of the total average of 105.9  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       4.260,57
    Executed Instructions                                                             inst                        238.592
    Avg. Issued Instructions Per Scheduler                                            inst                       4.284,57
    Issued Instructions                                                               inst                        239.936
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 23.9%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          76,08
    Achieved Active Warps Per SM                                                      warp                          24,35
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14240 transactions, got 99488 (6.99x) at PC 0x7f58a725e0e0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14237 transactions, got 99461 (6.99x) at PC 0x7f58a725e110                

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:05, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,43
    Elapsed Cycles                                                                   cycle                         51.190
    Memory [%]                                                                           %                          59,63
    SOL DRAM                                                                             %                          14,76
    Duration                                                                       usecond                          35,74
    SOL L1/TEX Cache                                                                     %                          62,38
    SOL L2 Cache                                                                         %                          59,63
    SM Active Cycles                                                                 cycle                      44.011,57
    SM [%]                                                                               %                           6,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,31
    Executed Ipc Elapsed                                                        inst/cycle                           0,27
    Issue Slots Busy                                                                     %                           7,75
    Issued Ipc Active                                                           inst/cycle                           0,31
    SM Busy                                                                              %                           7,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          28,14
    Mem Busy                                                                             %                          40,04
    Max Bandwidth                                                                        %                          59,63
    L1/TEX Hit Rate                                                                      %                          82,61
    L2 Hit Rate                                                                          %                          86,73
    Mem Pipes Busy                                                                       %                           5,16
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,26
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,74
    Active Warps Per Scheduler                                                        warp                           6,59
    Eligible Warps Per Scheduler                                                      warp                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.59 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          79,89
    Warp Cycles Per Executed Instruction                                             cycle                          80,26
    Warp Cycles Per Issue Active                                                      warp                          79,89
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 59.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 75.0% of the total average of 79.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.396,57
    Executed Instructions                                                             inst                        190.208
    Avg. Issued Instructions Per Scheduler                                            inst                       3.412,57
    Issued Instructions                                                               inst                        191.104
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 21.0%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          78,96
    Achieved Active Warps Per SM                                                      warp                          25,27
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab90               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6944 transactions, got 48608 (7.00x) at PC 0x7f58a725ab40                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6944 transactions, got 48608 (7.00x) at PC 0x7f58a725abc0                 

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:06, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,36
    Elapsed Cycles                                                                   cycle                     13.765.711
    Memory [%]                                                                           %                          45,46
    SOL DRAM                                                                             %                           0,39
    Duration                                                                       msecond                          10,10
    SOL L1/TEX Cache                                                                     %                          90,91
    SOL L2 Cache                                                                         %                          32,23
    SM Active Cycles                                                                 cycle                  12.586.244,93
    SM [%]                                                                               %                          10,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,48
    Executed Ipc Elapsed                                                        inst/cycle                           0,44
    Issue Slots Busy                                                                     %                          11,97
    Issued Ipc Active                                                           inst/cycle                           0,48
    SM Busy                                                                              %                          11,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Mbyte/second                         750,59
    Mem Busy                                                                             %                          45,46
    Max Bandwidth                                                                        %                          31,99
    L1/TEX Hit Rate                                                                      %                          72,57
    L2 Hit Rate                                                                          %                          99,17
    Mem Pipes Busy                                                                       %                           8,60
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          11,75
    Issued Warp Per Scheduler                                                                                        0,12
    No Eligible                                                                          %                          88,25
    Active Warps Per Scheduler                                                        warp                           6,69
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 8.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.69 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          56,96
    Warp Cycles Per Executed Instruction                                             cycle                          56,96
    Warp Cycles Per Issue Active                                                      warp                          56,96
    Avg. Active Threads Per Warp                                                                                    27,51
    Avg. Not Predicated Off Threads Per Warp                                                                        25,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 31.1 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 54.7% of the total average of 57.0 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 21.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 38.3% of the total average of 57.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.506.948,57
    Executed Instructions                                                             inst                     84.389.120
    Avg. Issued Instructions Per Scheduler                                            inst                   1.506.967,46
    Issued Instructions                                                               inst                     84.390.178
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,40
    Achieved Active Warps Per SM                                                      warp                          27,33
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 5505024 transactions, got 38076416 (6.92x) at PC 0x7f58a7266fb0           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 5505024 transactions, got 38076416 (6.92x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 5308416 transactions, got 36716544 (6.92x) at PC 0x7f58a7266fa0           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a72679b0               

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:07, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        323.920
    Memory [%]                                                                           %                          17,96
    SOL DRAM                                                                             %                           2,57
    Duration                                                                       usecond                         233,89
    SOL L1/TEX Cache                                                                     %                          18,92
    SOL L2 Cache                                                                         %                          17,96
    SM Active Cycles                                                                 cycle                     294.714,14
    SM [%]                                                                               %                          78,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 43% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,19
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,93
    Mem Busy                                                                             %                          10,44
    Max Bandwidth                                                                        %                          17,96
    L1/TEX Hit Rate                                                                      %                          88,22
    L2 Hit Rate                                                                          %                          95,14
    Mem Pipes Busy                                                                       %                          20,48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,89
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,11
    Active Warps Per Scheduler                                                        warp                           6,79
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.79 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         138,80
    Warp Cycles Per Executed Instruction                                             cycle                         139,04
    Warp Cycles Per Issue Active                                                      warp                         138,80
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.5% of the total average of 138.8  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 48.9 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.2% of the total average of 138.8 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      14.356,57
    Executed Instructions                                                             inst                        803.968
    Avg. Issued Instructions Per Scheduler                                            inst                      14.381,64
    Issued Instructions                                                               inst                        805.372
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,67
    Achieved Active Warps Per SM                                                      warp                          27,10
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:07, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         809,99
    SM Frequency                                                             cycle/usecond                         738,78
    Elapsed Cycles                                                                   cycle                         80.780
    Memory [%]                                                                           %                          76,51
    SOL DRAM                                                                             %                          10,20
    Duration                                                                       usecond                         108,96
    SOL L1/TEX Cache                                                                     %                          80,06
    SOL L2 Cache                                                                         %                          76,51
    SM Active Cycles                                                                 cycle                      74.894,64
    SM [%]                                                                               %                           8,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,23
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           5,72
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          10,57
    Mem Busy                                                                             %                          51,14
    Max Bandwidth                                                                        %                          76,51
    L1/TEX Hit Rate                                                                      %                          77,67
    L2 Hit Rate                                                                          %                         102,22
    Mem Pipes Busy                                                                       %                           8,36
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           2,99
    Issued Warp Per Scheduler                                                                                        0,03
    No Eligible                                                                          %                          97,01
    Active Warps Per Scheduler                                                        warp                           3,20
    Eligible Warps Per Scheduler                                                      warp                           0,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 33.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          3.20 active warps per scheduler, but only an average of 0.06 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         107,12
    Warp Cycles Per Executed Instruction                                             cycle                         107,72
    Warp Cycles Per Issue Active                                                      warp                         107,12
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.7 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 39.9% of the total average of 107.1 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 50.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 47.3% of the total average of 107.1  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       4.260,57
    Executed Instructions                                                             inst                        238.592
    Avg. Issued Instructions Per Scheduler                                            inst                       4.284,57
    Issued Instructions                                                               inst                        239.936
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 24.4%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,63
    Achieved Active Warps Per SM                                                      warp                          24,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14231 transactions, got 99407 (6.99x) at PC 0x7f58a725e110                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14201 transactions, got 99137 (6.98x) at PC 0x7f58a725e0e0                

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:07, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         29.292
    Memory [%]                                                                           %                          36,81
    SOL DRAM                                                                             %                          19,79
    Duration                                                                       usecond                          21,38
    SOL L1/TEX Cache                                                                     %                          73,62
    SOL L2 Cache                                                                         %                          11,51
    SM Active Cycles                                                                 cycle                      24.390,86
    SM [%]                                                                               %                          11,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,56
    Executed Ipc Elapsed                                                        inst/cycle                           0,46
    Issue Slots Busy                                                                     %                          13,99
    Issued Ipc Active                                                           inst/cycle                           0,56
    SM Busy                                                                              %                          13,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,91
    Mem Busy                                                                             %                          36,81
    Max Bandwidth                                                                        %                          19,79
    L1/TEX Hit Rate                                                                      %                          88,28
    L2 Hit Rate                                                                          %                          49,49
    Mem Pipes Busy                                                                       %                           9,01
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          14,02
    Issued Warp Per Scheduler                                                                                        0,14
    No Eligible                                                                          %                          85,98
    Active Warps Per Scheduler                                                        warp                           6,20
    Eligible Warps Per Scheduler                                                      warp                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 7.1 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.20 active warps per scheduler, but only an average of 0.25 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          44,26
    Warp Cycles Per Executed Instruction                                             cycle                          44,47
    Warp Cycles Per Issue Active                                                      warp                          44,26
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 32.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.0% of the total average of 44.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.396,57
    Executed Instructions                                                             inst                        190.208
    Avg. Issued Instructions Per Scheduler                                            inst                       3.412,57
    Issued Instructions                                                               inst                        191.104
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 22.0%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,96
    Achieved Active Warps Per SM                                                      warp                          24,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:08, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                      5.785.421
    Memory [%]                                                                           %                          47,27
    SOL DRAM                                                                             %                           0,69
    Duration                                                                       msecond                           4,38
    SOL L1/TEX Cache                                                                     %                          94,53
    SOL L2 Cache                                                                         %                          32,39
    SM Active Cycles                                                                 cycle                   5.652.852,14
    SM [%]                                                                               %                          27,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,13
    Executed Ipc Elapsed                                                        inst/cycle                           1,11
    Issue Slots Busy                                                                     %                          28,26
    Issued Ipc Active                                                           inst/cycle                           1,13
    SM Busy                                                                              %                          28,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,33
    Mem Busy                                                                             %                          47,27
    Max Bandwidth                                                                        %                          30,77
    L1/TEX Hit Rate                                                                      %                          77,35
    L2 Hit Rate                                                                          %                          96,44
    Mem Pipes Busy                                                                       %                           9,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          28,80
    Issued Warp Per Scheduler                                                                                        0,29
    No Eligible                                                                          %                          71,20
    Active Warps Per Scheduler                                                        warp                           7,28
    Eligible Warps Per Scheduler                                                      warp                           0,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.28 active warps per scheduler, but only an average of 0.34 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          25,27
    Warp Cycles Per Executed Instruction                                             cycle                          25,27
    Warp Cycles Per Issue Active                                                      warp                          25,27
    Avg. Active Threads Per Warp                                                                                    28,00
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 15.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.9% of the total average of 25.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.597.714,29
    Executed Instructions                                                             inst                     89.472.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.597.734,18
    Issued Instructions                                                               inst                     89.473.114
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,04
    Achieved Active Warps Per SM                                                      warp                          27,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 51380224 (7.00x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 114688 transactions, got 802816 (7.00x) at PC 0x7f58a72679b0              

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:08, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      1.224.002
    Memory [%]                                                                           %                          18,99
    SOL DRAM                                                                             %                           3,54
    Duration                                                                       usecond                         881,34
    SOL L1/TEX Cache                                                                     %                          20,07
    SOL L2 Cache                                                                         %                          18,99
    SM Active Cycles                                                                 cycle                   1.173.633,79
    SM [%]                                                                               %                          83,22
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 46% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,19
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,77
    Mem Busy                                                                             %                          11,69
    Max Bandwidth                                                                        %                          18,99
    L1/TEX Hit Rate                                                                      %                          88,70
    L2 Hit Rate                                                                          %                          88,87
    Mem Pipes Busy                                                                       %                          21,66
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,89
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,11
    Active Warps Per Scheduler                                                        warp                           6,80
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.80 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         139,20
    Warp Cycles Per Executed Instruction                                             cycle                         139,26
    Warp Cycles Per Issue Active                                                      warp                         139,20
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,92
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.3% of the total average of 139.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 49.5 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.5% of the total average of 139.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      57.206,29
    Executed Instructions                                                             inst                      3.203.552
    Avg. Issued Instructions Per Scheduler                                            inst                      57.231,38
    Issued Instructions                                                               inst                      3.204.957
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,80
    Achieved Active Warps Per SM                                                      warp                          27,14
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:08, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        313.167
    Memory [%]                                                                           %                          78,72
    SOL DRAM                                                                             %                          13,83
    Duration                                                                       usecond                         224,35
    SOL L1/TEX Cache                                                                     %                          82,86
    SOL L2 Cache                                                                         %                          78,72
    SM Active Cycles                                                                 cycle                     305.944,57
    SM [%]                                                                               %                           8,62
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,22
    Executed Ipc Elapsed                                                        inst/cycle                           0,22
    Issue Slots Busy                                                                     %                           5,58
    Issued Ipc Active                                                           inst/cycle                           0,22
    SM Busy                                                                              %                           5,58
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          27,16
    Mem Busy                                                                             %                          52,59
    Max Bandwidth                                                                        %                          78,72
    L1/TEX Hit Rate                                                                      %                          77,65
    L2 Hit Rate                                                                          %                          95,15
    Mem Pipes Busy                                                                       %                           8,62
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,83
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,17
    Active Warps Per Scheduler                                                        warp                           6,27
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 17.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.27 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         107,44
    Warp Cycles Per Executed Instruction                                             cycle                         107,59
    Warp Cycles Per Issue Active                                                      warp                         107,44
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.9 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 39.9% of the total average of 107.4 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 52.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 48.7% of the total average of 107.4  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      17.042,29
    Executed Instructions                                                             inst                        954.368
    Avg. Issued Instructions Per Scheduler                                            inst                      17.066,29
    Issued Instructions                                                               inst                        955.712
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,62
    Achieved Active Warps Per SM                                                      warp                          24,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56906 transactions, got 397466 (6.98x) at PC 0x7f58a725e110               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56822 transactions, got 396710 (6.98x) at PC 0x7f58a725e0e0               

  executeEltWiseLayerCUDA_split(float*, float*, float*, int, int), 2023-Mar-21 16:31:09, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,47
    SM Frequency                                                             cycle/nsecond                           1,48
    Elapsed Cycles                                                                   cycle                        368.964
    Memory [%]                                                                           %                          70,38
    SOL DRAM                                                                             %                          22,58
    Duration                                                                       usecond                         248,38
    SOL L1/TEX Cache                                                                     %                          73,87
    SOL L2 Cache                                                                         %                          70,38
    SM Active Cycles                                                                 cycle                     334.021,14
    SM [%]                                                                               %                           5,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,20
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           5,07
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                           5,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          42,53
    Mem Busy                                                                             %                          48,08
    Max Bandwidth                                                                        %                          70,38
    L1/TEX Hit Rate                                                                      %                          80,43
    L2 Hit Rate                                                                          %                          96,10
    Mem Pipes Busy                                                                       %                           5,65
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,25
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          94,75
    Active Warps Per Scheduler                                                        warp                           6,20
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 19.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.20 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         118,28
    Warp Cycles Per Executed Instruction                                             cycle                         118,39
    Warp Cycles Per Issue Active                                                      warp                         118,28
    Avg. Active Threads Per Warp                                                                                    28,28
    Avg. Not Predicated Off Threads Per Warp                                                                        22,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 35.9 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 30.4% of the total average of 118.3 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 73.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 62.5% of the total average of 118.3  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.6 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      16.914,29
    Executed Instructions                                                             inst                        947.200
    Avg. Issued Instructions Per Scheduler                                            inst                      16.930,29
    Issued Instructions                                                               inst                        948.096
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             26
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          76,48
    Achieved Active Warps Per SM                                                      warp                          24,47
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c7e0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c7f0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c830               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c890               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c8d0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56894 transactions, got 397358 (6.98x) at PC 0x7f58a725c880               

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:09, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,47
    SM Frequency                                                             cycle/nsecond                           1,66
    Elapsed Cycles                                                                   cycle                        120.578
    Memory [%]                                                                           %                          35,83
    SOL DRAM                                                                             %                          26,75
    Duration                                                                       usecond                          72,38
    SOL L1/TEX Cache                                                                     %                          71,65
    SOL L2 Cache                                                                         %                          23,82
    SM Active Cycles                                                                 cycle                      93.308,57
    SM [%]                                                                               %                          11,31
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,58
    Executed Ipc Elapsed                                                        inst/cycle                           0,45
    Issue Slots Busy                                                                     %                          14,58
    Issued Ipc Active                                                           inst/cycle                           0,58
    SM Busy                                                                              %                          14,58
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          50,37
    Mem Busy                                                                             %                          35,83
    Max Bandwidth                                                                        %                          26,75
    L1/TEX Hit Rate                                                                      %                          88,22
    L2 Hit Rate                                                                          %                          49,90
    Mem Pipes Busy                                                                       %                           8,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          14,96
    Issued Warp Per Scheduler                                                                                        0,15
    No Eligible                                                                          %                          85,04
    Active Warps Per Scheduler                                                        warp                           6,34
    Eligible Warps Per Scheduler                                                      warp                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 6.7 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.34 active warps per scheduler, but only an average of 0.25 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          42,39
    Warp Cycles Per Executed Instruction                                             cycle                          42,44
    Warp Cycles Per Issue Active                                                      warp                          42,39
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 31.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.3% of the total average of 42.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      13.586,29
    Executed Instructions                                                             inst                        760.832
    Avg. Issued Instructions Per Scheduler                                            inst                      13.602,29
    Issued Instructions                                                               inst                        761.728
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          76,45
    Achieved Active Warps Per SM                                                      warp                          24,47
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:09, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      6.042.113
    Memory [%]                                                                           %                          44,87
    SOL DRAM                                                                             %                           7,26
    Duration                                                                       msecond                           4,34
    SOL L1/TEX Cache                                                                     %                          89,73
    SOL L2 Cache                                                                         %                          30,86
    SM Active Cycles                                                                 cycle                   5.510.477,50
    SM [%]                                                                               %                          26,20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,15
    Executed Ipc Elapsed                                                        inst/cycle                           1,05
    Issue Slots Busy                                                                     %                          28,66
    Issued Ipc Active                                                           inst/cycle                           1,15
    SM Busy                                                                              %                          28,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          13,95
    Mem Busy                                                                             %                          44,87
    Max Bandwidth                                                                        %                          30,14
    L1/TEX Hit Rate                                                                      %                          76,32
    L2 Hit Rate                                                                          %                          93,33
    Mem Pipes Busy                                                                       %                           8,73
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          28,98
    Issued Warp Per Scheduler                                                                                        0,29
    No Eligible                                                                          %                          71,02
    Active Warps Per Scheduler                                                        warp                           6,97
    Eligible Warps Per Scheduler                                                      warp                           0,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.97 active warps per scheduler, but only an average of 0.34 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          24,06
    Warp Cycles Per Executed Instruction                                             cycle                          24,06
    Warp Cycles Per Issue Active                                                      warp                          24,06
    Avg. Active Threads Per Warp                                                                                    28,00
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 15.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.4% of the total average of 24.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.579.076,57
    Executed Instructions                                                             inst                     88.428.288
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.095,70
    Issued Instructions                                                               inst                     88.429.359
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,14
    Achieved Active Warps Per SM                                                      warp                          27,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 51380224 (7.00x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a72679b0               

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:10, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        324.288
    Memory [%]                                                                           %                          17,91
    SOL DRAM                                                                             %                           2,58
    Duration                                                                       usecond                         233,89
    SOL L1/TEX Cache                                                                     %                          18,97
    SOL L2 Cache                                                                         %                          17,91
    SM Active Cycles                                                                 cycle                     294.542,14
    SM [%]                                                                               %                          78,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 43% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,19
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,39
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.4%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,93
    Mem Busy                                                                             %                          10,69
    Max Bandwidth                                                                        %                          17,91
    L1/TEX Hit Rate                                                                      %                          88,45
    L2 Hit Rate                                                                          %                          95,53
    Mem Pipes Busy                                                                       %                          20,45
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,88
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,12
    Active Warps Per Scheduler                                                        warp                           6,77
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.77 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         138,71
    Warp Cycles Per Executed Instruction                                             cycle                         138,95
    Warp Cycles Per Issue Active                                                      warp                         138,71
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.4% of the total average of 138.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 48.9 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.3% of the total average of 138.7 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      14.356,57
    Executed Instructions                                                             inst                        803.968
    Avg. Issued Instructions Per Scheduler                                            inst                      14.381,68
    Issued Instructions                                                               inst                        805.374
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,67
    Achieved Active Warps Per SM                                                      warp                          27,10
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:10, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,47
    Elapsed Cycles                                                                   cycle                         87.870
    Memory [%]                                                                           %                          70,19
    SOL DRAM                                                                             %                          10,27
    Duration                                                                       usecond                          59,62
    SOL L1/TEX Cache                                                                     %                          74,10
    SOL L2 Cache                                                                         %                          70,19
    SM Active Cycles                                                                 cycle                      75.807,71
    SM [%]                                                                               %                           7,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,22
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           5,65
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          19,45
    Mem Busy                                                                             %                          45,66
    Max Bandwidth                                                                        %                          70,19
    L1/TEX Hit Rate                                                                      %                          77,65
    L2 Hit Rate                                                                          %                          96,11
    Mem Pipes Busy                                                                       %                           7,68
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,86
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,14
    Active Warps Per Scheduler                                                        warp                           6,31
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 17.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.31 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         107,67
    Warp Cycles Per Executed Instruction                                             cycle                         108,28
    Warp Cycles Per Issue Active                                                      warp                         107,67
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.9 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 39.9% of the total average of 107.7 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 51.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 48.1% of the total average of 107.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       4.260,57
    Executed Instructions                                                             inst                        238.592
    Avg. Issued Instructions Per Scheduler                                            inst                       4.284,57
    Issued Instructions                                                               inst                        239.936
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 23.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          76,27
    Achieved Active Warps Per SM                                                      warp                          24,41
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14228 transactions, got 99380 (6.98x) at PC 0x7f58a725e110                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14222 transactions, got 99326 (6.98x) at PC 0x7f58a725e0e0                

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:10, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,47
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                         29.109
    Memory [%]                                                                           %                          37,12
    SOL DRAM                                                                             %                          19,76
    Duration                                                                       usecond                          21,60
    SOL L1/TEX Cache                                                                     %                          74,23
    SOL L2 Cache                                                                         %                          21,11
    SM Active Cycles                                                                 cycle                      24.533,14
    SM [%]                                                                               %                          11,76
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,55
    Executed Ipc Elapsed                                                        inst/cycle                           0,47
    Issue Slots Busy                                                                     %                          13,91
    Issued Ipc Active                                                           inst/cycle                           0,56
    SM Busy                                                                              %                          13,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,17
    Mem Busy                                                                             %                          37,12
    Max Bandwidth                                                                        %                          19,76
    L1/TEX Hit Rate                                                                      %                          88,28
    L2 Hit Rate                                                                          %                          27,24
    Mem Pipes Busy                                                                       %                           9,07
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          14,28
    Issued Warp Per Scheduler                                                                                        0,14
    No Eligible                                                                          %                          85,72
    Active Warps Per Scheduler                                                        warp                           6,49
    Eligible Warps Per Scheduler                                                      warp                           0,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 7.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.49 active warps per scheduler, but only an average of 0.26 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          45,40
    Warp Cycles Per Executed Instruction                                             cycle                          45,62
    Warp Cycles Per Issue Active                                                      warp                          45,40
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 33.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 72.6% of the total average of 45.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.396,57
    Executed Instructions                                                             inst                        190.208
    Avg. Issued Instructions Per Scheduler                                            inst                       3.412,57
    Issued Instructions                                                               inst                        191.104
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 22.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,83
    Achieved Active Warps Per SM                                                      warp                          24,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:11, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,42
    Elapsed Cycles                                                                   cycle                     14.030.025
    Memory [%]                                                                           %                          44,59
    SOL DRAM                                                                             %                           1,54
    Duration                                                                       msecond                           9,88
    SOL L1/TEX Cache                                                                     %                          89,19
    SOL L2 Cache                                                                         %                          32,63
    SM Active Cycles                                                                 cycle                  12.400.440,93
    SM [%]                                                                               %                          10,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,49
    Executed Ipc Elapsed                                                        inst/cycle                           0,43
    Issue Slots Busy                                                                     %                          12,15
    Issued Ipc Active                                                           inst/cycle                           0,49
    SM Busy                                                                              %                          12,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,99
    Mem Busy                                                                             %                          44,59
    Max Bandwidth                                                                        %                          30,81
    L1/TEX Hit Rate                                                                      %                          72,68
    L2 Hit Rate                                                                          %                          96,34
    Mem Pipes Busy                                                                       %                           8,44
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          11,77
    Issued Warp Per Scheduler                                                                                        0,12
    No Eligible                                                                          %                          88,23
    Active Warps Per Scheduler                                                        warp                           6,85
    Eligible Warps Per Scheduler                                                      warp                           0,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 8.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.85 active warps per scheduler, but only an average of 0.17 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          58,16
    Warp Cycles Per Executed Instruction                                             cycle                          58,16
    Warp Cycles Per Issue Active                                                      warp                          58,16
    Avg. Active Threads Per Warp                                                                                    27,51
    Avg. Not Predicated Off Threads Per Warp                                                                        25,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 31.0 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 53.3% of the total average of 58.2 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 20.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 35.6% of the total average of 58.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.506.948,57
    Executed Instructions                                                             inst                     84.389.120
    Avg. Issued Instructions Per Scheduler                                            inst                   1.506.967,62
    Issued Instructions                                                               inst                     84.390.187
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,37
    Achieved Active Warps Per SM                                                      warp                          27,32
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 5505024 transactions, got 38076416 (6.92x) at PC 0x7f58a7266fb0           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 5505024 transactions, got 38076416 (6.92x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 5308416 transactions, got 36716544 (6.92x) at PC 0x7f58a7266fa0           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a72679b0               

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:11, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        324.626
    Memory [%]                                                                           %                          23,65
    SOL DRAM                                                                             %                           2,58
    Duration                                                                       usecond                         233,92
    SOL L1/TEX Cache                                                                     %                          18,94
    SOL L2 Cache                                                                         %                          23,65
    SM Active Cycles                                                                 cycle                     294.674,36
    SM [%]                                                                               %                          78,51
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 43% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,19
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,35
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.4%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,93
    Mem Busy                                                                             %                          10,66
    Max Bandwidth                                                                        %                          23,65
    L1/TEX Hit Rate                                                                      %                          88,12
    L2 Hit Rate                                                                          %                          92,96
    Mem Pipes Busy                                                                       %                          20,44
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,89
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,11
    Active Warps Per Scheduler                                                        warp                           6,81
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.81 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         139,17
    Warp Cycles Per Executed Instruction                                             cycle                         139,42
    Warp Cycles Per Issue Active                                                      warp                         139,17
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.3% of the total average of 139.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 48.9 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.1% of the total average of 139.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      14.356,57
    Executed Instructions                                                             inst                        803.968
    Avg. Issued Instructions Per Scheduler                                            inst                      14.381,66
    Issued Instructions                                                               inst                        805.373
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,66
    Achieved Active Warps Per SM                                                      warp                          27,09
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:12, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,47
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                         80.239
    Memory [%]                                                                           %                          76,31
    SOL DRAM                                                                             %                          10,27
    Duration                                                                       usecond                          59,81
    SOL L1/TEX Cache                                                                     %                          80,60
    SOL L2 Cache                                                                         %                          76,31
    SM Active Cycles                                                                 cycle                      75.206,64
    SM [%]                                                                               %                           8,41
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,23
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           5,70
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,70
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          19,27
    Mem Busy                                                                             %                          49,47
    Max Bandwidth                                                                        %                          76,31
    L1/TEX Hit Rate                                                                      %                          77,21
    L2 Hit Rate                                                                          %                          99,40
    Mem Pipes Busy                                                                       %                           8,41
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,79
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,21
    Active Warps Per Scheduler                                                        warp                           6,08
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 17.3 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.08 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         104,90
    Warp Cycles Per Executed Instruction                                             cycle                         105,49
    Warp Cycles Per Issue Active                                                      warp                         104,90
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 41.1 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 39.2% of the total average of 104.9 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 50.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 48.5% of the total average of 104.9  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       4.260,57
    Executed Instructions                                                             inst                        238.592
    Avg. Issued Instructions Per Scheduler                                            inst                       4.284,57
    Issued Instructions                                                               inst                        239.936
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 24.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,49
    Achieved Active Warps Per SM                                                      warp                          24,16
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14228 transactions, got 99380 (6.98x) at PC 0x7f58a725e110                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14213 transactions, got 99245 (6.98x) at PC 0x7f58a725e0e0                

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:12, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,30
    Elapsed Cycles                                                                   cycle                         28.489
    Memory [%]                                                                           %                          37,85
    SOL DRAM                                                                             %                          20,51
    Duration                                                                       usecond                          21,89
    SOL L1/TEX Cache                                                                     %                          75,71
    SOL L2 Cache                                                                         %                          11,69
    SM Active Cycles                                                                 cycle                      24.309,79
    SM [%]                                                                               %                          12,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,56
    Executed Ipc Elapsed                                                        inst/cycle                           0,48
    Issue Slots Busy                                                                     %                          14,04
    Issued Ipc Active                                                           inst/cycle                           0,56
    SM Busy                                                                              %                          14,04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          36,69
    Mem Busy                                                                             %                          37,85
    Max Bandwidth                                                                        %                          20,51
    L1/TEX Hit Rate                                                                      %                          88,30
    L2 Hit Rate                                                                          %                          50,64
    Mem Pipes Busy                                                                       %                           9,27
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          14,19
    Issued Warp Per Scheduler                                                                                        0,14
    No Eligible                                                                          %                          85,81
    Active Warps Per Scheduler                                                        warp                           6,41
    Eligible Warps Per Scheduler                                                      warp                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 7.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.41 active warps per scheduler, but only an average of 0.25 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          45,19
    Warp Cycles Per Executed Instruction                                             cycle                          45,41
    Warp Cycles Per Issue Active                                                      warp                          45,19
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 32.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 72.3% of the total average of 45.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.396,57
    Executed Instructions                                                             inst                        190.208
    Avg. Issued Instructions Per Scheduler                                            inst                       3.412,57
    Issued Instructions                                                               inst                        191.104
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 22.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,83
    Achieved Active Warps Per SM                                                      warp                          24,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:13, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,35
    Elapsed Cycles                                                                   cycle                      5.689.903
    Memory [%]                                                                           %                          48,07
    SOL DRAM                                                                             %                           1,31
    Duration                                                                       msecond                           4,19
    SOL L1/TEX Cache                                                                     %                          96,15
    SOL L2 Cache                                                                         %                          32,55
    SM Active Cycles                                                                 cycle                   5.562.276,07
    SM [%]                                                                               %                          28,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,15
    Executed Ipc Elapsed                                                        inst/cycle                           1,13
    Issue Slots Busy                                                                     %                          28,72
    Issued Ipc Active                                                           inst/cycle                           1,15
    SM Busy                                                                              %                          28,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,51
    Mem Busy                                                                             %                          48,07
    Max Bandwidth                                                                        %                          32,55
    L1/TEX Hit Rate                                                                      %                          77,18
    L2 Hit Rate                                                                          %                         101,77
    Mem Pipes Busy                                                                       %                           9,36
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          27,53
    Issued Warp Per Scheduler                                                                                        0,28
    No Eligible                                                                          %                          72,47
    Active Warps Per Scheduler                                                        warp                           6,67
    Eligible Warps Per Scheduler                                                      warp                           0,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.67 active warps per scheduler, but only an average of 0.33 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          24,24
    Warp Cycles Per Executed Instruction                                             cycle                          24,24
    Warp Cycles Per Issue Active                                                      warp                          24,24
    Avg. Active Threads Per Warp                                                                                    28,00
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 14.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.0% of the total average of 24.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.597.714,29
    Executed Instructions                                                             inst                     89.472.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.597.733,39
    Issued Instructions                                                               inst                     89.473.070
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,06
    Achieved Active Warps Per SM                                                      warp                          27,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 51380224 (7.00x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 114688 transactions, got 802816 (7.00x) at PC 0x7f58a72679b0              

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:13, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      1.224.662
    Memory [%]                                                                           %                          18,98
    SOL DRAM                                                                             %                           3,54
    Duration                                                                       usecond                         881,09
    SOL L1/TEX Cache                                                                     %                          20,02
    SOL L2 Cache                                                                         %                          18,98
    SM Active Cycles                                                                 cycle                   1.173.701,14
    SM [%]                                                                               %                          83,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 46% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,19
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,79
    Mem Busy                                                                             %                          11,17
    Max Bandwidth                                                                        %                          18,98
    L1/TEX Hit Rate                                                                      %                          88,84
    L2 Hit Rate                                                                          %                          95,45
    Mem Pipes Busy                                                                       %                          21,64
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,89
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,11
    Active Warps Per Scheduler                                                        warp                           6,80
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.80 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         139,05
    Warp Cycles Per Executed Instruction                                             cycle                         139,12
    Warp Cycles Per Issue Active                                                      warp                         139,05
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,92
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.3% of the total average of 139.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 49.5 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.6% of the total average of 139.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      57.206,29
    Executed Instructions                                                             inst                      3.203.552
    Avg. Issued Instructions Per Scheduler                                            inst                      57.237,25
    Issued Instructions                                                               inst                      3.205.286
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,79
    Achieved Active Warps Per SM                                                      warp                          27,13
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:13, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,52
    SM Frequency                                                             cycle/nsecond                           1,40
    Elapsed Cycles                                                                   cycle                        312.560
    Memory [%]                                                                           %                          78,83
    SOL DRAM                                                                             %                          15,67
    Duration                                                                       usecond                         222,56
    SOL L1/TEX Cache                                                                     %                          83,34
    SOL L2 Cache                                                                         %                          78,83
    SM Active Cycles                                                                 cycle                     303.379,36
    SM [%]                                                                               %                           8,64
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,22
    Executed Ipc Elapsed                                                        inst/cycle                           0,22
    Issue Slots Busy                                                                     %                           5,63
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,63
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          30,40
    Mem Busy                                                                             %                          53,30
    Max Bandwidth                                                                        %                          78,83
    L1/TEX Hit Rate                                                                      %                          77,82
    L2 Hit Rate                                                                          %                          95,38
    Mem Pipes Busy                                                                       %                           8,64
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,80
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,20
    Active Warps Per Scheduler                                                        warp                           6,21
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 17.2 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.21 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         107,16
    Warp Cycles Per Executed Instruction                                             cycle                         107,31
    Warp Cycles Per Issue Active                                                      warp                         107,16
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.0 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 40.1% of the total average of 107.2 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 52.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 48.5% of the total average of 107.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      17.042,29
    Executed Instructions                                                             inst                        954.368
    Avg. Issued Instructions Per Scheduler                                            inst                      17.066,29
    Issued Instructions                                                               inst                        955.712
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,49
    Achieved Active Warps Per SM                                                      warp                          24,16
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56996 transactions, got 398276 (6.99x) at PC 0x7f58a725e110               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56987 transactions, got 398195 (6.99x) at PC 0x7f58a725e0e0               

  executeEltWiseLayerCUDA_split(float*, float*, float*, int, int), 2023-Mar-21 16:31:13, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        343.468
    Memory [%]                                                                           %                          75,70
    SOL DRAM                                                                             %                          19,38
    Duration                                                                       usecond                         245,89
    SOL L1/TEX Cache                                                                     %                          79,37
    SOL L2 Cache                                                                         %                          75,70
    SM Active Cycles                                                                 cycle                     325.875,57
    SM [%]                                                                               %                           6,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,21
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           5,20
    Issued Ipc Active                                                           inst/cycle                           0,21
    SM Busy                                                                              %                           5,20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,34
    Mem Busy                                                                             %                          52,05
    Max Bandwidth                                                                        %                          75,70
    L1/TEX Hit Rate                                                                      %                          80,45
    L2 Hit Rate                                                                          %                          87,04
    Mem Pipes Busy                                                                       %                           6,07
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,32
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          94,68
    Active Warps Per Scheduler                                                        warp                           6,46
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 18.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.46 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         121,53
    Warp Cycles Per Executed Instruction                                             cycle                         121,65
    Warp Cycles Per Issue Active                                                      warp                         121,53
    Avg. Active Threads Per Warp                                                                                    28,28
    Avg. Not Predicated Off Threads Per Warp                                                                        22,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 71.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 58.5% of the total average of 121.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.6 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      16.914,29
    Executed Instructions                                                             inst                        947.200
    Avg. Issued Instructions Per Scheduler                                            inst                      16.930,29
    Issued Instructions                                                               inst                        948.096
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             26
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          76,47
    Achieved Active Warps Per SM                                                      warp                          24,47
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c7e0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c7f0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c830               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c890               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c8d0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56924 transactions, got 397628 (6.99x) at PC 0x7f58a725c880               

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:14, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,46
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         97.648
    Memory [%]                                                                           %                          44,28
    SOL DRAM                                                                             %                          23,59
    Duration                                                                       usecond                          73,22
    SOL L1/TEX Cache                                                                     %                          88,55
    SOL L2 Cache                                                                         %                          13,62
    SM Active Cycles                                                                 cycle                      95.313,71
    SM [%]                                                                               %                          13,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,57
    Executed Ipc Elapsed                                                        inst/cycle                           0,56
    Issue Slots Busy                                                                     %                          14,27
    Issued Ipc Active                                                           inst/cycle                           0,57
    SM Busy                                                                              %                          14,27
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          44,02
    Mem Busy                                                                             %                          44,28
    Max Bandwidth                                                                        %                          23,59
    L1/TEX Hit Rate                                                                      %                          88,21
    L2 Hit Rate                                                                          %                          65,06
    Mem Pipes Busy                                                                       %                          10,82
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          14,66
    Issued Warp Per Scheduler                                                                                        0,15
    No Eligible                                                                          %                          85,34
    Active Warps Per Scheduler                                                        warp                           6,18
    Eligible Warps Per Scheduler                                                      warp                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 6.8 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.18 active warps per scheduler, but only an average of 0.25 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          42,13
    Warp Cycles Per Executed Instruction                                             cycle                          42,18
    Warp Cycles Per Issue Active                                                      warp                          42,13
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 32.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.8% of the total average of 42.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      13.586,29
    Executed Instructions                                                             inst                        760.832
    Avg. Issued Instructions Per Scheduler                                            inst                      13.602,29
    Issued Instructions                                                               inst                        761.728
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,09
    Achieved Active Warps Per SM                                                      warp                          24,67
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:14, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      6.050.230
    Memory [%]                                                                           %                          44,80
    SOL DRAM                                                                             %                           5,71
    Duration                                                                       msecond                           4,35
    SOL L1/TEX Cache                                                                     %                          89,61
    SOL L2 Cache                                                                         %                          30,72
    SM Active Cycles                                                                 cycle                   5.515.444,21
    SM [%]                                                                               %                          26,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,15
    Executed Ipc Elapsed                                                        inst/cycle                           1,05
    Issue Slots Busy                                                                     %                          28,63
    Issued Ipc Active                                                           inst/cycle                           1,15
    SM Busy                                                                              %                          28,63
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          10,98
    Mem Busy                                                                             %                          44,80
    Max Bandwidth                                                                        %                          30,02
    L1/TEX Hit Rate                                                                      %                          76,09
    L2 Hit Rate                                                                          %                          94,79
    Mem Pipes Busy                                                                       %                           8,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          27,86
    Issued Warp Per Scheduler                                                                                        0,28
    No Eligible                                                                          %                          72,14
    Active Warps Per Scheduler                                                        warp                           6,72
    Eligible Warps Per Scheduler                                                      warp                           0,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.72 active warps per scheduler, but only an average of 0.33 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          24,10
    Warp Cycles Per Executed Instruction                                             cycle                          24,10
    Warp Cycles Per Issue Active                                                      warp                          24,10
    Avg. Active Threads Per Warp                                                                                    28,00
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 15.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.3% of the total average of 24.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.579.076,57
    Executed Instructions                                                             inst                     88.428.288
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.096,23
    Issued Instructions                                                               inst                     88.429.389
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,13
    Achieved Active Warps Per SM                                                      warp                          27,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 51380224 (7.00x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a72679b0               

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:15, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        324.453
    Memory [%]                                                                           %                          17,97
    SOL DRAM                                                                             %                           2,57
    Duration                                                                       usecond                         233,82
    SOL L1/TEX Cache                                                                     %                          18,94
    SOL L2 Cache                                                                         %                          17,97
    SM Active Cycles                                                                 cycle                     294.633,43
    SM [%]                                                                               %                          78,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 43% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,19
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,37
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.4%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,93
    Mem Busy                                                                             %                          10,59
    Max Bandwidth                                                                        %                          17,97
    L1/TEX Hit Rate                                                                      %                          88,09
    L2 Hit Rate                                                                          %                          90,86
    Mem Pipes Busy                                                                       %                          20,45
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,90
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,10
    Active Warps Per Scheduler                                                        warp                           6,79
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.79 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         138,70
    Warp Cycles Per Executed Instruction                                             cycle                         139,00
    Warp Cycles Per Issue Active                                                      warp                         138,70
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.4% of the total average of 138.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 48.8 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.2% of the total average of 138.7 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      14.356,57
    Executed Instructions                                                             inst                        803.968
    Avg. Issued Instructions Per Scheduler                                            inst                      14.387,50
    Issued Instructions                                                               inst                        805.700
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,69
    Achieved Active Warps Per SM                                                      warp                          27,10
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:15, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         85.323
    Memory [%]                                                                           %                          72,01
    SOL DRAM                                                                             %                           9,72
    Duration                                                                       usecond                          64,13
    SOL L1/TEX Cache                                                                     %                          75,95
    SOL L2 Cache                                                                         %                          72,01
    SM Active Cycles                                                                 cycle                      74.356,07
    SM [%]                                                                               %                           7,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,23
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           5,76
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,76
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          17,99
    Mem Busy                                                                             %                          47,65
    Max Bandwidth                                                                        %                          72,01
    L1/TEX Hit Rate                                                                      %                          77,55
    L2 Hit Rate                                                                          %                          96,23
    Mem Pipes Busy                                                                       %                           7,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,74
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,26
    Active Warps Per Scheduler                                                        warp                           6,11
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 17.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.11 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         106,53
    Warp Cycles Per Executed Instruction                                             cycle                         107,13
    Warp Cycles Per Issue Active                                                      warp                         106,53
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.2 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 39.6% of the total average of 106.5 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 50.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 47.4% of the total average of 106.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       4.260,57
    Executed Instructions                                                             inst                        238.592
    Avg. Issued Instructions Per Scheduler                                            inst                       4.284,57
    Issued Instructions                                                               inst                        239.936
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 24.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,77
    Achieved Active Warps Per SM                                                      warp                          24,25
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14228 transactions, got 99380 (6.98x) at PC 0x7f58a725e110                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14198 transactions, got 99110 (6.98x) at PC 0x7f58a725e0e0                

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:15, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                         28.722
    Memory [%]                                                                           %                          37,61
    SOL DRAM                                                                             %                          20,09
    Duration                                                                       usecond                          21,63
    SOL L1/TEX Cache                                                                     %                          75,22
    SOL L2 Cache                                                                         %                          11,61
    SM Active Cycles                                                                 cycle                      24.885,29
    SM [%]                                                                               %                          11,92
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,55
    Executed Ipc Elapsed                                                        inst/cycle                           0,47
    Issue Slots Busy                                                                     %                          13,71
    Issued Ipc Active                                                           inst/cycle                           0,55
    SM Busy                                                                              %                          13,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,13
    Mem Busy                                                                             %                          37,61
    Max Bandwidth                                                                        %                          20,09
    L1/TEX Hit Rate                                                                      %                          88,30
    L2 Hit Rate                                                                          %                          50,17
    Mem Pipes Busy                                                                       %                           9,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          14,28
    Issued Warp Per Scheduler                                                                                        0,14
    No Eligible                                                                          %                          85,72
    Active Warps Per Scheduler                                                        warp                           6,35
    Eligible Warps Per Scheduler                                                      warp                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 7.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.35 active warps per scheduler, but only an average of 0.25 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          44,48
    Warp Cycles Per Executed Instruction                                             cycle                          44,69
    Warp Cycles Per Issue Active                                                      warp                          44,48
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 33.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 75.1% of the total average of 44.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.396,57
    Executed Instructions                                                             inst                        190.208
    Avg. Issued Instructions Per Scheduler                                            inst                       3.412,57
    Issued Instructions                                                               inst                        191.104
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 22.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,53
    Achieved Active Warps Per SM                                                      warp                          24,81
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:16, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,41
    Elapsed Cycles                                                                   cycle                     14.019.749
    Memory [%]                                                                           %                          44,61
    SOL DRAM                                                                             %                           1,55
    Duration                                                                       msecond                           9,91
    SOL L1/TEX Cache                                                                     %                          89,22
    SOL L2 Cache                                                                         %                          32,18
    SM Active Cycles                                                                 cycle                  12.230.267,71
    SM [%]                                                                               %                          10,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,49
    Executed Ipc Elapsed                                                        inst/cycle                           0,43
    Issue Slots Busy                                                                     %                          12,32
    Issued Ipc Active                                                           inst/cycle                           0,49
    SM Busy                                                                              %                          12,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,96
    Mem Busy                                                                             %                          44,61
    Max Bandwidth                                                                        %                          30,84
    L1/TEX Hit Rate                                                                      %                          73,30
    L2 Hit Rate                                                                          %                          96,64
    Mem Pipes Busy                                                                       %                           8,44
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          11,93
    Issued Warp Per Scheduler                                                                                        0,12
    No Eligible                                                                          %                          88,07
    Active Warps Per Scheduler                                                        warp                           6,93
    Eligible Warps Per Scheduler                                                      warp                           0,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 8.4 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.93 active warps per scheduler, but only an average of 0.17 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          58,06
    Warp Cycles Per Executed Instruction                                             cycle                          58,06
    Warp Cycles Per Issue Active                                                      warp                          58,06
    Avg. Active Threads Per Warp                                                                                    27,51
    Avg. Not Predicated Off Threads Per Warp                                                                        25,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 31.0 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 53.3% of the total average of 58.1 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 20.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 35.2% of the total average of 58.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.506.948,57
    Executed Instructions                                                             inst                     84.389.120
    Avg. Issued Instructions Per Scheduler                                            inst                   1.506.967,52
    Issued Instructions                                                               inst                     84.390.181
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85,38
    Achieved Active Warps Per SM                                                      warp                          27,32
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 5505024 transactions, got 38076416 (6.92x) at PC 0x7f58a7266fb0           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 5505024 transactions, got 38076416 (6.92x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 5308416 transactions, got 36716544 (6.92x) at PC 0x7f58a7266fa0           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 28672 transactions, got 200704 (7.00x) at PC 0x7f58a72679b0               

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:16, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        324.393
    Memory [%]                                                                           %                          21,11
    SOL DRAM                                                                             %                           2,58
    Duration                                                                       usecond                         233,92
    SOL L1/TEX Cache                                                                     %                          18,90
    SOL L2 Cache                                                                         %                          21,11
    SM Active Cycles                                                                 cycle                     294.755,43
    SM [%]                                                                               %                          78,53
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 43% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,19
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,93
    Mem Busy                                                                             %                          10,59
    Max Bandwidth                                                                        %                          21,11
    L1/TEX Hit Rate                                                                      %                          88,01
    L2 Hit Rate                                                                          %                          93,26
    Mem Pipes Busy                                                                       %                          20,44
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,89
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,11
    Active Warps Per Scheduler                                                        warp                           6,79
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.79 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         138,73
    Warp Cycles Per Executed Instruction                                             cycle                         138,98
    Warp Cycles Per Issue Active                                                      warp                         138,73
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.5% of the total average of 138.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 48.8 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.2% of the total average of 138.7 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      14.356,57
    Executed Instructions                                                             inst                        803.968
    Avg. Issued Instructions Per Scheduler                                            inst                      14.381,64
    Issued Instructions                                                               inst                        805.372
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,66
    Achieved Active Warps Per SM                                                      warp                          27,09
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:17, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,36
    Elapsed Cycles                                                                   cycle                         81.928
    Memory [%]                                                                           %                          75,03
    SOL DRAM                                                                             %                          13,94
    Duration                                                                       usecond                          59,90
    SOL L1/TEX Cache                                                                     %                          78,85
    SOL L2 Cache                                                                         %                          75,03
    SM Active Cycles                                                                 cycle                      74.029,64
    SM [%]                                                                               %                           8,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,23
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           5,79
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          27,33
    Mem Busy                                                                             %                          50,53
    Max Bandwidth                                                                        %                          75,03
    L1/TEX Hit Rate                                                                      %                          77,19
    L2 Hit Rate                                                                          %                          95,95
    Mem Pipes Busy                                                                       %                           8,24
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,92
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,08
    Active Warps Per Scheduler                                                        warp                           6,32
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 16.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.32 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         106,74
    Warp Cycles Per Executed Instruction                                             cycle                         107,34
    Warp Cycles Per Issue Active                                                      warp                         106,74
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.3 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 39.6% of the total average of 106.7 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 50.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 47.3% of the total average of 106.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       4.260,57
    Executed Instructions                                                             inst                        238.592
    Avg. Issued Instructions Per Scheduler                                            inst                       4.284,57
    Issued Instructions                                                               inst                        239.936
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 24.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,81
    Achieved Active Warps Per SM                                                      warp                          24,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14204 transactions, got 99164 (6.98x) at PC 0x7f58a725e110                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14189 transactions, got 99029 (6.98x) at PC 0x7f58a725e0e0                

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:17, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,55
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         29.258
    Memory [%]                                                                           %                          36,84
    SOL DRAM                                                                             %                          19,07
    Duration                                                                       usecond                          21,28
    SOL L1/TEX Cache                                                                     %                          73,69
    SOL L2 Cache                                                                         %                          11,52
    SM Active Cycles                                                                 cycle                      24.415,64
    SM [%]                                                                               %                          11,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,56
    Executed Ipc Elapsed                                                        inst/cycle                           0,47
    Issue Slots Busy                                                                     %                          13,98
    Issued Ipc Active                                                           inst/cycle                           0,56
    SM Busy                                                                              %                          13,98
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,80
    Mem Busy                                                                             %                          36,84
    Max Bandwidth                                                                        %                          19,07
    L1/TEX Hit Rate                                                                      %                          88,29
    L2 Hit Rate                                                                          %                          50,06
    Mem Pipes Busy                                                                       %                           9,02
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          13,92
    Issued Warp Per Scheduler                                                                                        0,14
    No Eligible                                                                          %                          86,08
    Active Warps Per Scheduler                                                        warp                           6,18
    Eligible Warps Per Scheduler                                                      warp                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 7.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.18 active warps per scheduler, but only an average of 0.25 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          44,38
    Warp Cycles Per Executed Instruction                                             cycle                          44,59
    Warp Cycles Per Issue Active                                                      warp                          44,38
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 32.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.1% of the total average of 44.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.396,57
    Executed Instructions                                                             inst                        190.208
    Avg. Issued Instructions Per Scheduler                                            inst                       3.412,57
    Issued Instructions                                                               inst                        191.104
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         65.536
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 7 thread blocks.    
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 22.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,77
    Achieved Active Warps Per SM                                                      warp                          24,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 100352 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda_split(float*, float*, float*, float*, int, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:17, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,35
    Elapsed Cycles                                                                   cycle                      5.682.327
    Memory [%]                                                                           %                          48,13
    SOL DRAM                                                                             %                           1,01
    Duration                                                                       msecond                           4,20
    SOL L1/TEX Cache                                                                     %                          96,25
    SOL L2 Cache                                                                         %                          32,14
    SM Active Cycles                                                                 cycle                   5.791.420,36
    SM [%]                                                                               %                          28,19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,10
    Executed Ipc Elapsed                                                        inst/cycle                           1,13
    Issue Slots Busy                                                                     %                          27,59
    Issued Ipc Active                                                           inst/cycle                           1,10
    SM Busy                                                                              %                          27,59
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,92
    Mem Busy                                                                             %                          48,13
    Max Bandwidth                                                                        %                          31,29
    L1/TEX Hit Rate                                                                      %                          77,17
    L2 Hit Rate                                                                          %                          99,24
    Mem Pipes Busy                                                                       %                           9,36
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          28,59
    Issued Warp Per Scheduler                                                                                        0,29
    No Eligible                                                                          %                          71,41
    Active Warps Per Scheduler                                                        warp                           6,92
    Eligible Warps Per Scheduler                                                      warp                           0,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.92 active warps per scheduler, but only an average of 0.34 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          24,22
    Warp Cycles Per Executed Instruction                                             cycle                          24,22
    Warp Cycles Per Issue Active                                                      warp                          24,22
    Avg. Active Threads Per Warp                                                                                    28,00
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 15.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.4% of the total average of 24.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.597.714,29
    Executed Instructions                                                             inst                     89.472.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.597.733,55
    Issued Instructions                                                               inst                     89.473.079
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             60
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,08
    Achieved Active Warps Per SM                                                      warp                          27,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 51380224 (7.00x) at PC 0x7f58a7267070           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 114688 transactions, got 802816 (7.00x) at PC 0x7f58a72679b0              

  executeBnNormLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:18, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,60
    Elapsed Cycles                                                                   cycle                      1.412.158
    Memory [%]                                                                           %                          16,67
    SOL DRAM                                                                             %                           7,10
    Duration                                                                       usecond                         881,12
    SOL L1/TEX Cache                                                                     %                          17,38
    SOL L2 Cache                                                                         %                          16,67
    SM Active Cycles                                                                 cycle                      1.173.456
    SM [%]                                                                               %                          72,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 40% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,20
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,88
    Issued Ipc Active                                                           inst/cycle                           0,20
    SM Busy                                                                              %                          86,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          13,61
    Mem Busy                                                                             %                           9,65
    Max Bandwidth                                                                        %                          16,67
    L1/TEX Hit Rate                                                                      %                          88,58
    L2 Hit Rate                                                                          %                          94,88
    Mem Pipes Busy                                                                       %                          18,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,88
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          95,12
    Active Warps Per Scheduler                                                        warp                           6,79
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 20.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.79 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         139,04
    Warp Cycles Per Executed Instruction                                             cycle                         139,11
    Warp Cycles Per Issue Active                                                      warp                         139,04
    Avg. Active Threads Per Warp                                                                                    28,08
    Avg. Not Predicated Off Threads Per Warp                                                                        25,92
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 82.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 59.4% of the total average of 139.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 49.4 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 35.5% of the total average of 139.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      57.206,29
    Executed Instructions                                                             inst                      3.203.552
    Avg. Issued Instructions Per Scheduler                                            inst                      57.231,38
    Issued Instructions                                                               inst                      3.204.957
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             35
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,80
    Achieved Active Warps Per SM                                                      warp                          27,13
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260100               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260420               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725fd50               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a7260070               

  executeScaleLayerCUDA_split(float*, float*, float*, int, int, int), 2023-Mar-21 16:31:18, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        312.454
    Memory [%]                                                                           %                          78,47
    SOL DRAM                                                                             %                          14,11
    Duration                                                                       usecond                         225,82
    SOL L1/TEX Cache                                                                     %                          83,09
    SOL L2 Cache                                                                         %                          78,47
    SM Active Cycles                                                                 cycle                     301.857,50
    SM [%]                                                                               %                           8,63
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,23
    Executed Ipc Elapsed                                                        inst/cycle                           0,22
    Issue Slots Busy                                                                     %                           5,65
    Issued Ipc Active                                                           inst/cycle                           0,23
    SM Busy                                                                              %                           5,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          27,54
    Mem Busy                                                                             %                          52,65
    Max Bandwidth                                                                        %                          78,47
    L1/TEX Hit Rate                                                                      %                          77,70
    L2 Hit Rate                                                                          %                          95,93
    Mem Pipes Busy                                                                       %                           8,63
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,81
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,19
    Active Warps Per Scheduler                                                        warp                           6,20
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 17.2 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.20 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         106,64
    Warp Cycles Per Executed Instruction                                             cycle                         106,79
    Warp Cycles Per Issue Active                                                      warp                         106,64
    Avg. Active Threads Per Warp                                                                                    28,27
    Avg. Not Predicated Off Threads Per Warp                                                                        22,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.7 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 40.1% of the total average of 106.6 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 51.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 48.5% of the total average of 106.6  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.2 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      17.042,29
    Executed Instructions                                                             inst                        954.368
    Avg. Issued Instructions Per Scheduler                                            inst                      17.066,29
    Issued Instructions                                                               inst                        955.712
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             29
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          75,64
    Achieved Active Warps Per SM                                                      warp                          24,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e030               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725e060               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56975 transactions, got 398087 (6.99x) at PC 0x7f58a725e110               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56876 transactions, got 397196 (6.98x) at PC 0x7f58a725e0e0               

  executeEltWiseLayerCUDA_split(float*, float*, float*, int, int), 2023-Mar-21 16:31:18, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,52
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                        332.520
    Memory [%]                                                                           %                          77,33
    SOL DRAM                                                                             %                          20,94
    Duration                                                                       usecond                         241,66
    SOL L1/TEX Cache                                                                     %                          81,26
    SOL L2 Cache                                                                         %                          77,33
    SM Active Cycles                                                                 cycle                     322.013,36
    SM [%]                                                                               %                           6,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,21
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           5,26
    Issued Ipc Active                                                           inst/cycle                           0,21
    SM Busy                                                                              %                           5,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          40,73
    Mem Busy                                                                             %                          51,23
    Max Bandwidth                                                                        %                          77,33
    L1/TEX Hit Rate                                                                      %                          81,58
    L2 Hit Rate                                                                          %                          92,03
    Mem Pipes Busy                                                                       %                           6,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,44
    Issued Warp Per Scheduler                                                                                        0,05
    No Eligible                                                                          %                          94,56
    Active Warps Per Scheduler                                                        warp                           6,50
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 18.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.50 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         119,54
    Warp Cycles Per Executed Instruction                                             cycle                         119,65
    Warp Cycles Per Issue Active                                                      warp                         119,54
    Avg. Active Threads Per Warp                                                                                    28,28
    Avg. Not Predicated Off Threads Per Warp                                                                        22,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 38.5 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 32.2% of the total average of 119.5 cycles between issuing two    
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 68.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 57.4% of the total average of 119.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 28.3 threads being active per cycle. This is further reduced    
          to 22.6 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      16.914,29
    Executed Instructions                                                             inst                        947.200
    Avg. Issued Instructions Per Scheduler                                            inst                      16.930,29
    Issued Instructions                                                               inst                        948.096
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             26
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,65
    Achieved Active Warps Per SM                                                      warp                          24,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c7e0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c7f0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c830               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c890               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725c8d0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 56819 transactions, got 396683 (6.98x) at PC 0x7f58a725c880               

  executeReLULayerCUDA_split(float*, int, int), 2023-Mar-21 16:31:18, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                         99.043
    Memory [%]                                                                           %                          43,64
    SOL DRAM                                                                             %                          25,12
    Duration                                                                       usecond                          71,07
    SOL L1/TEX Cache                                                                     %                          87,28
    SOL L2 Cache                                                                         %                          14,01
    SM Active Cycles                                                                 cycle                      92.791,64
    SM [%]                                                                               %                          13,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,59
    Executed Ipc Elapsed                                                        inst/cycle                           0,55
    Issue Slots Busy                                                                     %                          14,66
    Issued Ipc Active                                                           inst/cycle                           0,59
    SM Busy                                                                              %                          14,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          48,59
    Mem Busy                                                                             %                          43,64
    Max Bandwidth                                                                        %                          25,12
    L1/TEX Hit Rate                                                                      %                          88,21
    L2 Hit Rate                                                                          %                          49,93
    Mem Pipes Busy                                                                       %                          10,66
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          15,04
    Issued Warp Per Scheduler                                                                                        0,15
    No Eligible                                                                          %                          84,96
    Active Warps Per Scheduler                                                        warp                           6,28
    Eligible Warps Per Scheduler                                                      warp                           0,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 6.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.28 active warps per scheduler, but only an average of 0.25 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          41,76
    Warp Cycles Per Executed Instruction                                             cycle                          41,81
    Warp Cycles Per Issue Active                                                      warp                          41,76
    Avg. Active Threads Per Warp                                                                                    28,34
    Avg. Not Predicated Off Threads Per Warp                                                                        25,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 31.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 75.0% of the total average of 41.8   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      13.586,29
    Executed Instructions                                                             inst                        760.832
    Avg. Issued Instructions Per Scheduler                                            inst                      13.602,29
    Issued Instructions                                                               inst                        761.728
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                      1.024
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             31
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        262.144
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              2
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          76,95
    Achieved Active Warps Per SM                                                      warp                          24,63
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725ab10               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 57344 transactions, got 401408 (7.00x) at PC 0x7f58a725ab90               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:19, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,54
    SM Frequency                                                             cycle/nsecond                           1,43
    Elapsed Cycles                                                                   cycle                     10.032.174
    Memory [%]                                                                           %                          45,03
    SOL DRAM                                                                             %                          44,76
    Duration                                                                       msecond                           7,00
    SOL L1/TEX Cache                                                                     %                          90,05
    SOL L2 Cache                                                                         %                          40,50
    SM Active Cycles                                                                 cycle                   9.597.311,14
    SM [%]                                                                               %                          28,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,18
    Executed Ipc Elapsed                                                        inst/cycle                           1,13
    Issue Slots Busy                                                                     %                          29,38
    Issued Ipc Active                                                           inst/cycle                           1,18
    SM Busy                                                                              %                          29,38
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          88,38
    Mem Busy                                                                             %                          45,03
    Max Bandwidth                                                                        %                          44,76
    L1/TEX Hit Rate                                                                      %                          71,06
    L2 Hit Rate                                                                          %                          64,21
    Mem Pipes Busy                                                                       %                           9,41
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          28,77
    Issued Warp Per Scheduler                                                                                        0,29
    No Eligible                                                                          %                          71,23
    Active Warps Per Scheduler                                                        warp                           6,02
    Eligible Warps Per Scheduler                                                      warp                           0,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.5 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.02 active warps per scheduler, but only an average of 0.34 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          20,91
    Warp Cycles Per Executed Instruction                                             cycle                          20,91
    Warp Cycles Per Issue Active                                                      warp                          20,91
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 15.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 72.7% of the total average of 20.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   2.820.114,29
    Executed Instructions                                                             inst                    157.926.400
    Avg. Issued Instructions Per Scheduler                                            inst                   2.820.150,91
    Issued Instructions                                                               inst                    157.928.451
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          77,24
    Achieved Active Warps Per SM                                                      warp                          24,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12845056 transactions, got 91750400 (7.14x) at PC 0x7f58a7265650          
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:20, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        542.973
    Memory [%]                                                                           %                          15,09
    SOL DRAM                                                                             %                           3,71
    Duration                                                                       usecond                         390,43
    SOL L1/TEX Cache                                                                     %                          13,82
    SOL L2 Cache                                                                         %                          15,09
    SM Active Cycles                                                                 cycle                     610.896,21
    SM [%]                                                                               %                          83,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 52% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,14
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           3,62
    Issued Ipc Active                                                           inst/cycle                           0,14
    SM Busy                                                                              %                          74,32
    ---------------------------------------------------------------------- --------------- ------------------------------
          FP64 is the highest-utilized pipeline (74.3%). It executes 64-bit floating point operations. The pipeline is  
          well-utilized and might become a bottleneck if more work is added.                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           7,12
    Mem Busy                                                                             %                           8,52
    Max Bandwidth                                                                        %                          15,09
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          91,19
    Mem Pipes Busy                                                                       %                          21,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,34
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,66
    Active Warps Per Scheduler                                                        warp                           5,95
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.95 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,20
    Warp Cycles Per Executed Instruction                                             cycle                         137,28
    Warp Cycles Per Issue Active                                                      warp                         137,20
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 104.7 cycles being stalled waiting for a scoreboard dependency on  
          a L1TEX (local, global, surface, texture) operation. This represents about 76.3% of the total average of      
          137.2 cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses  
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.6 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.3% of the total average of 137.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      22.071,43
    Executed Instructions                                                             inst                      1.236.000
    Avg. Issued Instructions Per Scheduler                                            inst                      22.085,55
    Issued Instructions                                                               inst                      1.236.791
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,42
    Achieved Active Warps Per SM                                                      warp                          22,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:20, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         64.330
    Memory [%]                                                                           %                          38,45
    SOL DRAM                                                                             %                          30,88
    Duration                                                                       usecond                          46,72
    SOL L1/TEX Cache                                                                     %                          56,79
    SOL L2 Cache                                                                         %                          38,45
    SM Active Cycles                                                                 cycle                      56.810,43
    SM [%]                                                                               %                          17,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,26
    Executed Ipc Elapsed                                                        inst/cycle                           0,23
    Issue Slots Busy                                                                     %                           6,47
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,51
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          59,23
    Mem Busy                                                                             %                          32,91
    Max Bandwidth                                                                        %                          38,45
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          80,34
    Mem Pipes Busy                                                                       %                          17,10
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,25
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,75
    Active Warps Per Scheduler                                                        warp                           5,45
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.45 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,25
    Warp Cycles Per Executed Instruction                                             cycle                          75,64
    Warp Cycles Per Issue Active                                                      warp                          75,25
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.9% of the total average of 75.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.657,14
    Executed Instructions                                                             inst                        204.800
    Avg. Issued Instructions Per Scheduler                                            inst                       3.675,89
    Issued Instructions                                                               inst                        205.850
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          62,05
    Achieved Active Warps Per SM                                                      warp                          19,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725ede0               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:20, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      2.464.883
    Memory [%]                                                                           %                          53,74
    SOL DRAM                                                                             %                          16,30
    Duration                                                                       msecond                           1,76
    SOL L1/TEX Cache                                                                     %                          92,62
    SOL L2 Cache                                                                         %                          53,74
    SM Active Cycles                                                                 cycle                   2.617.115,86
    SM [%]                                                                               %                          28,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,08
    Executed Ipc Elapsed                                                        inst/cycle                           1,15
    Issue Slots Busy                                                                     %                          26,94
    Issued Ipc Active                                                           inst/cycle                           1,08
    SM Busy                                                                              %                          26,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          31,27
    Mem Busy                                                                             %                          53,74
    Max Bandwidth                                                                        %                          50,80
    L1/TEX Hit Rate                                                                      %                          60,92
    L2 Hit Rate                                                                          %                          87,93
    Mem Pipes Busy                                                                       %                           9,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          30,77
    Issued Warp Per Scheduler                                                                                        0,31
    No Eligible                                                                          %                          69,23
    Active Warps Per Scheduler                                                        warp                           6,23
    Eligible Warps Per Scheduler                                                      warp                           0,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.3 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.23 active warps per scheduler, but only an average of 0.36 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          20,26
    Warp Cycles Per Executed Instruction                                             cycle                          20,26
    Warp Cycles Per Issue Active                                                      warp                          20,26
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 15.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.6% of the total average of 20.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                     705.028,57
    Executed Instructions                                                             inst                     39.481.600
    Avg. Issued Instructions Per Scheduler                                            inst                     705.065,18
    Issued Instructions                                                               inst                     39.483.650
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          73,23
    Achieved Active Warps Per SM                                                      warp                          23,43
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3211264 transactions, got 22937600 (7.14x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:21, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        148.302
    Memory [%]                                                                           %                          11,67
    SOL DRAM                                                                             %                           1,97
    Duration                                                                       usecond                         107,14
    SOL L1/TEX Cache                                                                     %                          12,31
    SOL L2 Cache                                                                         %                          11,67
    SM Active Cycles                                                                 cycle                     133.266,21
    SM [%]                                                                               %                          76,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,76
    Mem Busy                                                                             %                           7,48
    Max Bandwidth                                                                        %                          11,67
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          91,74
    Mem Pipes Busy                                                                       %                          19,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,34
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,66
    Active Warps Per Scheduler                                                        warp                           5,96
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.96 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,11
    Warp Cycles Per Executed Instruction                                             cycle                         137,46
    Warp Cycles Per Issue Active                                                      warp                         137,11
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.0% of the total average of 137.1  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.1% of the total average of 137.1 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,69
    Achieved Active Warps Per SM                                                      warp                          22,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:21, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         172,57
    SM Frequency                                                             cycle/usecond                         158,05
    Elapsed Cycles                                                                   cycle                         17.749
    Memory [%]                                                                           %                          38,17
    SOL DRAM                                                                             %                          16,30
    Duration                                                                       usecond                            112
    SOL L1/TEX Cache                                                                     %                          51,61
    SOL L2 Cache                                                                         %                          38,17
    SM Active Cycles                                                                 cycle                      14.586,79
    SM [%]                                                                               %                          15,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,40
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,31
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,60
    Mem Busy                                                                             %                          31,85
    Max Bandwidth                                                                        %                          38,17
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          82,81
    Mem Pipes Busy                                                                       %                          15,49
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,21
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,79
    Active Warps Per Scheduler                                                        warp                           5,49
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.49 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          76,16
    Warp Cycles Per Executed Instruction                                             cycle                          77,72
    Warp Cycles Per Issue Active                                                      warp                          76,16
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 57.0% of the total average of 76.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,82
    Achieved Active Warps Per SM                                                      warp                          19,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:21, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,43
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                         12.363
    Memory [%]                                                                           %                          23,80
    SOL DRAM                                                                             %                          23,80
    Duration                                                                       usecond                           9,22
    SOL L1/TEX Cache                                                                     %                          35,83
    SOL L2 Cache                                                                         %                          13,55
    SM Active Cycles                                                                 cycle                       9.831,36
    SM [%]                                                                               %                          11,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,26
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           6,52
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           6,52
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,59
    Mem Busy                                                                             %                          17,92
    Max Bandwidth                                                                        %                          23,80
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          45,86
    Mem Pipes Busy                                                                       %                          11,11
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,40
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,60
    Active Warps Per Scheduler                                                        warp                           5,51
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.51 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          74,37
    Warp Cycles Per Executed Instruction                                             cycle                          75,85
    Warp Cycles Per Issue Active                                                      warp                          74,37
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 60.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 81.1% of the total average of 74.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          64,86
    Achieved Active Warps Per SM                                                      warp                          20,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:22, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,44
    Elapsed Cycles                                                                   cycle                      5.042.248
    Memory [%]                                                                           %                          43,89
    SOL DRAM                                                                             %                           2,95
    Duration                                                                       msecond                           3,50
    SOL L1/TEX Cache                                                                     %                          87,78
    SOL L2 Cache                                                                         %                           6,31
    SM Active Cycles                                                                 cycle                   4.565.236,93
    SM [%]                                                                               %                          26,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,18
    Executed Ipc Elapsed                                                        inst/cycle                           1,07
    Issue Slots Busy                                                                     %                          29,42
    Issued Ipc Active                                                           inst/cycle                           1,18
    SM Busy                                                                              %                          29,42
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           5,65
    Mem Busy                                                                             %                          43,89
    Max Bandwidth                                                                        %                          39,04
    L1/TEX Hit Rate                                                                      %                          97,67
    L2 Hit Rate                                                                          %                         106,25
    Mem Pipes Busy                                                                       %                          20,96
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          30,85
    Issued Warp Per Scheduler                                                                                        0,31
    No Eligible                                                                          %                          69,15
    Active Warps Per Scheduler                                                        warp                           6,22
    Eligible Warps Per Scheduler                                                      warp                           0,45
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.22 active warps per scheduler, but only an average of 0.45 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          20,15
    Warp Cycles Per Executed Instruction                                             cycle                          20,15
    Warp Cycles Per Issue Active                                                      warp                          20,15
    Avg. Active Threads Per Warp                                                                                    30,46
    Avg. Not Predicated Off Threads Per Warp                                                                        28,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 7.2 cycles being stalled waiting for the local/global instruction  
          queue to be not full. This represents about 35.6% of the total average of 20.1 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 7.7 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 38.1% of the total average of 20.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.342.857,14
    Executed Instructions                                                             inst                     75.200.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.342.889,64
    Issued Instructions                                                               inst                     75.201.820
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          74,11
    Achieved Active Warps Per SM                                                      warp                          23,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4816896 transactions, got 32768000 (6.80x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4816896 transactions, got 32522240 (6.75x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4521984 transactions, got 30490624 (6.74x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 1449984 transactions, got 1462272 (1.01x) at PC 0x7f58a7265560            

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:22, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        148.297
    Memory [%]                                                                           %                          11,66
    SOL DRAM                                                                             %                           2,03
    Duration                                                                       usecond                         107,10
    SOL L1/TEX Cache                                                                     %                          12,26
    SOL L2 Cache                                                                         %                          11,66
    SM Active Cycles                                                                 cycle                     133.256,50
    SM [%]                                                                               %                          76,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,87
    Mem Busy                                                                             %                           7,52
    Max Bandwidth                                                                        %                          11,66
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          92,25
    Mem Pipes Busy                                                                       %                          19,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,33
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,67
    Active Warps Per Scheduler                                                        warp                           5,94
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.94 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,01
    Warp Cycles Per Executed Instruction                                             cycle                         137,36
    Warp Cycles Per Issue Active                                                      warp                         137,01
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.1% of the total average of 137.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.1% of the total average of 137.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,70
    Achieved Active Warps Per SM                                                      warp                          22,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:22, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,36
    Elapsed Cycles                                                                   cycle                         18.107
    Memory [%]                                                                           %                          56,83
    SOL DRAM                                                                             %                          16,37
    Duration                                                                       usecond                          13,28
    SOL L1/TEX Cache                                                                     %                          50,54
    SOL L2 Cache                                                                         %                          56,83
    SM Active Cycles                                                                 cycle                      14.674,36
    SM [%]                                                                               %                          15,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           6,36
    Issued Ipc Active                                                           inst/cycle                           0,25
    SM Busy                                                                              %                           7,27
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          30,40
    Mem Busy                                                                             %                          56,83
    Max Bandwidth                                                                        %                          37,50
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          44,53
    Mem Pipes Busy                                                                       %                          15,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,32
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,68
    Active Warps Per Scheduler                                                        warp                          23,92
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          23.92 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps   
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         326,81
    Warp Cycles Per Executed Instruction                                             cycle                         333,51
    Warp Cycles Per Issue Active                                                      warp                         326,81
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          62,05
    Achieved Active Warps Per SM                                                      warp                          19,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:22, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         12.407
    Memory [%]                                                                           %                          21,91
    SOL DRAM                                                                             %                          21,91
    Duration                                                                       usecond                           9,34
    SOL L1/TEX Cache                                                                     %                          35,68
    SOL L2 Cache                                                                         %                          13,51
    SM Active Cycles                                                                 cycle                       9.282,79
    SM [%]                                                                               %                          11,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,27
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           6,91
    Issued Ipc Active                                                           inst/cycle                           0,28
    SM Busy                                                                              %                           6,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,02
    Mem Busy                                                                             %                          17,84
    Max Bandwidth                                                                        %                          21,91
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          45,68
    Mem Pipes Busy                                                                       %                          11,07
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,20
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,80
    Active Warps Per Scheduler                                                        warp                           5,30
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.30 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          73,65
    Warp Cycles Per Executed Instruction                                             cycle                          75,11
    Warp Cycles Per Issue Active                                                      warp                          73,65
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.6% of the total average of 73.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,27
    Achieved Active Warps Per SM                                                      warp                          20,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:23, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,51
    Elapsed Cycles                                                                   cycle                      3.114.876
    Memory [%]                                                                           %                          39,24
    SOL DRAM                                                                             %                           1,47
    Duration                                                                       msecond                           2,06
    SOL L1/TEX Cache                                                                     %                          78,49
    SOL L2 Cache                                                                         %                          29,07
    SM Active Cycles                                                                 cycle                   2.812.319,57
    SM [%]                                                                               %                          45,55
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,01
    Executed Ipc Elapsed                                                        inst/cycle                           1,82
    Issue Slots Busy                                                                     %                          50,34
    Issued Ipc Active                                                           inst/cycle                           2,01
    SM Busy                                                                              %                          50,34
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,81
    Mem Busy                                                                             %                          39,24
    Max Bandwidth                                                                        %                          35,25
    L1/TEX Hit Rate                                                                      %                          86,44
    L2 Hit Rate                                                                          %                          94,16
    Mem Pipes Busy                                                                       %                          15,24
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          50,43
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          49,57
    Active Warps Per Scheduler                                                        warp                           6,24
    Eligible Warps Per Scheduler                                                      warp                           0,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.24 active warps per scheduler, but only an average of 0.78 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,37
    Warp Cycles Per Executed Instruction                                             cycle                          12,37
    Warp Cycles Per Issue Active                                                      warp                          12,37
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.0 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 48.5% of the total average of 12.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.415.771,43
    Executed Instructions                                                             inst                     79.283.200
    Avg. Issued Instructions Per Scheduler                                            inst                   1.415.807,73
    Issued Instructions                                                               inst                     79.285.233
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          77,81
    Achieved Active Warps Per SM                                                      warp                          24,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6422528 transactions, got 45481984 (7.08x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:23, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        542.797
    Memory [%]                                                                           %                          14,12
    SOL DRAM                                                                             %                           3,71
    Duration                                                                       usecond                         390,66
    SOL L1/TEX Cache                                                                     %                          13,98
    SOL L2 Cache                                                                         %                          14,12
    SM Active Cycles                                                                 cycle                     530.007,64
    SM [%]                                                                               %                          83,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 52% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,17
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           7,10
    Mem Busy                                                                             %                           8,48
    Max Bandwidth                                                                        %                          14,12
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          92,10
    Mem Pipes Busy                                                                       %                          21,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,34
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,66
    Active Warps Per Scheduler                                                        warp                           5,95
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.95 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,21
    Warp Cycles Per Executed Instruction                                             cycle                         137,29
    Warp Cycles Per Issue Active                                                      warp                         137,21
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.3% of the total average of 137.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.6 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.3% of the total average of 137.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      22.071,43
    Executed Instructions                                                             inst                      1.236.000
    Avg. Issued Instructions Per Scheduler                                            inst                      22.085,55
    Issued Instructions                                                               inst                      1.236.791
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,59
    Achieved Active Warps Per SM                                                      warp                          22,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:23, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,52
    SM Frequency                                                             cycle/nsecond                           1,35
    Elapsed Cycles                                                                   cycle                         64.101
    Memory [%]                                                                           %                          37,38
    SOL DRAM                                                                             %                          29,97
    Duration                                                                       usecond                          47,33
    SOL L1/TEX Cache                                                                     %                          57,01
    SOL L2 Cache                                                                         %                          37,38
    SM Active Cycles                                                                 cycle                      56.455,86
    SM [%]                                                                               %                          17,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,26
    Executed Ipc Elapsed                                                        inst/cycle                           0,23
    Issue Slots Busy                                                                     %                           6,51
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          58,31
    Mem Busy                                                                             %                          32,84
    Max Bandwidth                                                                        %                          37,38
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          80,07
    Mem Pipes Busy                                                                       %                          17,15
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,35
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,65
    Active Warps Per Scheduler                                                        warp                           5,49
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.49 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          74,75
    Warp Cycles Per Executed Instruction                                             cycle                          75,13
    Warp Cycles Per Issue Active                                                      warp                          74,75
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.4% of the total average of 74.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.657,14
    Executed Instructions                                                             inst                        204.800
    Avg. Issued Instructions Per Scheduler                                            inst                       3.675,89
    Issued Instructions                                                               inst                        205.850
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,92
    Achieved Active Warps Per SM                                                      warp                          19,81
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:24, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         71.207
    Memory [%]                                                                           %                          53,27
    SOL DRAM                                                                             %                          44,86
    Duration                                                                       usecond                          51,81
    SOL L1/TEX Cache                                                                     %                          67,38
    SOL L2 Cache                                                                         %                          53,27
    SM Active Cycles                                                                 cycle                      66.411,71
    SM [%]                                                                               %                          12,87
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,21
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           5,18
    Issued Ipc Active                                                           inst/cycle                           0,21
    SM Busy                                                                              %                           5,51
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          86,68
    Mem Busy                                                                             %                          45,72
    Max Bandwidth                                                                        %                          53,27
    L1/TEX Hit Rate                                                                      %                          89,24
    L2 Hit Rate                                                                          %                          76,89
    Mem Pipes Busy                                                                       %                          12,87
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,91
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,09
    Active Warps Per Scheduler                                                        warp                           5,32
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 16.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.32 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          89,98
    Warp Cycles Per Executed Instruction                                             cycle                          90,30
    Warp Cycles Per Issue Active                                                      warp                          89,98
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 68.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.1% of the total average of 90.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.428,57
    Executed Instructions                                                             inst                        192.000
    Avg. Issued Instructions Per Scheduler                                            inst                       3.441,07
    Issued Instructions                                                               inst                        192.700
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,63
    Achieved Active Warps Per SM                                                      warp                          19,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:24, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         41.064
    Memory [%]                                                                           %                          27,23
    SOL DRAM                                                                             %                          27,23
    Duration                                                                       usecond                          30,78
    SOL L1/TEX Cache                                                                     %                          43,18
    SOL L2 Cache                                                                         %                          16,20
    SM Active Cycles                                                                 cycle                      35.608,57
    SM [%]                                                                               %                          13,39
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,28
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           7,10
    Issued Ipc Active                                                           inst/cycle                           0,28
    SM Busy                                                                              %                           7,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          52,32
    Mem Busy                                                                             %                          21,59
    Max Bandwidth                                                                        %                          27,23
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          41,16
    Mem Pipes Busy                                                                       %                          13,39
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,72
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,28
    Active Warps Per Scheduler                                                        warp                           5,45
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.45 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          70,58
    Warp Cycles Per Executed Instruction                                             cycle                          70,93
    Warp Cycles Per Issue Active                                                      warp                          70,58
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 57.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 81.3% of the total average of 70.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       2.514,29
    Executed Instructions                                                             inst                        140.800
    Avg. Issued Instructions Per Scheduler                                            inst                       2.526,79
    Issued Instructions                                                               inst                        141.500
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          64,65
    Achieved Active Warps Per SM                                                      warp                          20,69
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:24, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      3.623.996
    Memory [%]                                                                           %                          34,18
    SOL DRAM                                                                             %                           3,34
    Duration                                                                       msecond                           2,63
    SOL L1/TEX Cache                                                                     %                          68,36
    SOL L2 Cache                                                                         %                          23,93
    SM Active Cycles                                                                 cycle                   3.612.514,79
    SM [%]                                                                               %                          38,92
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,56
    Executed Ipc Elapsed                                                        inst/cycle                           1,56
    Issue Slots Busy                                                                     %                          38,95
    Issued Ipc Active                                                           inst/cycle                           1,56
    SM Busy                                                                              %                          38,95
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,37
    Mem Busy                                                                             %                          34,18
    Max Bandwidth                                                                        %                          30,94
    L1/TEX Hit Rate                                                                      %                          86,38
    L2 Hit Rate                                                                          %                          97,22
    Mem Pipes Busy                                                                       %                          12,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          42,13
    Issued Warp Per Scheduler                                                                                        0,42
    No Eligible                                                                          %                          57,87
    Active Warps Per Scheduler                                                        warp                           6,17
    Eligible Warps Per Scheduler                                                      warp                           0,60
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.4 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.17 active warps per scheduler, but only an average of 0.60 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,65
    Warp Cycles Per Executed Instruction                                             cycle                          14,65
    Warp Cycles Per Issue Active                                                      warp                          14,65
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 10.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 68.1% of the total average of 14.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.407.200
    Executed Instructions                                                             inst                     78.803.200
    Avg. Issued Instructions Per Scheduler                                            inst                   1.407.236,39
    Issued Instructions                                                               inst                     78.805.238
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          78,06
    Achieved Active Warps Per SM                                                      warp                          24,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6422528 transactions, got 45481984 (7.08x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:25, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        148.332
    Memory [%]                                                                           %                          12,23
    SOL DRAM                                                                             %                           1,97
    Duration                                                                       usecond                         107,20
    SOL L1/TEX Cache                                                                     %                          12,23
    SOL L2 Cache                                                                         %                          12,23
    SM Active Cycles                                                                 cycle                     133.248,64
    SM [%]                                                                               %                          76,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,76
    Mem Busy                                                                             %                           7,50
    Max Bandwidth                                                                        %                          12,23
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          92,40
    Mem Pipes Busy                                                                       %                          19,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,35
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,65
    Active Warps Per Scheduler                                                        warp                           5,96
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.96 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,01
    Warp Cycles Per Executed Instruction                                             cycle                         137,36
    Warp Cycles Per Issue Active                                                      warp                         137,01
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.1% of the total average of 137.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.1% of the total average of 137.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,69
    Achieved Active Warps Per SM                                                      warp                          22,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:25, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,61
    SM Frequency                                                             cycle/nsecond                           1,36
    Elapsed Cycles                                                                   cycle                         18.031
    Memory [%]                                                                           %                          35,76
    SOL DRAM                                                                             %                          14,73
    Duration                                                                       usecond                          13,25
    SOL L1/TEX Cache                                                                     %                          50,71
    SOL L2 Cache                                                                         %                          35,76
    SM Active Cycles                                                                 cycle                      14.640,43
    SM [%]                                                                               %                          15,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           6,37
    Issued Ipc Active                                                           inst/cycle                           0,25
    SM Busy                                                                              %                           7,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          30,42
    Mem Busy                                                                             %                          30,54
    Max Bandwidth                                                                        %                          35,76
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          90,03
    Mem Pipes Busy                                                                       %                          15,24
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,14
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,86
    Active Warps Per Scheduler                                                        warp                           5,34
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 14.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.34 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          74,76
    Warp Cycles Per Executed Instruction                                             cycle                          76,29
    Warp Cycles Per Issue Active                                                      warp                          74,76
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 58.0% of the total average of 74.8   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,91
    Achieved Active Warps Per SM                                                      warp                          19,81
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:25, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,57
    SM Frequency                                                             cycle/nsecond                           1,30
    Elapsed Cycles                                                                   cycle                         12.492
    Memory [%]                                                                           %                          20,97
    SOL DRAM                                                                             %                          20,97
    Duration                                                                       usecond                           9,57
    SOL L1/TEX Cache                                                                     %                          35,46
    SOL L2 Cache                                                                         %                          13,60
    SM Active Cycles                                                                 cycle                       9.274,79
    SM [%]                                                                               %                          11,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,27
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           6,91
    Issued Ipc Active                                                           inst/cycle                           0,28
    SM Busy                                                                              %                           6,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          42,02
    Mem Busy                                                                             %                          17,73
    Max Bandwidth                                                                        %                          20,97
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          45,93
    Mem Pipes Busy                                                                       %                          11,00
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,16
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,84
    Active Warps Per Scheduler                                                        warp                           5,24
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 14.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.24 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          73,12
    Warp Cycles Per Executed Instruction                                             cycle                          74,57
    Warp Cycles Per Issue Active                                                      warp                          73,12
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 77.2% of the total average of 73.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,51
    Achieved Active Warps Per SM                                                      warp                          20,96
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:26, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,55
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      4.851.912
    Memory [%]                                                                           %                          45,66
    SOL DRAM                                                                             %                           1,77
    Duration                                                                       msecond                           3,50
    SOL L1/TEX Cache                                                                     %                          91,32
    SOL L2 Cache                                                                         %                           6,56
    SM Active Cycles                                                                 cycle                   4.559.439,36
    SM [%]                                                                               %                          27,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 3% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,18
    Executed Ipc Elapsed                                                        inst/cycle                           1,11
    Issue Slots Busy                                                                     %                          29,45
    Issued Ipc Active                                                           inst/cycle                           1,18
    SM Busy                                                                              %                          29,45
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,51
    Mem Busy                                                                             %                          45,66
    Max Bandwidth                                                                        %                          40,61
    L1/TEX Hit Rate                                                                      %                          97,67
    L2 Hit Rate                                                                          %                         111,44
    Mem Pipes Busy                                                                       %                          21,79
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          31,01
    Issued Warp Per Scheduler                                                                                        0,31
    No Eligible                                                                          %                          68,99
    Active Warps Per Scheduler                                                        warp                           6,24
    Eligible Warps Per Scheduler                                                      warp                           0,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.24 active warps per scheduler, but only an average of 0.46 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          20,13
    Warp Cycles Per Executed Instruction                                             cycle                          20,13
    Warp Cycles Per Issue Active                                                      warp                          20,13
    Avg. Active Threads Per Warp                                                                                    30,46
    Avg. Not Predicated Off Threads Per Warp                                                                        28,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 7.2 cycles being stalled waiting for the local/global instruction  
          queue to be not full. This represents about 35.5% of the total average of 20.1 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 7.7 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 38.2% of the total average of 20.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.342.857,14
    Executed Instructions                                                             inst                     75.200.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.342.889,64
    Issued Instructions                                                               inst                     75.201.820
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          74,14
    Achieved Active Warps Per SM                                                      warp                          23,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4816896 transactions, got 32768000 (6.80x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4816896 transactions, got 32522240 (6.75x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4521984 transactions, got 30490624 (6.74x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 1449984 transactions, got 1462272 (1.01x) at PC 0x7f58a7265560            

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:26, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         969,89
    SM Frequency                                                             cycle/usecond                         899,94
    Elapsed Cycles                                                                   cycle                        148.349
    Memory [%]                                                                           %                          11,82
    SOL DRAM                                                                             %                           2,02
    Duration                                                                       usecond                         164,70
    SOL L1/TEX Cache                                                                     %                          12,37
    SOL L2 Cache                                                                         %                          11,82
    SM Active Cycles                                                                 cycle                     133.274,93
    SM [%]                                                                               %                          76,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,51
    Mem Busy                                                                             %                           7,51
    Max Bandwidth                                                                        %                          11,82
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          91,57
    Mem Pipes Busy                                                                       %                          19,96
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,35
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,65
    Active Warps Per Scheduler                                                        warp                           5,96
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.96 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,00
    Warp Cycles Per Executed Instruction                                             cycle                         137,35
    Warp Cycles Per Issue Active                                                      warp                         137,00
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.1% of the total average of 137.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.1% of the total average of 137.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,71
    Achieved Active Warps Per SM                                                      warp                          22,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:26, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,35
    SM Frequency                                                             cycle/nsecond                           1,23
    Elapsed Cycles                                                                   cycle                         17.771
    Memory [%]                                                                           %                          37,60
    SOL DRAM                                                                             %                          16,17
    Duration                                                                       usecond                          14,43
    SOL L1/TEX Cache                                                                     %                          51,48
    SOL L2 Cache                                                                         %                          37,60
    SM Active Cycles                                                                 cycle                      14.467,21
    SM [%]                                                                               %                          15,48
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,45
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,37
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          27,90
    Mem Busy                                                                             %                          31,47
    Max Bandwidth                                                                        %                          37,60
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          88,68
    Mem Pipes Busy                                                                       %                          15,48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,22
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,78
    Active Warps Per Scheduler                                                        warp                           5,48
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.48 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,89
    Warp Cycles Per Executed Instruction                                             cycle                          77,44
    Warp Cycles Per Issue Active                                                      warp                          75,89
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.2% of the total average of 75.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,71
    Achieved Active Warps Per SM                                                      warp                          19,75
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:26, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,27
    Elapsed Cycles                                                                   cycle                         12.085
    Memory [%]                                                                           %                          23,58
    SOL DRAM                                                                             %                          23,58
    Duration                                                                       usecond                           9,50
    SOL L1/TEX Cache                                                                     %                          36,63
    SOL L2 Cache                                                                         %                          13,89
    SM Active Cycles                                                                 cycle                          9.274
    SM [%]                                                                               %                          11,37
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,27
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,91
    Issued Ipc Active                                                           inst/cycle                           0,28
    SM Busy                                                                              %                           6,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          42,28
    Mem Busy                                                                             %                          18,32
    Max Bandwidth                                                                        %                          23,58
    L1/TEX Hit Rate                                                                      %                          85,91
    L2 Hit Rate                                                                          %                          40,77
    Mem Pipes Busy                                                                       %                          11,37
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           6,29
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          93,71
    Active Warps Per Scheduler                                                        warp                           4,69
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 15.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.69 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          74,59
    Warp Cycles Per Executed Instruction                                             cycle                          76,07
    Warp Cycles Per Issue Active                                                      warp                          74,59
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 75.9% of the total average of 74.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,72
    Achieved Active Warps Per SM                                                      warp                          21,03
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:27, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      2.848.963
    Memory [%]                                                                           %                          42,94
    SOL DRAM                                                                             %                           1,85
    Duration                                                                       msecond                           2,06
    SOL L1/TEX Cache                                                                     %                          85,89
    SOL L2 Cache                                                                         %                          30,68
    SM Active Cycles                                                                 cycle                   2.805.011,07
    SM [%]                                                                               %                          49,84
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,02
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          50,47
    Issued Ipc Active                                                           inst/cycle                           2,02
    SM Busy                                                                              %                          50,47
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,55
    Mem Busy                                                                             %                          42,94
    Max Bandwidth                                                                        %                          38,64
    L1/TEX Hit Rate                                                                      %                          86,44
    L2 Hit Rate                                                                          %                          97,54
    Mem Pipes Busy                                                                       %                          16,67
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          50,48
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          49,52
    Active Warps Per Scheduler                                                        warp                           6,23
    Eligible Warps Per Scheduler                                                      warp                           0,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.23 active warps per scheduler, but only an average of 0.78 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,33
    Warp Cycles Per Executed Instruction                                             cycle                          12,33
    Warp Cycles Per Issue Active                                                      warp                          12,33
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.0 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 48.4% of the total average of 12.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.415.771,43
    Executed Instructions                                                             inst                     79.283.200
    Avg. Issued Instructions Per Scheduler                                            inst                   1.415.807,79
    Issued Instructions                                                               inst                     79.285.236
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          77,80
    Achieved Active Warps Per SM                                                      warp                          24,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6422528 transactions, got 45481984 (7.08x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:27, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        543.008
    Memory [%]                                                                           %                          15,65
    SOL DRAM                                                                             %                           3,69
    Duration                                                                       usecond                         390,66
    SOL L1/TEX Cache                                                                     %                          14,09
    SOL L2 Cache                                                                         %                          15,65
    SM Active Cycles                                                                 cycle                     529.572,14
    SM [%]                                                                               %                          83,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 52% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,17
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           7,07
    Mem Busy                                                                             %                           9,83
    Max Bandwidth                                                                        %                          15,65
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          79,48
    Mem Pipes Busy                                                                       %                          21,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,34
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,66
    Active Warps Per Scheduler                                                        warp                           5,95
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.95 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,21
    Warp Cycles Per Executed Instruction                                             cycle                         137,30
    Warp Cycles Per Issue Active                                                      warp                         137,21
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.2% of the total average of 137.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.6 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.3% of the total average of 137.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      22.071,43
    Executed Instructions                                                             inst                      1.236.000
    Avg. Issued Instructions Per Scheduler                                            inst                      22.085,55
    Issued Instructions                                                               inst                      1.236.791
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,57
    Achieved Active Warps Per SM                                                      warp                          22,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:27, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         736,10
    SM Frequency                                                             cycle/usecond                         672,89
    Elapsed Cycles                                                                   cycle                         64.064
    Memory [%]                                                                           %                          37,78
    SOL DRAM                                                                             %                          30,89
    Duration                                                                       usecond                          94,94
    SOL L1/TEX Cache                                                                     %                          57,03
    SOL L2 Cache                                                                         %                          37,78
    SM Active Cycles                                                                 cycle                      56.664,07
    SM [%]                                                                               %                          17,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,26
    Executed Ipc Elapsed                                                        inst/cycle                           0,23
    Issue Slots Busy                                                                     %                           6,49
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,53
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          29,10
    Mem Busy                                                                             %                          32,73
    Max Bandwidth                                                                        %                          37,78
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          79,96
    Mem Pipes Busy                                                                       %                          17,17
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,38
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,62
    Active Warps Per Scheduler                                                        warp                           5,59
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.59 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,71
    Warp Cycles Per Executed Instruction                                             cycle                          76,10
    Warp Cycles Per Issue Active                                                      warp                          75,71
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.1% of the total average of 75.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.657,14
    Executed Instructions                                                             inst                        204.800
    Avg. Issued Instructions Per Scheduler                                            inst                       3.675,89
    Issued Instructions                                                               inst                        205.850
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          62,02
    Achieved Active Warps Per SM                                                      warp                          19,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:28, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         73.114
    Memory [%]                                                                           %                          50,61
    SOL DRAM                                                                             %                          44,23
    Duration                                                                       usecond                          53,31
    SOL L1/TEX Cache                                                                     %                          65,65
    SOL L2 Cache                                                                         %                          50,61
    SM Active Cycles                                                                 cycle                      62.317,57
    SM [%]                                                                               %                          12,54
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,22
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           5,52
    Issued Ipc Active                                                           inst/cycle                           0,22
    SM Busy                                                                              %                           5,87
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          81,83
    Mem Busy                                                                             %                          46,35
    Max Bandwidth                                                                        %                          50,61
    L1/TEX Hit Rate                                                                      %                          90,62
    L2 Hit Rate                                                                          %                          76,25
    Mem Pipes Busy                                                                       %                          12,54
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           6,00
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,00
    Active Warps Per Scheduler                                                        warp                           5,41
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 16.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.41 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          90,11
    Warp Cycles Per Executed Instruction                                             cycle                          90,44
    Warp Cycles Per Issue Active                                                      warp                          90,11
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 62.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 69.7% of the total average of 90.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.428,57
    Executed Instructions                                                             inst                        192.000
    Avg. Issued Instructions Per Scheduler                                            inst                       3.441,07
    Issued Instructions                                                               inst                        192.700
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,77
    Achieved Active Warps Per SM                                                      warp                          19,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:28, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         42.408
    Memory [%]                                                                           %                          27,01
    SOL DRAM                                                                             %                          27,01
    Duration                                                                       usecond                          30,91
    SOL L1/TEX Cache                                                                     %                          41,83
    SOL L2 Cache                                                                         %                          15,69
    SM Active Cycles                                                                 cycle                      34.609,14
    SM [%]                                                                               %                          12,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,29
    Executed Ipc Elapsed                                                        inst/cycle                           0,24
    Issue Slots Busy                                                                     %                           7,30
    Issued Ipc Active                                                           inst/cycle                           0,29
    SM Busy                                                                              %                           7,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          52,11
    Mem Busy                                                                             %                          20,91
    Max Bandwidth                                                                        %                          27,01
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          40,94
    Mem Pipes Busy                                                                       %                          12,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,59
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,41
    Active Warps Per Scheduler                                                        warp                           5,27
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.2 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.27 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          69,44
    Warp Cycles Per Executed Instruction                                             cycle                          69,78
    Warp Cycles Per Issue Active                                                      warp                          69,44
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 81.1% of the total average of 69.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       2.514,29
    Executed Instructions                                                             inst                        140.800
    Avg. Issued Instructions Per Scheduler                                            inst                       2.526,79
    Issued Instructions                                                               inst                        141.500
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,47
    Achieved Active Warps Per SM                                                      warp                          20,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:28, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,35
    Elapsed Cycles                                                                   cycle                      3.620.057
    Memory [%]                                                                           %                          34,19
    SOL DRAM                                                                             %                           3,31
    Duration                                                                       msecond                           2,67
    SOL L1/TEX Cache                                                                     %                          68,38
    SOL L2 Cache                                                                         %                          23,49
    SM Active Cycles                                                                 cycle                   3.343.475,43
    SM [%]                                                                               %                          38,96
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,68
    Executed Ipc Elapsed                                                        inst/cycle                           1,56
    Issue Slots Busy                                                                     %                          42,09
    Issued Ipc Active                                                           inst/cycle                           1,68
    SM Busy                                                                              %                          42,09
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,26
    Mem Busy                                                                             %                          34,19
    Max Bandwidth                                                                        %                          31,01
    L1/TEX Hit Rate                                                                      %                          86,38
    L2 Hit Rate                                                                          %                         101,13
    Mem Pipes Busy                                                                       %                          13,00
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          41,82
    Issued Warp Per Scheduler                                                                                        0,42
    No Eligible                                                                          %                          58,18
    Active Warps Per Scheduler                                                        warp                           6,13
    Eligible Warps Per Scheduler                                                      warp                           0,59
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.4 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.13 active warps per scheduler, but only an average of 0.59 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,65
    Warp Cycles Per Executed Instruction                                             cycle                          14,65
    Warp Cycles Per Issue Active                                                      warp                          14,65
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 8.8 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 59.9% of the total average of 14.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.407.200
    Executed Instructions                                                             inst                     78.803.200
    Avg. Issued Instructions Per Scheduler                                            inst                   1.407.236,29
    Issued Instructions                                                               inst                     78.805.232
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          78,05
    Achieved Active Warps Per SM                                                      warp                          24,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6422528 transactions, got 45481984 (7.08x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:29, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        148.418
    Memory [%]                                                                           %                          11,52
    SOL DRAM                                                                             %                           1,97
    Duration                                                                       usecond                         107,26
    SOL L1/TEX Cache                                                                     %                          12,23
    SOL L2 Cache                                                                         %                          11,52
    SM Active Cycles                                                                 cycle                     133.285,07
    SM [%]                                                                               %                          76,64
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,27
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,76
    Mem Busy                                                                             %                           7,53
    Max Bandwidth                                                                        %                          11,52
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                         117,45
    Mem Pipes Busy                                                                       %                          19,96
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,35
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,65
    Active Warps Per Scheduler                                                        warp                           5,96
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.96 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,07
    Warp Cycles Per Executed Instruction                                             cycle                         137,42
    Warp Cycles Per Issue Active                                                      warp                         137,07
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.0% of the total average of 137.1  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.1% of the total average of 137.1 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,68
    Achieved Active Warps Per SM                                                      warp                          22,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:29, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                         17.765
    Memory [%]                                                                           %                          37,44
    SOL DRAM                                                                             %                          16,52
    Duration                                                                       usecond                          13,25
    SOL L1/TEX Cache                                                                     %                          51,43
    SOL L2 Cache                                                                         %                          37,44
    SM Active Cycles                                                                 cycle                      14.478,14
    SM [%]                                                                               %                          15,48
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,44
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,37
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          30,43
    Mem Busy                                                                             %                          31,63
    Max Bandwidth                                                                        %                          37,44
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          83,67
    Mem Pipes Busy                                                                       %                          15,48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,17
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,83
    Active Warps Per Scheduler                                                        warp                           5,39
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 14.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.39 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,25
    Warp Cycles Per Executed Instruction                                             cycle                          76,79
    Warp Cycles Per Issue Active                                                      warp                          75,25
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.6% of the total average of 75.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,72
    Achieved Active Warps Per SM                                                      warp                          19,75
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:29, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         12.259
    Memory [%]                                                                           %                          22,70
    SOL DRAM                                                                             %                          22,70
    Duration                                                                       usecond                           9,22
    SOL L1/TEX Cache                                                                     %                          36,12
    SOL L2 Cache                                                                         %                          13,67
    SM Active Cycles                                                                 cycle                          9.355
    SM [%]                                                                               %                          11,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,27
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,85
    Issued Ipc Active                                                           inst/cycle                           0,27
    SM Busy                                                                              %                           6,85
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,58
    Mem Busy                                                                             %                          18,06
    Max Bandwidth                                                                        %                          22,70
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          46,10
    Mem Pipes Busy                                                                       %                          11,21
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,36
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,64
    Active Warps Per Scheduler                                                        warp                           5,45
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.45 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          73,97
    Warp Cycles Per Executed Instruction                                             cycle                          75,44
    Warp Cycles Per Issue Active                                                      warp                          73,97
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.9% of the total average of 74.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,16
    Achieved Active Warps Per SM                                                      warp                          20,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:30, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      4.851.619
    Memory [%]                                                                           %                          45,71
    SOL DRAM                                                                             %                           1,58
    Duration                                                                       msecond                           3,50
    SOL L1/TEX Cache                                                                     %                          91,41
    SOL L2 Cache                                                                         %                           6,74
    SM Active Cycles                                                                 cycle                   4.565.555,29
    SM [%]                                                                               %                          27,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 3% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,18
    Executed Ipc Elapsed                                                        inst/cycle                           1,11
    Issue Slots Busy                                                                     %                          29,41
    Issued Ipc Active                                                           inst/cycle                           1,18
    SM Busy                                                                              %                          29,41
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,03
    Mem Busy                                                                             %                          45,71
    Max Bandwidth                                                                        %                          40,59
    L1/TEX Hit Rate                                                                      %                          97,67
    L2 Hit Rate                                                                          %                          98,84
    Mem Pipes Busy                                                                       %                          21,79
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          31,02
    Issued Warp Per Scheduler                                                                                        0,31
    No Eligible                                                                          %                          68,98
    Active Warps Per Scheduler                                                        warp                           6,28
    Eligible Warps Per Scheduler                                                      warp                           0,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.28 active warps per scheduler, but only an average of 0.46 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          20,26
    Warp Cycles Per Executed Instruction                                             cycle                          20,26
    Warp Cycles Per Issue Active                                                      warp                          20,26
    Avg. Active Threads Per Warp                                                                                    30,46
    Avg. Not Predicated Off Threads Per Warp                                                                        28,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 7.2 cycles being stalled waiting for the local/global instruction  
          queue to be not full. This represents about 35.7% of the total average of 20.3 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 7.7 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 37.9% of the total average of 20.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.342.857,14
    Executed Instructions                                                             inst                     75.200.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.342.889,64
    Issued Instructions                                                               inst                     75.201.820
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          74,12
    Achieved Active Warps Per SM                                                      warp                          23,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4816896 transactions, got 32768000 (6.80x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4816896 transactions, got 32522240 (6.75x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4521984 transactions, got 30490624 (6.74x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 1449984 transactions, got 1462272 (1.01x) at PC 0x7f58a7265560            

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:30, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        148.307
    Memory [%]                                                                           %                          11,61
    SOL DRAM                                                                             %                           1,97
    Duration                                                                       usecond                         107,04
    SOL L1/TEX Cache                                                                     %                          12,38
    SOL L2 Cache                                                                         %                          11,61
    SM Active Cycles                                                                 cycle                     133.246,64
    SM [%]                                                                               %                          76,70
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,76
    Mem Busy                                                                             %                           7,59
    Max Bandwidth                                                                        %                          11,61
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          90,45
    Mem Pipes Busy                                                                       %                          19,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,34
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,66
    Active Warps Per Scheduler                                                        warp                           5,96
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.96 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,38
    Warp Cycles Per Executed Instruction                                             cycle                         137,73
    Warp Cycles Per Issue Active                                                      warp                         137,38
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 62.9% of the total average of 137.4  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.1% of the total average of 137.4 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,67
    Achieved Active Warps Per SM                                                      warp                          22,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:30, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,47
    SM Frequency                                                             cycle/nsecond                           1,30
    Elapsed Cycles                                                                   cycle                         17.643
    Memory [%]                                                                           %                          37,32
    SOL DRAM                                                                             %                          15,87
    Duration                                                                       usecond                          13,54
    SOL L1/TEX Cache                                                                     %                          51,78
    SOL L2 Cache                                                                         %                          37,32
    SM Active Cycles                                                                 cycle                      14.713,29
    SM [%]                                                                               %                          15,59
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,34
    Issued Ipc Active                                                           inst/cycle                           0,25
    SM Busy                                                                              %                           7,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          29,77
    Mem Busy                                                                             %                          34,76
    Max Bandwidth                                                                        %                          37,32
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          75,64
    Mem Pipes Busy                                                                       %                          15,59
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,30
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,70
    Active Warps Per Scheduler                                                        warp                           5,52
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.52 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,60
    Warp Cycles Per Executed Instruction                                             cycle                          77,15
    Warp Cycles Per Issue Active                                                      warp                          75,60
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 57.8% of the total average of 75.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,80
    Achieved Active Warps Per SM                                                      warp                          19,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:30, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,30
    Elapsed Cycles                                                                   cycle                         12.025
    Memory [%]                                                                           %                          23,35
    SOL DRAM                                                                             %                          23,35
    Duration                                                                       usecond                           9,25
    SOL L1/TEX Cache                                                                     %                          36,83
    SOL L2 Cache                                                                         %                          14,04
    SM Active Cycles                                                                 cycle                          9.422
    SM [%]                                                                               %                          11,43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,27
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,80
    Issued Ipc Active                                                           inst/cycle                           0,27
    SM Busy                                                                              %                           6,80
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,43
    Mem Busy                                                                             %                          18,42
    Max Bandwidth                                                                        %                          23,35
    L1/TEX Hit Rate                                                                      %                          85,91
    L2 Hit Rate                                                                          %                          60,64
    Mem Pipes Busy                                                                       %                          11,43
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,38
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,62
    Active Warps Per Scheduler                                                        warp                           5,59
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.59 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,69
    Warp Cycles Per Executed Instruction                                             cycle                          77,19
    Warp Cycles Per Issue Active                                                      warp                          75,69
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 57.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 75.6% of the total average of 75.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,04
    Achieved Active Warps Per SM                                                      warp                          20,81
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:31, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      2.850.718
    Memory [%]                                                                           %                          42,84
    SOL DRAM                                                                             %                           0,46
    Duration                                                                       msecond                           2,07
    SOL L1/TEX Cache                                                                     %                          85,68
    SOL L2 Cache                                                                         %                          29,96
    SM Active Cycles                                                                 cycle                   2.805.463,57
    SM [%]                                                                               %                          49,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,02
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          50,47
    Issued Ipc Active                                                           inst/cycle                           2,02
    SM Busy                                                                              %                          50,47
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Mbyte/second                         881,49
    Mem Busy                                                                             %                          42,84
    Max Bandwidth                                                                        %                          38,55
    L1/TEX Hit Rate                                                                      %                          86,44
    L2 Hit Rate                                                                          %                         101,47
    Mem Pipes Busy                                                                       %                          16,65
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          46,40
    Issued Warp Per Scheduler                                                                                        0,46
    No Eligible                                                                          %                          53,60
    Active Warps Per Scheduler                                                        warp                           5,73
    Eligible Warps Per Scheduler                                                      warp                           0,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.73 active warps per scheduler, but only an average of 0.72 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,34
    Warp Cycles Per Executed Instruction                                             cycle                          12,34
    Warp Cycles Per Issue Active                                                      warp                          12,34
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.0 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 48.4% of the total average of 12.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.415.771,43
    Executed Instructions                                                             inst                     79.283.200
    Avg. Issued Instructions Per Scheduler                                            inst                   1.415.807,84
    Issued Instructions                                                               inst                     79.285.239
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          77,81
    Achieved Active Warps Per SM                                                      warp                          24,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6422528 transactions, got 45481984 (7.08x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:31, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        543.001
    Memory [%]                                                                           %                          13,07
    SOL DRAM                                                                             %                           3,95
    Duration                                                                       usecond                         390,98
    SOL L1/TEX Cache                                                                     %                          14,13
    SOL L2 Cache                                                                         %                          13,07
    SM Active Cycles                                                                 cycle                     529.723,57
    SM [%]                                                                               %                          83,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 52% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,17
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           7,56
    Mem Busy                                                                             %                           8,39
    Max Bandwidth                                                                        %                          13,07
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          92,83
    Mem Pipes Busy                                                                       %                          21,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,33
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,67
    Active Warps Per Scheduler                                                        warp                           5,94
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.94 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,16
    Warp Cycles Per Executed Instruction                                             cycle                         137,25
    Warp Cycles Per Issue Active                                                      warp                         137,16
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.3% of the total average of 137.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.6 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.3% of the total average of 137.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      22.071,43
    Executed Instructions                                                             inst                      1.236.000
    Avg. Issued Instructions Per Scheduler                                            inst                      22.085,55
    Issued Instructions                                                               inst                      1.236.791
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,57
    Achieved Active Warps Per SM                                                      warp                          22,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:31, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                         64.039
    Memory [%]                                                                           %                          37,33
    SOL DRAM                                                                             %                          31,14
    Duration                                                                       usecond                          47,65
    SOL L1/TEX Cache                                                                     %                          57,11
    SOL L2 Cache                                                                         %                          37,33
    SM Active Cycles                                                                 cycle                      56.745,79
    SM [%]                                                                               %                          17,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,26
    Executed Ipc Elapsed                                                        inst/cycle                           0,23
    Issue Slots Busy                                                                     %                           6,48
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,52
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          57,93
    Mem Busy                                                                             %                          32,95
    Max Bandwidth                                                                        %                          37,33
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          80,03
    Mem Pipes Busy                                                                       %                          17,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,30
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,70
    Active Warps Per Scheduler                                                        warp                           5,51
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.51 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,58
    Warp Cycles Per Executed Instruction                                             cycle                          75,97
    Warp Cycles Per Issue Active                                                      warp                          75,58
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.4% of the total average of 75.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.657,14
    Executed Instructions                                                             inst                        204.800
    Avg. Issued Instructions Per Scheduler                                            inst                       3.675,89
    Issued Instructions                                                               inst                        205.850
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          62,06
    Achieved Active Warps Per SM                                                      warp                          19,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:32, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                         71.525
    Memory [%]                                                                           %                          54,08
    SOL DRAM                                                                             %                          44,09
    Duration                                                                       usecond                          51,17
    SOL L1/TEX Cache                                                                     %                          66,82
    SOL L2 Cache                                                                         %                          54,08
    SM Active Cycles                                                                 cycle                      65.231,21
    SM [%]                                                                               %                          12,82
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,21
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           5,28
    Issued Ipc Active                                                           inst/cycle                           0,21
    SM Busy                                                                              %                           5,61
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          85,40
    Mem Busy                                                                             %                          50,16
    Max Bandwidth                                                                        %                          54,08
    L1/TEX Hit Rate                                                                      %                          90,61
    L2 Hit Rate                                                                          %                          72,84
    Mem Pipes Busy                                                                       %                          12,82
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,98
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,02
    Active Warps Per Scheduler                                                        warp                           5,58
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 16.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.58 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          93,31
    Warp Cycles Per Executed Instruction                                             cycle                          93,65
    Warp Cycles Per Issue Active                                                      warp                          93,31
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 66.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 71.1% of the total average of 93.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.428,57
    Executed Instructions                                                             inst                        192.000
    Avg. Issued Instructions Per Scheduler                                            inst                       3.441,07
    Issued Instructions                                                               inst                        192.700
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,31
    Achieved Active Warps Per SM                                                      warp                          19,62
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:32, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         41.895
    Memory [%]                                                                           %                          27,17
    SOL DRAM                                                                             %                          27,17
    Duration                                                                       usecond                          30,30
    SOL L1/TEX Cache                                                                     %                          42,32
    SOL L2 Cache                                                                         %                          18,00
    SM Active Cycles                                                                 cycle                      34.949,07
    SM [%]                                                                               %                          13,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,29
    Executed Ipc Elapsed                                                        inst/cycle                           0,24
    Issue Slots Busy                                                                     %                           7,23
    Issued Ipc Active                                                           inst/cycle                           0,29
    SM Busy                                                                              %                           7,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          53,18
    Mem Busy                                                                             %                          21,16
    Max Bandwidth                                                                        %                          27,17
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          40,60
    Mem Pipes Busy                                                                       %                          13,12
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,73
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,27
    Active Warps Per Scheduler                                                        warp                           5,97
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.97 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          77,14
    Warp Cycles Per Executed Instruction                                             cycle                          77,53
    Warp Cycles Per Issue Active                                                      warp                          77,14
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 73.1% of the total average of 77.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       2.514,29
    Executed Instructions                                                             inst                        140.800
    Avg. Issued Instructions Per Scheduler                                            inst                       2.526,79
    Issued Instructions                                                               inst                        141.500
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          64,97
    Achieved Active Warps Per SM                                                      warp                          20,79
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:32, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,27
    Elapsed Cycles                                                                   cycle                      3.622.153
    Memory [%]                                                                           %                          34,17
    SOL DRAM                                                                             %                           3,27
    Duration                                                                       msecond                           2,85
    SOL L1/TEX Cache                                                                     %                          68,34
    SOL L2 Cache                                                                         %                          23,47
    SM Active Cycles                                                                 cycle                      3.300.045
    SM [%]                                                                               %                          38,94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,71
    Executed Ipc Elapsed                                                        inst/cycle                           1,56
    Issue Slots Busy                                                                     %                          42,64
    Issued Ipc Active                                                           inst/cycle                           1,71
    SM Busy                                                                              %                          42,64
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           5,86
    Mem Busy                                                                             %                          34,17
    Max Bandwidth                                                                        %                          30,94
    L1/TEX Hit Rate                                                                      %                          86,38
    L2 Hit Rate                                                                          %                          95,97
    Mem Pipes Busy                                                                       %                          12,99
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          42,28
    Issued Warp Per Scheduler                                                                                        0,42
    No Eligible                                                                          %                          57,72
    Active Warps Per Scheduler                                                        warp                           6,19
    Eligible Warps Per Scheduler                                                      warp                           0,60
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.4 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.19 active warps per scheduler, but only an average of 0.60 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,64
    Warp Cycles Per Executed Instruction                                             cycle                          14,64
    Warp Cycles Per Issue Active                                                      warp                          14,64
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 8.6 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 58.6% of the total average of 14.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.407.200
    Executed Instructions                                                             inst                     78.803.200
    Avg. Issued Instructions Per Scheduler                                            inst                   1.407.236,45
    Issued Instructions                                                               inst                     78.805.241
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          78,05
    Achieved Active Warps Per SM                                                      warp                          24,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6422528 transactions, got 45481984 (7.08x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:33, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        148.331
    Memory [%]                                                                           %                          11,63
    SOL DRAM                                                                             %                           1,97
    Duration                                                                       usecond                         107,26
    SOL L1/TEX Cache                                                                     %                          10,91
    SOL L2 Cache                                                                         %                          11,63
    SM Active Cycles                                                                 cycle                     133.224,07
    SM [%]                                                                               %                          76,70
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,31
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,75
    Mem Busy                                                                             %                           7,53
    Max Bandwidth                                                                        %                          11,63
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          91,34
    Mem Pipes Busy                                                                       %                          19,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,35
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,65
    Active Warps Per Scheduler                                                        warp                           5,96
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.96 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,00
    Warp Cycles Per Executed Instruction                                             cycle                         137,35
    Warp Cycles Per Issue Active                                                      warp                         137,00
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.1% of the total average of 137.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.2% of the total average of 137.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,71
    Achieved Active Warps Per SM                                                      warp                          22,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:33, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,42
    Elapsed Cycles                                                                   cycle                         19.024
    Memory [%]                                                                           %                          37,10
    SOL DRAM                                                                             %                          29,34
    Duration                                                                       usecond                          13,31
    SOL L1/TEX Cache                                                                     %                          48,09
    SOL L2 Cache                                                                         %                          37,10
    SM Active Cycles                                                                 cycle                      14.618,21
    SM [%]                                                                               %                          14,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           6,38
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          54,53
    Mem Busy                                                                             %                          31,84
    Max Bandwidth                                                                        %                          37,10
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          75,64
    Mem Pipes Busy                                                                       %                          14,46
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,32
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,68
    Active Warps Per Scheduler                                                        warp                           6,17
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.17 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          84,18
    Warp Cycles Per Executed Instruction                                             cycle                          85,91
    Warp Cycles Per Issue Active                                                      warp                          84,18
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 52.0% of the total average of 84.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,94
    Achieved Active Warps Per SM                                                      warp                          19,82
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:33, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,47
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                         12.197
    Memory [%]                                                                           %                          23,12
    SOL DRAM                                                                             %                          23,12
    Duration                                                                       usecond                           9,25
    SOL L1/TEX Cache                                                                     %                          36,29
    SOL L2 Cache                                                                         %                          13,73
    SM Active Cycles                                                                 cycle                       9.228,79
    SM [%]                                                                               %                          11,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,27
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,95
    Issued Ipc Active                                                           inst/cycle                           0,28
    SM Busy                                                                              %                           6,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,42
    Mem Busy                                                                             %                          18,15
    Max Bandwidth                                                                        %                          23,12
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          45,97
    Mem Pipes Busy                                                                       %                          11,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,34
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,66
    Active Warps Per Scheduler                                                        warp                           5,48
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.48 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          74,65
    Warp Cycles Per Executed Instruction                                             cycle                          76,14
    Warp Cycles Per Issue Active                                                      warp                          74,65
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 55.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.8% of the total average of 74.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,36
    Achieved Active Warps Per SM                                                      warp                          20,92
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:34, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      4.903.715
    Memory [%]                                                                           %                          45,24
    SOL DRAM                                                                             %                           2,17
    Duration                                                                       msecond                           3,51
    SOL L1/TEX Cache                                                                     %                          90,47
    SOL L2 Cache                                                                         %                           7,12
    SM Active Cycles                                                                 cycle                   4.558.670,36
    SM [%]                                                                               %                          27,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 3% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,18
    Executed Ipc Elapsed                                                        inst/cycle                           1,10
    Issue Slots Busy                                                                     %                          29,46
    Issued Ipc Active                                                           inst/cycle                           1,18
    SM Busy                                                                              %                          29,46
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,16
    Mem Busy                                                                             %                          45,24
    Max Bandwidth                                                                        %                          40,14
    L1/TEX Hit Rate                                                                      %                          97,68
    L2 Hit Rate                                                                          %                         115,60
    Mem Pipes Busy                                                                       %                          21,56
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          29,65
    Issued Warp Per Scheduler                                                                                        0,30
    No Eligible                                                                          %                          70,35
    Active Warps Per Scheduler                                                        warp                           5,98
    Eligible Warps Per Scheduler                                                      warp                           0,44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.4 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.98 active warps per scheduler, but only an average of 0.44 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          20,16
    Warp Cycles Per Executed Instruction                                             cycle                          20,16
    Warp Cycles Per Issue Active                                                      warp                          20,16
    Avg. Active Threads Per Warp                                                                                    30,46
    Avg. Not Predicated Off Threads Per Warp                                                                        28,33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 7.2 cycles being stalled waiting for the local/global instruction  
          queue to be not full. This represents about 35.6% of the total average of 20.2 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 7.7 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 38.0% of the total average of 20.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.342.857,14
    Executed Instructions                                                             inst                     75.200.000
    Avg. Issued Instructions Per Scheduler                                            inst                   1.342.889,71
    Issued Instructions                                                               inst                     75.201.824
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          74,12
    Achieved Active Warps Per SM                                                      warp                          23,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4816896 transactions, got 32768000 (6.80x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4816896 transactions, got 32522240 (6.75x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4521984 transactions, got 30490624 (6.74x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7265fa0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 1449984 transactions, got 1462272 (1.01x) at PC 0x7f58a7265560            

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:34, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        148.305
    Memory [%]                                                                           %                          11,47
    SOL DRAM                                                                             %                           2,03
    Duration                                                                       usecond                         107,33
    SOL L1/TEX Cache                                                                     %                          12,35
    SOL L2 Cache                                                                         %                          11,47
    SM Active Cycles                                                                 cycle                     133.249,43
    SM [%]                                                                               %                          76,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,15
    Issue Slots Busy                                                                     %                           4,18
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,86
    Mem Busy                                                                             %                           7,44
    Max Bandwidth                                                                        %                          11,47
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                         119,45
    Mem Pipes Busy                                                                       %                          19,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,35
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,65
    Active Warps Per Scheduler                                                        warp                           5,95
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.95 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,02
    Warp Cycles Per Executed Instruction                                             cycle                         137,37
    Warp Cycles Per Issue Active                                                      warp                         137,02
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.1% of the total average of 137.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.1% of the total average of 137.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       5.557,14
    Executed Instructions                                                             inst                        311.200
    Avg. Issued Instructions Per Scheduler                                            inst                       5.571,27
    Issued Instructions                                                               inst                        311.991
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,69
    Achieved Active Warps Per SM                                                      warp                          22,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:34, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,46
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                         17.737
    Memory [%]                                                                           %                          36,49
    SOL DRAM                                                                             %                          16,13
    Duration                                                                       usecond                          13,38
    SOL L1/TEX Cache                                                                     %                          51,59
    SOL L2 Cache                                                                         %                          36,49
    SM Active Cycles                                                                 cycle                      14.569,93
    SM [%]                                                                               %                          15,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,25
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,40
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          30,23
    Mem Busy                                                                             %                          32,22
    Max Bandwidth                                                                        %                          36,49
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          88,11
    Mem Pipes Busy                                                                       %                          15,49
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,11
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,89
    Active Warps Per Scheduler                                                        warp                           5,52
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 14.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.52 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          77,60
    Warp Cycles Per Executed Instruction                                             cycle                          79,20
    Warp Cycles Per Issue Active                                                      warp                          77,60
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 55.9% of the total average of 77.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         914,29
    Executed Instructions                                                             inst                         51.200
    Avg. Issued Instructions Per Scheduler                                            inst                         933,04
    Issued Instructions                                                               inst                         52.250
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,89
    Achieved Active Warps Per SM                                                      warp                          19,80
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725ede0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:34, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         12.287
    Memory [%]                                                                           %                          23,23
    SOL DRAM                                                                             %                          23,23
    Duration                                                                       usecond                           9,38
    SOL L1/TEX Cache                                                                     %                          36,03
    SOL L2 Cache                                                                         %                          13,65
    SM Active Cycles                                                                 cycle                       9.192,14
    SM [%]                                                                               %                          11,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,27
    Executed Ipc Elapsed                                                        inst/cycle                           0,21
    Issue Slots Busy                                                                     %                           6,97
    Issued Ipc Active                                                           inst/cycle                           0,28
    SM Busy                                                                              %                           6,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          42,83
    Mem Busy                                                                             %                          18,02
    Max Bandwidth                                                                        %                          23,23
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          45,67
    Mem Pipes Busy                                                                       %                          11,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,28
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,72
    Active Warps Per Scheduler                                                        warp                           5,41
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.41 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          74,25
    Warp Cycles Per Executed Instruction                                             cycle                          75,73
    Warp Cycles Per Issue Active                                                      warp                          74,25
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 75.4% of the total average of 74.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         628,57
    Executed Instructions                                                             inst                         35.200
    Avg. Issued Instructions Per Scheduler                                            inst                         641,07
    Issued Instructions                                                               inst                         35.900
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         128
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,71
    Achieved Active Warps Per SM                                                      warp                          21,03
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 12544 transactions, got 88832 (7.08x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:35, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,51
    Elapsed Cycles                                                                   cycle                      3.120.338
    Memory [%]                                                                           %                          39,17
    SOL DRAM                                                                             %                           3,79
    Duration                                                                       msecond                           2,06
    SOL L1/TEX Cache                                                                     %                          78,34
    SOL L2 Cache                                                                         %                          27,92
    SM Active Cycles                                                                 cycle                   2.808.254,50
    SM [%]                                                                               %                          45,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,02
    Executed Ipc Elapsed                                                        inst/cycle                           1,82
    Issue Slots Busy                                                                     %                          50,42
    Issued Ipc Active                                                           inst/cycle                           2,02
    SM Busy                                                                              %                          50,42
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           7,27
    Mem Busy                                                                             %                          39,17
    Max Bandwidth                                                                        %                          35,26
    L1/TEX Hit Rate                                                                      %                          86,44
    L2 Hit Rate                                                                          %                          98,04
    Mem Pipes Busy                                                                       %                          15,22
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          50,49
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          49,51
    Active Warps Per Scheduler                                                        warp                           6,25
    Eligible Warps Per Scheduler                                                      warp                           0,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.25 active warps per scheduler, but only an average of 0.78 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,37
    Warp Cycles Per Executed Instruction                                             cycle                          12,37
    Warp Cycles Per Issue Active                                                      warp                          12,37
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        28,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.0 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 48.4% of the total average of 12.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.415.771,43
    Executed Instructions                                                             inst                     79.283.200
    Avg. Issued Instructions Per Scheduler                                            inst                   1.415.807,75
    Issued Instructions                                                               inst                     79.285.234
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              1
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          77,81
    Achieved Active Warps Per SM                                                      warp                          24,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6422528 transactions, got 45481984 (7.08x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:35, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        543.016
    Memory [%]                                                                           %                          13,12
    SOL DRAM                                                                             %                           3,69
    Duration                                                                       usecond                         390,88
    SOL L1/TEX Cache                                                                     %                          13,97
    SOL L2 Cache                                                                         %                          13,12
    SM Active Cycles                                                                 cycle                     529.528,93
    SM [%]                                                                               %                          83,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 52% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,17
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           7,07
    Mem Busy                                                                             %                          10,90
    Max Bandwidth                                                                        %                          13,12
    L1/TEX Hit Rate                                                                      %                          93,07
    L2 Hit Rate                                                                          %                          71,31
    Mem Pipes Busy                                                                       %                          21,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,33
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,67
    Active Warps Per Scheduler                                                        warp                           5,95
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.95 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         137,21
    Warp Cycles Per Executed Instruction                                             cycle                         137,30
    Warp Cycles Per Issue Active                                                      warp                         137,21
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        29,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 86.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.2% of the total average of 137.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 41.6 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 30.3% of the total average of 137.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      22.071,43
    Executed Instructions                                                             inst                      1.236.000
    Avg. Issued Instructions Per Scheduler                                            inst                      22.085,55
    Issued Instructions                                                               inst                      1.236.791
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              3
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          71,57
    Achieved Active Warps Per SM                                                      warp                          22,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:35, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         64.619
    Memory [%]                                                                           %                          37,86
    SOL DRAM                                                                             %                          30,87
    Duration                                                                       usecond                          46,78
    SOL L1/TEX Cache                                                                     %                          56,60
    SOL L2 Cache                                                                         %                          37,86
    SM Active Cycles                                                                 cycle                      56.876,14
    SM [%]                                                                               %                          17,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,26
    Executed Ipc Elapsed                                                        inst/cycle                           0,23
    Issue Slots Busy                                                                     %                           6,46
    Issued Ipc Active                                                           inst/cycle                           0,26
    SM Busy                                                                              %                           7,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          59,02
    Mem Busy                                                                             %                          32,58
    Max Bandwidth                                                                        %                          37,86
    L1/TEX Hit Rate                                                                      %                          93,06
    L2 Hit Rate                                                                          %                          82,10
    Mem Pipes Busy                                                                       %                          17,03
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,27
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,73
    Active Warps Per Scheduler                                                        warp                           5,47
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.47 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          75,22
    Warp Cycles Per Executed Instruction                                             cycle                          75,60
    Warp Cycles Per Issue Active                                                      warp                          75,22
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.8% of the total average of 75.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.657,14
    Executed Instructions                                                             inst                        204.800
    Avg. Issued Instructions Per Scheduler                                            inst                       3.675,89
    Issued Instructions                                                               inst                        205.850
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          62,02
    Achieved Active Warps Per SM                                                      warp                          19,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:36, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,59
    SM Frequency                                                             cycle/nsecond                           1,40
    Elapsed Cycles                                                                   cycle                         72.377
    Memory [%]                                                                           %                          52,92
    SOL DRAM                                                                             %                          43,07
    Duration                                                                       usecond                          51,52
    SOL L1/TEX Cache                                                                     %                          66,11
    SOL L2 Cache                                                                         %                          52,92
    SM Active Cycles                                                                 cycle                      64.652,64
    SM [%]                                                                               %                          12,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,21
    Executed Ipc Elapsed                                                        inst/cycle                           0,19
    Issue Slots Busy                                                                     %                           5,32
    Issued Ipc Active                                                           inst/cycle                           0,21
    SM Busy                                                                              %                           5,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          87,67
    Mem Busy                                                                             %                          48,03
    Max Bandwidth                                                                        %                          52,92
    L1/TEX Hit Rate                                                                      %                          90,61
    L2 Hit Rate                                                                          %                          73,61
    Mem Pipes Busy                                                                       %                          12,67
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           5,95
    Issued Warp Per Scheduler                                                                                        0,06
    No Eligible                                                                          %                          94,05
    Active Warps Per Scheduler                                                        warp                           5,43
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 16.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.43 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          91,39
    Warp Cycles Per Executed Instruction                                             cycle                          91,72
    Warp Cycles Per Issue Active                                                      warp                          91,39
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 65.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 72.0% of the total average of 91.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       3.428,57
    Executed Instructions                                                             inst                        192.000
    Avg. Issued Instructions Per Scheduler                                            inst                       3.441,07
    Issued Instructions                                                               inst                        192.700
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          61,42
    Achieved Active Warps Per SM                                                      warp                          19,66
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:36, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                         42.049
    Memory [%]                                                                           %                          26,72
    SOL DRAM                                                                             %                          26,72
    Duration                                                                       usecond                          31,74
    SOL L1/TEX Cache                                                                     %                          42,17
    SOL L2 Cache                                                                         %                          18,18
    SM Active Cycles                                                                 cycle                      34.742,43
    SM [%]                                                                               %                          13,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,29
    Executed Ipc Elapsed                                                        inst/cycle                           0,24
    Issue Slots Busy                                                                     %                           7,27
    Issued Ipc Active                                                           inst/cycle                           0,29
    SM Busy                                                                              %                           7,27
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          50,74
    Mem Busy                                                                             %                          21,08
    Max Bandwidth                                                                        %                          26,72
    L1/TEX Hit Rate                                                                      %                          85,90
    L2 Hit Rate                                                                          %                          40,57
    Mem Pipes Busy                                                                       %                          13,07
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,66
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,34
    Active Warps Per Scheduler                                                        warp                           5,47
    Eligible Warps Per Scheduler                                                      warp                           0,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.47 active warps per scheduler, but only an average of 0.12 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          71,42
    Warp Cycles Per Executed Instruction                                             cycle                          71,78
    Warp Cycles Per Issue Active                                                      warp                          71,42
    Avg. Active Threads Per Warp                                                                                    31,36
    Avg. Not Predicated Off Threads Per Warp                                                                        31,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 56.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 79.4% of the total average of 71.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       2.514,29
    Executed Instructions                                                             inst                        140.800
    Avg. Issued Instructions Per Scheduler                                            inst                       2.526,79
    Issued Instructions                                                               inst                        141.500
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        784
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        401.408
    Waves Per SM                                                                                                    36,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 784    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              1
    Theoretical Active Warps per SM                                                   warp                             25
    Theoretical Occupancy                                                                %                          78,12
    Achieved Occupancy                                                                   %                          65,61
    Achieved Active Warps Per SM                                                      warp                          21,00
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 50176 transactions, got 355328 (7.08x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:37, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,43
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                      6.748.107
    Memory [%]                                                                           %                          33,94
    SOL DRAM                                                                             %                           3,50
    Duration                                                                       msecond                           5,10
    SOL L1/TEX Cache                                                                     %                          67,87
    SOL L2 Cache                                                                         %                          15,40
    SM Active Cycles                                                                 cycle                   7.037.380,43
    SM [%]                                                                               %                          46,82
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,79
    Executed Ipc Elapsed                                                        inst/cycle                           1,87
    Issue Slots Busy                                                                     %                          44,79
    Issued Ipc Active                                                           inst/cycle                           1,79
    SM Busy                                                                              %                          44,79
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,39
    Mem Busy                                                                             %                          33,94
    Max Bandwidth                                                                        %                          25,95
    L1/TEX Hit Rate                                                                      %                          89,46
    L2 Hit Rate                                                                          %                          99,68
    Mem Pipes Busy                                                                       %                          15,62
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          44,79
    Issued Warp Per Scheduler                                                                                        0,45
    No Eligible                                                                          %                          55,21
    Active Warps Per Scheduler                                                        warp                           6,45
    Eligible Warps Per Scheduler                                                      warp                           0,64
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.45 active warps per scheduler, but only an average of 0.64 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,40
    Warp Cycles Per Executed Instruction                                             cycle                          14,40
    Warp Cycles Per Issue Active                                                      warp                          14,40
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 8.9 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 61.9% of the total average of 14.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      3.152.128
    Executed Instructions                                                             inst                    176.519.168
    Avg. Issued Instructions Per Scheduler                                            inst                   3.152.165,39
    Issued Instructions                                                               inst                    176.521.262
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          84,04
    Achieved Active Warps Per SM                                                      warp                          26,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 13107200 transactions, got 61865984 (4.72x) at PC 0x7f58a7265650          
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:37, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        297.590
    Memory [%]                                                                           %                           7,03
    SOL DRAM                                                                             %                           2,83
    Duration                                                                       usecond                         213,54
    SOL L1/TEX Cache                                                                     %                           7,36
    SOL L2 Cache                                                                         %                           7,03
    SM Active Cycles                                                                 cycle                     292.683,21
    SM [%]                                                                               %                          85,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,24
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.9%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           5,43
    Mem Busy                                                                             %                           7,03
    Max Bandwidth                                                                        %                           6,89
    L1/TEX Hit Rate                                                                      %                          87,79
    L2 Hit Rate                                                                          %                          68,60
    Mem Pipes Busy                                                                       %                          22,27
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,25
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,75
    Active Warps Per Scheduler                                                        warp                           6,35
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.35 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         149,51
    Warp Cycles Per Executed Instruction                                             cycle                         149,69
    Warp Cycles Per Issue Active                                                      warp                         149,51
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        26,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 97.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.0% of the total average of 149.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      12.391,25
    Executed Instructions                                                             inst                        693.910
    Avg. Issued Instructions Per Scheduler                                            inst                      12.406,25
    Issued Instructions                                                               inst                        694.750
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          79,02
    Achieved Active Warps Per SM                                                      warp                          25,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:37, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         19.899
    Memory [%]                                                                           %                          44,38
    SOL DRAM                                                                             %                          40,43
    Duration                                                                       usecond                          14,98
    SOL L1/TEX Cache                                                                     %                          54,44
    SOL L2 Cache                                                                         %                          44,38
    SM Active Cycles                                                                 cycle                      18.828,79
    SM [%]                                                                               %                          30,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,44
    Executed Ipc Elapsed                                                        inst/cycle                           0,41
    Issue Slots Busy                                                                     %                          10,99
    Issued Ipc Active                                                           inst/cycle                           0,44
    SM Busy                                                                              %                          12,69
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          75,18
    Mem Busy                                                                             %                          44,38
    Max Bandwidth                                                                        %                          40,43
    L1/TEX Hit Rate                                                                      %                          87,86
    L2 Hit Rate                                                                          %                          65,66
    Mem Pipes Busy                                                                       %                          30,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,85
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,15
    Active Warps Per Scheduler                                                        warp                           5,44
    Eligible Warps Per Scheduler                                                      warp                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.44 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          50,16
    Warp Cycles Per Executed Instruction                                             cycle                          50,68
    Warp Cycles Per Issue Active                                                      warp                          50,16
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 37.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.8% of the total average of 50.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          2.048
    Executed Instructions                                                             inst                        114.688
    Avg. Issued Instructions Per Scheduler                                            inst                          2.069
    Issued Instructions                                                               inst                        115.864
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,79
    Achieved Active Warps Per SM                                                      warp                          22,65
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725ede0               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:38, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,52
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                      1.767.090
    Memory [%]                                                                           %                          32,39
    SOL DRAM                                                                             %                           2,62
    Duration                                                                       msecond                           1,27
    SOL L1/TEX Cache                                                                     %                          64,78
    SOL L2 Cache                                                                         %                          16,10
    SM Active Cycles                                                                 cycle                   1.758.128,93
    SM [%]                                                                               %                          44,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,79
    Executed Ipc Elapsed                                                        inst/cycle                           1,79
    Issue Slots Busy                                                                     %                          44,82
    Issued Ipc Active                                                           inst/cycle                           1,79
    SM Busy                                                                              %                          44,82
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           5,10
    Mem Busy                                                                             %                          32,39
    Max Bandwidth                                                                        %                          24,85
    L1/TEX Hit Rate                                                                      %                          88,91
    L2 Hit Rate                                                                          %                         102,73
    Mem Pipes Busy                                                                       %                          14,92
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          43,67
    Issued Warp Per Scheduler                                                                                        0,44
    No Eligible                                                                          %                          56,33
    Active Warps Per Scheduler                                                        warp                           6,30
    Eligible Warps Per Scheduler                                                      warp                           0,61
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.3 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.30 active warps per scheduler, but only an average of 0.61 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,43
    Warp Cycles Per Executed Instruction                                             cycle                          14,43
    Warp Cycles Per Issue Active                                                      warp                          14,43
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 8.2 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 57.1% of the total average of 14.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                        788.032
    Executed Instructions                                                             inst                     44.129.792
    Avg. Issued Instructions Per Scheduler                                            inst                     788.068,86
    Issued Instructions                                                               inst                     44.131.856
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          80,02
    Achieved Active Warps Per SM                                                      warp                          25,61
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3276800 transactions, got 15466496 (4.72x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:38, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,63
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.297
    Memory [%]                                                                           %                           6,51
    SOL DRAM                                                                             %                           3,17
    Duration                                                                       usecond                          56,61
    SOL L1/TEX Cache                                                                     %                           6,92
    SOL L2 Cache                                                                         %                           6,51
    SM Active Cycles                                                                 cycle                      73.788,50
    SM [%]                                                                               %                          81,27
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,61
    Mem Busy                                                                             %                           5,53
    Max Bandwidth                                                                        %                           6,51
    L1/TEX Hit Rate                                                                      %                          87,89
    L2 Hit Rate                                                                          %                          82,33
    Mem Pipes Busy                                                                       %                          21,14
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,24
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,76
    Active Warps Per Scheduler                                                        warp                           6,27
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.27 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,93
    Warp Cycles Per Executed Instruction                                             cycle                         148,65
    Warp Cycles Per Issue Active                                                      warp                         147,93
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.4% of the total average of 147.9  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,79
    Achieved Active Warps Per SM                                                      warp                          24,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:38, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,36
    SM Frequency                                                             cycle/nsecond                           1,24
    Elapsed Cycles                                                                   cycle                          6.566
    Memory [%]                                                                           %                          33,87
    SOL DRAM                                                                             %                          22,15
    Duration                                                                       usecond                           5,28
    SOL L1/TEX Cache                                                                     %                          40,96
    SOL L2 Cache                                                                         %                          33,87
    SM Active Cycles                                                                 cycle                       5.154,14
    SM [%]                                                                               %                          23,41
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,40
    Executed Ipc Elapsed                                                        inst/cycle                           0,31
    Issue Slots Busy                                                                     %                          10,34
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,59
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          38,48
    Mem Busy                                                                             %                          33,87
    Max Bandwidth                                                                        %                          28,94
    L1/TEX Hit Rate                                                                      %                          87,93
    L2 Hit Rate                                                                          %                          69,38
    Mem Pipes Busy                                                                       %                          23,41
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,26
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,74
    Active Warps Per Scheduler                                                        warp                           5,38
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.7 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.38 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,44
    Warp Cycles Per Executed Instruction                                             cycle                          54,59
    Warp Cycles Per Issue Active                                                      warp                          52,44
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 34.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.3% of the total average of 52.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,48
    Achieved Active Warps Per SM                                                      warp                          22,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:38, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,16
    SM Frequency                                                             cycle/nsecond                           1,07
    Elapsed Cycles                                                                   cycle                          5.681
    Memory [%]                                                                           %                          25,57
    SOL DRAM                                                                             %                          25,57
    Duration                                                                       usecond                           5,31
    SOL L1/TEX Cache                                                                     %                          22,47
    SOL L2 Cache                                                                         %                          15,19
    SM Active Cycles                                                                 cycle                       4.390,29
    SM [%]                                                                               %                          13,53
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,32
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,34
    Issued Ipc Active                                                           inst/cycle                           0,33
    SM Busy                                                                              %                           8,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,86
    Mem Busy                                                                             %                          15,19
    Max Bandwidth                                                                        %                          25,57
    L1/TEX Hit Rate                                                                      %                          75,81
    L2 Hit Rate                                                                          %                          15,03
    Mem Pipes Busy                                                                       %                          13,53
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,43
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,57
    Active Warps Per Scheduler                                                        warp                           5,27
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.27 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          62,53
    Warp Cycles Per Executed Instruction                                             cycle                          65,02
    Warp Cycles Per Issue Active                                                      warp                          62,53
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 44.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 71.2% of the total average of 62.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.6%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,46
    Achieved Active Warps Per SM                                                      warp                          22,23
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:39, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      2.478.850
    Memory [%]                                                                           %                          47,75
    SOL DRAM                                                                             %                           1,89
    Duration                                                                       msecond                           1,80
    SOL L1/TEX Cache                                                                     %                          89,00
    SOL L2 Cache                                                                         %                           3,75
    SM Active Cycles                                                                 cycle                   2.427.844,36
    SM [%]                                                                               %                          60,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 5% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,47
    Executed Ipc Elapsed                                                        inst/cycle                           2,43
    Issue Slots Busy                                                                     %                          61,85
    Issued Ipc Active                                                           inst/cycle                           2,47
    SM Busy                                                                              %                          61,85
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,62
    Mem Busy                                                                             %                          44,50
    Max Bandwidth                                                                        %                          47,75
    L1/TEX Hit Rate                                                                      %                          98,83
    L2 Hit Rate                                                                          %                          94,04
    Mem Pipes Busy                                                                       %                          47,75
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          61,81
    Issued Warp Per Scheduler                                                                                        0,62
    No Eligible                                                                          %                          38,19
    Active Warps Per Scheduler                                                        warp                           6,60
    Eligible Warps Per Scheduler                                                      warp                           1,35
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,68
    Warp Cycles Per Executed Instruction                                             cycle                          10,68
    Warp Cycles Per Issue Active                                                      warp                          10,68
    Avg. Active Threads Per Warp                                                                                    26,59
    Avg. Not Predicated Off Threads Per Warp                                                                        24,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 3.4 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 31.9% of the total average of 10.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.501.568
    Executed Instructions                                                             inst                     84.087.808
    Avg. Issued Instructions Per Scheduler                                            inst                   1.501.604,88
    Issued Instructions                                                               inst                     84.089.873
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          82,59
    Achieved Active Warps Per SM                                                      warp                          26,43
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4915200 transactions, got 18251776 (3.71x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4915200 transactions, got 17399808 (3.54x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4259840 transactions, got 16089088 (3.78x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:39, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.149
    Memory [%]                                                                           %                           6,53
    SOL DRAM                                                                             %                           1,94
    Duration                                                                       usecond                          56,67
    SOL L1/TEX Cache                                                                     %                           6,94
    SOL L2 Cache                                                                         %                           6,53
    SM Active Cycles                                                                 cycle                      73.807,79
    SM [%]                                                                               %                          81,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,69
    Mem Busy                                                                             %                           5,52
    Max Bandwidth                                                                        %                           6,53
    L1/TEX Hit Rate                                                                      %                          87,97
    L2 Hit Rate                                                                          %                          83,22
    Mem Pipes Busy                                                                       %                          21,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,22
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,78
    Active Warps Per Scheduler                                                        warp                           6,25
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.25 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,98
    Warp Cycles Per Executed Instruction                                             cycle                         148,70
    Warp Cycles Per Issue Active                                                      warp                         147,98
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.3% of the total average of 148.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,79
    Achieved Active Warps Per SM                                                      warp                          24,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:39, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,36
    SM Frequency                                                             cycle/nsecond                           1,23
    Elapsed Cycles                                                                   cycle                          6.612
    Memory [%]                                                                           %                          35,01
    SOL DRAM                                                                             %                          27,01
    Duration                                                                       usecond                           5,38
    SOL L1/TEX Cache                                                                     %                          41,33
    SOL L2 Cache                                                                         %                          35,01
    SM Active Cycles                                                                 cycle                       5.241,07
    SM [%]                                                                               %                          23,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,31
    Issue Slots Busy                                                                     %                          10,17
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,40
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          46,92
    Mem Busy                                                                             %                          35,01
    Max Bandwidth                                                                        %                          30,78
    L1/TEX Hit Rate                                                                      %                          87,94
    L2 Hit Rate                                                                          %                          66,26
    Mem Pipes Busy                                                                       %                          23,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,75
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          90,25
    Active Warps Per Scheduler                                                        warp                           6,47
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.3 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.47 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          66,39
    Warp Cycles Per Executed Instruction                                             cycle                          69,11
    Warp Cycles Per Issue Active                                                      warp                          66,39
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 34.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 51.3% of the total average of 66.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.9%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,18
    Achieved Active Warps Per SM                                                      warp                          22,14
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:40, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,32
    SM Frequency                                                             cycle/nsecond                           1,20
    Elapsed Cycles                                                                   cycle                          5.589
    Memory [%]                                                                           %                          25,53
    SOL DRAM                                                                             %                          25,53
    Duration                                                                       usecond                           4,64
    SOL L1/TEX Cache                                                                     %                          22,85
    SOL L2 Cache                                                                         %                          15,77
    SM Active Cycles                                                                 cycle                       4.246,79
    SM [%]                                                                               %                          13,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,62
    Issued Ipc Active                                                           inst/cycle                           0,34
    SM Busy                                                                              %                           8,62
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,28
    Mem Busy                                                                             %                          15,77
    Max Bandwidth                                                                        %                          25,53
    L1/TEX Hit Rate                                                                      %                          75,88
    L2 Hit Rate                                                                          %                          12,00
    Mem Pipes Busy                                                                       %                          13,75
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,89
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,11
    Active Warps Per Scheduler                                                        warp                           5,71
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.2 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.71 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          64,25
    Warp Cycles Per Executed Instruction                                             cycle                          66,81
    Warp Cycles Per Issue Active                                                      warp                          64,25
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.8% of the total average of 64.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,39
    Achieved Active Warps Per SM                                                      warp                          22,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:40, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      2.533.692
    Memory [%]                                                                           %                          23,63
    SOL DRAM                                                                             %                           0,49
    Duration                                                                       msecond                           1,83
    SOL L1/TEX Cache                                                                     %                          47,26
    SOL L2 Cache                                                                         %                          10,12
    SM Active Cycles                                                                 cycle                   2.450.146,07
    SM [%]                                                                               %                          62,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,58
    Executed Ipc Elapsed                                                        inst/cycle                           2,50
    Issue Slots Busy                                                                     %                          64,46
    Issued Ipc Active                                                           inst/cycle                           2,58
    SM Busy                                                                              %                          64,46
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Mbyte/second                         939,04
    Mem Busy                                                                             %                          23,63
    Max Bandwidth                                                                        %                          21,03
    L1/TEX Hit Rate                                                                      %                          94,58
    L2 Hit Rate                                                                          %                         100,64
    Mem Pipes Busy                                                                       %                          20,87
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          53,52
    Issued Warp Per Scheduler                                                                                        0,54
    No Eligible                                                                          %                          46,48
    Active Warps Per Scheduler                                                        warp                           5,81
    Eligible Warps Per Scheduler                                                      warp                           1,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 1.9 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.81 active warps per scheduler, but only an average of 1.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,86
    Warp Cycles Per Executed Instruction                                             cycle                          10,86
    Warp Cycles Per Issue Active                                                      warp                          10,86
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 3.5 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 32.0% of the total average of 10.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.579.264
    Executed Instructions                                                             inst                     88.438.784
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.300,88
    Issued Instructions                                                               inst                     88.440.849
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          87,39
    Achieved Active Warps Per SM                                                      warp                          27,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:40, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        297.033
    Memory [%]                                                                           %                           6,89
    SOL DRAM                                                                             %                           3,56
    Duration                                                                       usecond                         213,95
    SOL L1/TEX Cache                                                                     %                           7,38
    SOL L2 Cache                                                                         %                           6,89
    SM Active Cycles                                                                 cycle                     374.333,07
    SM [%]                                                                               %                          85,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,13
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           3,32
    Issued Ipc Active                                                           inst/cycle                           0,13
    SM Busy                                                                              %                          67,96
    ---------------------------------------------------------------------- --------------- ------------------------------
          FP64 is the highest-utilized pipeline (68.0%). It executes 64-bit floating point operations. The pipeline is  
          well-utilized and might become a bottleneck if more work is added.                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,80
    Mem Busy                                                                             %                           5,83
    Max Bandwidth                                                                        %                           6,89
    L1/TEX Hit Rate                                                                      %                          87,77
    L2 Hit Rate                                                                          %                          82,81
    Mem Pipes Busy                                                                       %                          22,31
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,25
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,75
    Active Warps Per Scheduler                                                        warp                           6,32
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.32 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,72
    Warp Cycles Per Executed Instruction                                             cycle                         148,96
    Warp Cycles Per Issue Active                                                      warp                         148,72
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        26,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 149.7 cycles being stalled waiting for a scoreboard dependency on  
          a L1TEX (local, global, surface, texture) operation. This represents about 100.6% of the total average of     
          148.7 cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses  
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      12.391,25
    Executed Instructions                                                             inst                        693.910
    Avg. Issued Instructions Per Scheduler                                            inst                      12.411,36
    Issued Instructions                                                               inst                        695.036
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          82,02
    Achieved Active Warps Per SM                                                      warp                          26,25
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:40, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,29
    Elapsed Cycles                                                                   cycle                         20.093
    Memory [%]                                                                           %                          44,75
    SOL DRAM                                                                             %                          40,55
    Duration                                                                       usecond                          15,58
    SOL L1/TEX Cache                                                                     %                          54,00
    SOL L2 Cache                                                                         %                          44,75
    SM Active Cycles                                                                 cycle                      18.998,21
    SM [%]                                                                               %                          30,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,43
    Executed Ipc Elapsed                                                        inst/cycle                           0,41
    Issue Slots Busy                                                                     %                          10,89
    Issued Ipc Active                                                           inst/cycle                           0,44
    SM Busy                                                                              %                          12,58
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          72,47
    Mem Busy                                                                             %                          44,75
    Max Bandwidth                                                                        %                          40,55
    L1/TEX Hit Rate                                                                      %                          87,88
    L2 Hit Rate                                                                          %                          64,60
    Mem Pipes Busy                                                                       %                          30,65
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,91
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,09
    Active Warps Per Scheduler                                                        warp                           5,71
    Eligible Warps Per Scheduler                                                      warp                           0,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.71 active warps per scheduler, but only an average of 0.13 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,30
    Warp Cycles Per Executed Instruction                                             cycle                          52,83
    Warp Cycles Per Issue Active                                                      warp                          52,30
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 37.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 71.5% of the total average of 52.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          2.048
    Executed Instructions                                                             inst                        114.688
    Avg. Issued Instructions Per Scheduler                                            inst                          2.069
    Issued Instructions                                                               inst                        115.864
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,39
    Achieved Active Warps Per SM                                                      warp                          22,53
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:41, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,46
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         22.340
    Memory [%]                                                                           %                          66,13
    SOL DRAM                                                                             %                          66,13
    Duration                                                                       usecond                          16,70
    SOL L1/TEX Cache                                                                     %                          54,28
    SOL L2 Cache                                                                         %                          54,85
    SM Active Cycles                                                                 cycle                         20.776
    SM [%]                                                                               %                          22,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,37
    Executed Ipc Elapsed                                                        inst/cycle                           0,34
    Issue Slots Busy                                                                     %                           9,31
    Issued Ipc Active                                                           inst/cycle                           0,37
    SM Busy                                                                              %                           9,86
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                         123,24
    Mem Busy                                                                             %                          54,85
    Max Bandwidth                                                                        %                          66,13
    L1/TEX Hit Rate                                                                      %                          78,69
    L2 Hit Rate                                                                          %                          50,68
    Mem Pipes Busy                                                                       %                          22,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,13
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,87
    Active Warps Per Scheduler                                                        warp                           5,62
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.62 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          61,54
    Warp Cycles Per Executed Instruction                                             cycle                          61,99
    Warp Cycles Per Issue Active                                                      warp                          61,54
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 46.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.3% of the total average of 61.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.920
    Executed Instructions                                                             inst                        107.520
    Avg. Issued Instructions Per Scheduler                                            inst                          1.934
    Issued Instructions                                                               inst                        108.304
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          72,02
    Achieved Active Warps Per SM                                                      warp                          23,05
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:41, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,43
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         15.713
    Memory [%]                                                                           %                          36,86
    SOL DRAM                                                                             %                          36,86
    Duration                                                                       usecond                          11,94
    SOL L1/TEX Cache                                                                     %                          32,56
    SOL L2 Cache                                                                         %                          21,57
    SM Active Cycles                                                                 cycle                      14.298,43
    SM [%]                                                                               %                          19,59
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                           9,95
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                           9,95
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          67,30
    Mem Busy                                                                             %                          21,57
    Max Bandwidth                                                                        %                          36,86
    L1/TEX Hit Rate                                                                      %                          75,73
    L2 Hit Rate                                                                          %                          10,90
    Mem Pipes Busy                                                                       %                          19,59
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,90
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          90,10
    Active Warps Per Scheduler                                                        warp                           5,30
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.30 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,50
    Warp Cycles Per Executed Instruction                                             cycle                          54,03
    Warp Cycles Per Issue Active                                                      warp                          53,50
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 40.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.0% of the total average of 53.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.408
    Executed Instructions                                                             inst                         78.848
    Avg. Issued Instructions Per Scheduler                                            inst                          1.422
    Issued Instructions                                                               inst                         79.632
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,18
    Achieved Active Warps Per SM                                                      warp                          21,82
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:41, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,72
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      3.168.443
    Memory [%]                                                                           %                          19,35
    SOL DRAM                                                                             %                           0,71
    Duration                                                                       msecond                           2,28
    SOL L1/TEX Cache                                                                     %                          38,70
    SOL L2 Cache                                                                         %                           8,61
    SM Active Cycles                                                                 cycle                      3.158.724
    SM [%]                                                                               %                          49,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,99
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          49,85
    Issued Ipc Active                                                           inst/cycle                           1,99
    SM Busy                                                                              %                          49,85
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,57
    Mem Busy                                                                             %                          19,35
    Max Bandwidth                                                                        %                          16,79
    L1/TEX Hit Rate                                                                      %                          94,24
    L2 Hit Rate                                                                          %                          96,26
    Mem Pipes Busy                                                                       %                          16,61
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          49,83
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          50,17
    Active Warps Per Scheduler                                                        warp                           6,46
    Eligible Warps Per Scheduler                                                      warp                           0,96
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.46 active warps per scheduler, but only an average of 0.96 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,97
    Warp Cycles Per Executed Instruction                                             cycle                          12,97
    Warp Cycles Per Issue Active                                                      warp                          12,97
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.0 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 45.9% of the total average of 13.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.574.464
    Executed Instructions                                                             inst                     88.169.984
    Avg. Issued Instructions Per Scheduler                                            inst                   1.574.501,32
    Issued Instructions                                                               inst                     88.172.074
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          80,89
    Achieved Active Warps Per SM                                                      warp                          25,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:42, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.136
    Memory [%]                                                                           %                           6,54
    SOL DRAM                                                                             %                           1,92
    Duration                                                                       usecond                          56,61
    SOL L1/TEX Cache                                                                     %                           6,91
    SOL L2 Cache                                                                         %                           6,54
    SM Active Cycles                                                                 cycle                      73.784,71
    SM [%]                                                                               %                          81,42
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,64
    Mem Busy                                                                             %                           5,94
    Max Bandwidth                                                                        %                           6,54
    L1/TEX Hit Rate                                                                      %                          87,89
    L2 Hit Rate                                                                          %                          76,78
    Mem Pipes Busy                                                                       %                          21,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,23
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,77
    Active Warps Per Scheduler                                                        warp                           6,28
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.28 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,36
    Warp Cycles Per Executed Instruction                                             cycle                         149,08
    Warp Cycles Per Issue Active                                                      warp                         148,36
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.1% of the total average of 148.4  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,76
    Achieved Active Warps Per SM                                                      warp                          24,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:42, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,57
    SM Frequency                                                             cycle/nsecond                           1,26
    Elapsed Cycles                                                                   cycle                          6.624
    Memory [%]                                                                           %                          34,25
    SOL DRAM                                                                             %                          19,22
    Duration                                                                       usecond                           5,25
    SOL L1/TEX Cache                                                                     %                          41,53
    SOL L2 Cache                                                                         %                          34,25
    SM Active Cycles                                                                 cycle                       5.204,71
    SM [%]                                                                               %                          23,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,31
    Issue Slots Busy                                                                     %                          10,24
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,48
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          38,71
    Mem Busy                                                                             %                          34,25
    Max Bandwidth                                                                        %                          28,09
    L1/TEX Hit Rate                                                                      %                          87,94
    L2 Hit Rate                                                                          %                          67,49
    Mem Pipes Busy                                                                       %                          23,21
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,33
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,67
    Active Warps Per Scheduler                                                        warp                           5,47
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.7 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.47 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,89
    Warp Cycles Per Executed Instruction                                             cycle                          55,06
    Warp Cycles Per Issue Active                                                      warp                          52,89
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 33.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.6% of the total average of 52.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 21.3%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,87
    Achieved Active Warps Per SM                                                      warp                          22,04
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:42, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,52
    SM Frequency                                                             cycle/nsecond                           1,23
    Elapsed Cycles                                                                   cycle                          5.758
    Memory [%]                                                                           %                          24,65
    SOL DRAM                                                                             %                          24,65
    Duration                                                                       usecond                           4,67
    SOL L1/TEX Cache                                                                     %                          22,16
    SOL L2 Cache                                                                         %                          15,20
    SM Active Cycles                                                                 cycle                       4.218,93
    SM [%]                                                                               %                          13,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,24
    Issue Slots Busy                                                                     %                           8,68
    Issued Ipc Active                                                           inst/cycle                           0,35
    SM Busy                                                                              %                           8,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          47,97
    Mem Busy                                                                             %                          15,00
    Max Bandwidth                                                                        %                          24,65
    L1/TEX Hit Rate                                                                      %                          75,82
    L2 Hit Rate                                                                          %                          12,52
    Mem Pipes Busy                                                                       %                          13,34
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,72
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,28
    Active Warps Per Scheduler                                                        warp                           5,44
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.44 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          62,37
    Warp Cycles Per Executed Instruction                                             cycle                          64,85
    Warp Cycles Per Issue Active                                                      warp                          62,37
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 67.6% of the total average of 62.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,30
    Achieved Active Warps Per SM                                                      warp                          22,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:43, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,41
    Elapsed Cycles                                                                   cycle                      2.544.521
    Memory [%]                                                                           %                          46,52
    SOL DRAM                                                                             %                           4,46
    Duration                                                                       msecond                           1,80
    SOL L1/TEX Cache                                                                     %                          86,71
    SOL L2 Cache                                                                         %                           4,82
    SM Active Cycles                                                                 cycle                   2.429.105,50
    SM [%]                                                                               %                          59,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 5% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,47
    Executed Ipc Elapsed                                                        inst/cycle                           2,37
    Issue Slots Busy                                                                     %                          61,82
    Issued Ipc Active                                                           inst/cycle                           2,47
    SM Busy                                                                              %                          61,82
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           8,57
    Mem Busy                                                                             %                          43,36
    Max Bandwidth                                                                        %                          46,52
    L1/TEX Hit Rate                                                                      %                          98,84
    L2 Hit Rate                                                                          %                          70,82
    Mem Pipes Busy                                                                       %                          46,52
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          61,78
    Issued Warp Per Scheduler                                                                                        0,62
    No Eligible                                                                          %                          38,22
    Active Warps Per Scheduler                                                        warp                           6,60
    Eligible Warps Per Scheduler                                                      warp                           1,35
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,68
    Warp Cycles Per Executed Instruction                                             cycle                          10,68
    Warp Cycles Per Issue Active                                                      warp                          10,68
    Avg. Active Threads Per Warp                                                                                    26,59
    Avg. Not Predicated Off Threads Per Warp                                                                        24,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 3.4 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 31.9% of the total average of 10.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.501.568
    Executed Instructions                                                             inst                     84.087.808
    Avg. Issued Instructions Per Scheduler                                            inst                   1.501.604,88
    Issued Instructions                                                               inst                     84.089.873
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          82,55
    Achieved Active Warps Per SM                                                      warp                          26,42
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4915200 transactions, got 18251776 (3.71x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4915200 transactions, got 17399808 (3.54x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4259840 transactions, got 16089088 (3.78x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:43, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.291
    Memory [%]                                                                           %                           6,48
    SOL DRAM                                                                             %                           1,89
    Duration                                                                       usecond                          56,67
    SOL L1/TEX Cache                                                                     %                           6,88
    SOL L2 Cache                                                                         %                           6,48
    SM Active Cycles                                                                 cycle                      73.823,64
    SM [%]                                                                               %                          81,27
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,58
    Mem Busy                                                                             %                           5,50
    Max Bandwidth                                                                        %                           6,48
    L1/TEX Hit Rate                                                                      %                          87,90
    L2 Hit Rate                                                                          %                         118,80
    Mem Pipes Busy                                                                       %                          21,14
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,23
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,77
    Active Warps Per Scheduler                                                        warp                           6,25
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.25 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,66
    Warp Cycles Per Executed Instruction                                             cycle                         148,38
    Warp Cycles Per Issue Active                                                      warp                         147,66
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.4% of the total average of 147.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,74
    Achieved Active Warps Per SM                                                      warp                          24,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:43, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,34
    SM Frequency                                                             cycle/nsecond                           1,36
    Elapsed Cycles                                                                   cycle                          7.342
    Memory [%]                                                                           %                          39,66
    SOL DRAM                                                                             %                          39,66
    Duration                                                                       usecond                           5,41
    SOL L1/TEX Cache                                                                     %                          37,26
    SOL L2 Cache                                                                         %                          31,57
    SM Active Cycles                                                                 cycle                       5.217,79
    SM [%]                                                                               %                          20,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,28
    Issue Slots Busy                                                                     %                          10,22
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,45
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          67,88
    Mem Busy                                                                             %                          31,57
    Max Bandwidth                                                                        %                          39,66
    L1/TEX Hit Rate                                                                      %                          87,94
    L2 Hit Rate                                                                          %                          63,17
    Mem Pipes Busy                                                                       %                          20,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,32
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,68
    Active Warps Per Scheduler                                                        warp                           5,51
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.7 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.51 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,43
    Warp Cycles Per Executed Instruction                                             cycle                          55,63
    Warp Cycles Per Issue Active                                                      warp                          53,43
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 33.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.3% of the total average of 53.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 21.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,04
    Achieved Active Warps Per SM                                                      warp                          22,09
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:43, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,31
    SM Frequency                                                             cycle/nsecond                           1,22
    Elapsed Cycles                                                                   cycle                          5.610
    Memory [%]                                                                           %                          26,13
    SOL DRAM                                                                             %                          26,13
    Duration                                                                       usecond                           4,61
    SOL L1/TEX Cache                                                                     %                          22,75
    SOL L2 Cache                                                                         %                          18,07
    SM Active Cycles                                                                 cycle                       4.249,29
    SM [%]                                                                               %                          13,70
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,61
    Issued Ipc Active                                                           inst/cycle                           0,34
    SM Busy                                                                              %                           8,61
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,67
    Mem Busy                                                                             %                          18,07
    Max Bandwidth                                                                        %                          26,13
    L1/TEX Hit Rate                                                                      %                          75,82
    L2 Hit Rate                                                                          %                          23,14
    Mem Pipes Busy                                                                       %                          13,70
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,21
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,79
    Active Warps Per Scheduler                                                        warp                           5,58
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.2 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.58 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          67,94
    Warp Cycles Per Executed Instruction                                             cycle                          70,65
    Warp Cycles Per Issue Active                                                      warp                          67,94
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 62.6% of the total average of 67.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.9%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,22
    Achieved Active Warps Per SM                                                      warp                          22,15
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:44, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,52
    Elapsed Cycles                                                                   cycle                      2.790.943
    Memory [%]                                                                           %                          21,44
    SOL DRAM                                                                             %                           1,89
    Duration                                                                       msecond                           1,83
    SOL L1/TEX Cache                                                                     %                          42,89
    SOL L2 Cache                                                                         %                           9,02
    SM Active Cycles                                                                 cycle                   2.660.778,29
    SM [%]                                                                               %                          56,71
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,37
    Executed Ipc Elapsed                                                        inst/cycle                           2,27
    Issue Slots Busy                                                                     %                          59,35
    Issued Ipc Active                                                           inst/cycle                           2,37
    SM Busy                                                                              %                          59,35
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,61
    Mem Busy                                                                             %                          21,44
    Max Bandwidth                                                                        %                          18,94
    L1/TEX Hit Rate                                                                      %                          94,59
    L2 Hit Rate                                                                          %                          87,50
    Mem Pipes Busy                                                                       %                          18,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          64,45
    Issued Warp Per Scheduler                                                                                        0,64
    No Eligible                                                                          %                          35,55
    Active Warps Per Scheduler                                                        warp                           7,36
    Eligible Warps Per Scheduler                                                      warp                           1,33
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,42
    Warp Cycles Per Executed Instruction                                             cycle                          11,42
    Warp Cycles Per Issue Active                                                      warp                          11,42
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 4.5 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 39.3% of the total average of 11.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.579.264
    Executed Instructions                                                             inst                     88.438.784
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.300,91
    Issued Instructions                                                               inst                     88.440.851
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          87,36
    Achieved Active Warps Per SM                                                      warp                          27,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:44, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        297.519
    Memory [%]                                                                           %                           7,71
    SOL DRAM                                                                             %                           2,84
    Duration                                                                       usecond                         213,66
    SOL L1/TEX Cache                                                                     %                           7,35
    SOL L2 Cache                                                                         %                           7,71
    SM Active Cycles                                                                 cycle                     292.742,14
    SM [%]                                                                               %                          85,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,24
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,90
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.9%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           5,43
    Mem Busy                                                                             %                           5,84
    Max Bandwidth                                                                        %                           7,71
    L1/TEX Hit Rate                                                                      %                          87,77
    L2 Hit Rate                                                                          %                          82,28
    Mem Pipes Busy                                                                       %                          22,27
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,25
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,75
    Active Warps Per Scheduler                                                        warp                           6,32
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.32 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,96
    Warp Cycles Per Executed Instruction                                             cycle                         149,14
    Warp Cycles Per Issue Active                                                      warp                         148,96
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        26,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 97.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.3% of the total average of 149.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      12.391,25
    Executed Instructions                                                             inst                        693.910
    Avg. Issued Instructions Per Scheduler                                            inst                      12.406,25
    Issued Instructions                                                               inst                        694.750
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          79,13
    Achieved Active Warps Per SM                                                      warp                          25,32
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:44, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,30
    Elapsed Cycles                                                                   cycle                         20.149
    Memory [%]                                                                           %                          46,59
    SOL DRAM                                                                             %                          46,59
    Duration                                                                       usecond                          15,49
    SOL L1/TEX Cache                                                                     %                          54,05
    SOL L2 Cache                                                                         %                          45,00
    SM Active Cycles                                                                 cycle                      18.911,36
    SM [%]                                                                               %                          30,55
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,43
    Executed Ipc Elapsed                                                        inst/cycle                           0,41
    Issue Slots Busy                                                                     %                          10,94
    Issued Ipc Active                                                           inst/cycle                           0,44
    SM Busy                                                                              %                          12,63
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          85,75
    Mem Busy                                                                             %                          45,00
    Max Bandwidth                                                                        %                          46,59
    L1/TEX Hit Rate                                                                      %                          87,91
    L2 Hit Rate                                                                          %                          62,83
    Mem Pipes Busy                                                                       %                          30,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          11,35
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          88,65
    Active Warps Per Scheduler                                                        warp                           5,72
    Eligible Warps Per Scheduler                                                      warp                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 8.8 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.72 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          50,41
    Warp Cycles Per Executed Instruction                                             cycle                          50,92
    Warp Cycles Per Issue Active                                                      warp                          50,41
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 37.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 73.6% of the total average of 50.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          2.048
    Executed Instructions                                                             inst                        114.688
    Avg. Issued Instructions Per Scheduler                                            inst                          2.069
    Issued Instructions                                                               inst                        115.864
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,35
    Achieved Active Warps Per SM                                                      warp                          22,51
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:45, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         21.868
    Memory [%]                                                                           %                          63,21
    SOL DRAM                                                                             %                          63,21
    Duration                                                                       usecond                          16,67
    SOL L1/TEX Cache                                                                     %                          55,21
    SOL L2 Cache                                                                         %                          55,52
    SM Active Cycles                                                                 cycle                      20.244,43
    SM [%]                                                                               %                          23,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,38
    Executed Ipc Elapsed                                                        inst/cycle                           0,35
    Issue Slots Busy                                                                     %                           9,55
    Issued Ipc Active                                                           inst/cycle                           0,38
    SM Busy                                                                              %                          10,12
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                         116,15
    Mem Busy                                                                             %                          55,52
    Max Bandwidth                                                                        %                          63,21
    L1/TEX Hit Rate                                                                      %                          83,83
    L2 Hit Rate                                                                          %                          53,29
    Mem Pipes Busy                                                                       %                          23,47
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,22
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,78
    Active Warps Per Scheduler                                                        warp                           5,53
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.53 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          59,97
    Warp Cycles Per Executed Instruction                                             cycle                          60,40
    Warp Cycles Per Issue Active                                                      warp                          59,97
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 75.8% of the total average of 60.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.920
    Executed Instructions                                                             inst                        107.520
    Avg. Issued Instructions Per Scheduler                                            inst                          1.934
    Issued Instructions                                                               inst                        108.304
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          72,03
    Achieved Active Warps Per SM                                                      warp                          23,05
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:45, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         15.749
    Memory [%]                                                                           %                          36,32
    SOL DRAM                                                                             %                          36,32
    Duration                                                                       usecond                             12
    SOL L1/TEX Cache                                                                     %                          32,49
    SOL L2 Cache                                                                         %                          21,55
    SM Active Cycles                                                                 cycle                      14.207,86
    SM [%]                                                                               %                          19,55
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,40
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                          10,01
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                          10,01
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          66,94
    Mem Busy                                                                             %                          21,55
    Max Bandwidth                                                                        %                          36,32
    L1/TEX Hit Rate                                                                      %                          75,74
    L2 Hit Rate                                                                          %                           9,46
    Mem Pipes Busy                                                                       %                          19,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,98
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          90,02
    Active Warps Per Scheduler                                                        warp                           5,32
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.32 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,24
    Warp Cycles Per Executed Instruction                                             cycle                          53,77
    Warp Cycles Per Issue Active                                                      warp                          53,24
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 40.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.6% of the total average of 53.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.408
    Executed Instructions                                                             inst                         78.848
    Avg. Issued Instructions Per Scheduler                                            inst                          1.422
    Issued Instructions                                                               inst                         79.632
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,69
    Achieved Active Warps Per SM                                                      warp                          21,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:45, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      3.169.301
    Memory [%]                                                                           %                          19,36
    SOL DRAM                                                                             %                           0,97
    Duration                                                                       msecond                           2,28
    SOL L1/TEX Cache                                                                     %                          38,73
    SOL L2 Cache                                                                         %                           8,02
    SM Active Cycles                                                                 cycle                   3.514.465,86
    SM [%]                                                                               %                          49,80
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,79
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          44,80
    Issued Ipc Active                                                           inst/cycle                           1,79
    SM Busy                                                                              %                          44,80
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,86
    Mem Busy                                                                             %                          19,36
    Max Bandwidth                                                                        %                          16,80
    L1/TEX Hit Rate                                                                      %                          94,24
    L2 Hit Rate                                                                          %                          96,25
    Mem Pipes Busy                                                                       %                          16,61
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          49,90
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          50,10
    Active Warps Per Scheduler                                                        warp                           6,48
    Eligible Warps Per Scheduler                                                      warp                           0,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.48 active warps per scheduler, but only an average of 0.97 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,98
    Warp Cycles Per Executed Instruction                                             cycle                          12,98
    Warp Cycles Per Issue Active                                                      warp                          12,98
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 7.5 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 58.1% of the total average of 13.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.574.464
    Executed Instructions                                                             inst                     88.169.984
    Avg. Issued Instructions Per Scheduler                                            inst                   1.574.501,30
    Issued Instructions                                                               inst                     88.172.073
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          80,51
    Achieved Active Warps Per SM                                                      warp                          25,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:46, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.242
    Memory [%]                                                                           %                           6,49
    SOL DRAM                                                                             %                           1,88
    Duration                                                                       usecond                          56,67
    SOL L1/TEX Cache                                                                     %                           6,90
    SOL L2 Cache                                                                         %                           6,49
    SM Active Cycles                                                                 cycle                      73.755,50
    SM [%]                                                                               %                          81,30
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,58
    Mem Busy                                                                             %                           6,22
    Max Bandwidth                                                                        %                           6,49
    L1/TEX Hit Rate                                                                      %                          87,87
    L2 Hit Rate                                                                          %                          72,94
    Mem Pipes Busy                                                                       %                          21,15
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,23
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,77
    Active Warps Per Scheduler                                                        warp                           6,25
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.25 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,75
    Warp Cycles Per Executed Instruction                                             cycle                         148,47
    Warp Cycles Per Issue Active                                                      warp                         147,75
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.4% of the total average of 147.7  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,56
    Achieved Active Warps Per SM                                                      warp                          24,82
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:46, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,24
    Elapsed Cycles                                                                   cycle                          6.464
    Memory [%]                                                                           %                          34,85
    SOL DRAM                                                                             %                          21,00
    Duration                                                                       usecond                           5,22
    SOL L1/TEX Cache                                                                     %                          41,96
    SOL L2 Cache                                                                         %                          34,85
    SM Active Cycles                                                                 cycle                       5.144,71
    SM [%]                                                                               %                          23,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,40
    Executed Ipc Elapsed                                                        inst/cycle                           0,32
    Issue Slots Busy                                                                     %                          10,36
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,61
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          38,92
    Mem Busy                                                                             %                          34,85
    Max Bandwidth                                                                        %                          29,51
    L1/TEX Hit Rate                                                                      %                          87,94
    L2 Hit Rate                                                                          %                          63,86
    Mem Pipes Busy                                                                       %                          23,79
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,66
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,34
    Active Warps Per Scheduler                                                        warp                           5,68
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.4 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.68 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,30
    Warp Cycles Per Executed Instruction                                             cycle                          55,49
    Warp Cycles Per Issue Active                                                      warp                          53,30
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 32.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 61.4% of the total average of 53.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 21.4%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,76
    Achieved Active Warps Per SM                                                      warp                          22,00
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:46, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,21
    Elapsed Cycles                                                                   cycle                          5.603
    Memory [%]                                                                           %                          22,34
    SOL DRAM                                                                             %                          22,34
    Duration                                                                       usecond                           4,61
    SOL L1/TEX Cache                                                                     %                          22,80
    SOL L2 Cache                                                                         %                          15,62
    SM Active Cycles                                                                 cycle                       4.238,71
    SM [%]                                                                               %                          13,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,63
    Issued Ipc Active                                                           inst/cycle                           0,35
    SM Busy                                                                              %                           8,63
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,69
    Mem Busy                                                                             %                          15,41
    Max Bandwidth                                                                        %                          22,34
    L1/TEX Hit Rate                                                                      %                          75,84
    L2 Hit Rate                                                                          %                          12,36
    Mem Pipes Busy                                                                       %                          13,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,70
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,30
    Active Warps Per Scheduler                                                        warp                           5,35
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.35 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          61,52
    Warp Cycles Per Executed Instruction                                             cycle                          63,96
    Warp Cycles Per Issue Active                                                      warp                          61,52
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 68.7% of the total average of 61.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,53
    Achieved Active Warps Per SM                                                      warp                          22,25
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:47, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      2.481.471
    Memory [%]                                                                           %                          47,71
    SOL DRAM                                                                             %                           0,78
    Duration                                                                       msecond                           1,80
    SOL L1/TEX Cache                                                                     %                          88,94
    SOL L2 Cache                                                                         %                           3,85
    SM Active Cycles                                                                 cycle                   2.517.571,43
    SM [%]                                                                               %                          60,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 5% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,39
    Executed Ipc Elapsed                                                        inst/cycle                           2,43
    Issue Slots Busy                                                                     %                          59,64
    Issued Ipc Active                                                           inst/cycle                           2,39
    SM Busy                                                                              %                          59,64
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,49
    Mem Busy                                                                             %                          44,47
    Max Bandwidth                                                                        %                          47,71
    L1/TEX Hit Rate                                                                      %                          98,83
    L2 Hit Rate                                                                          %                          94,15
    Mem Pipes Busy                                                                       %                          47,71
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          61,83
    Issued Warp Per Scheduler                                                                                        0,62
    No Eligible                                                                          %                          38,17
    Active Warps Per Scheduler                                                        warp                           6,61
    Eligible Warps Per Scheduler                                                      warp                           1,35
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,69
    Warp Cycles Per Executed Instruction                                             cycle                          10,69
    Warp Cycles Per Issue Active                                                      warp                          10,69
    Avg. Active Threads Per Warp                                                                                    26,59
    Avg. Not Predicated Off Threads Per Warp                                                                        24,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 3.8 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 35.4% of the total average of 10.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.501.568
    Executed Instructions                                                             inst                     84.087.808
    Avg. Issued Instructions Per Scheduler                                            inst                   1.501.604,88
    Issued Instructions                                                               inst                     84.089.873
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          81,64
    Achieved Active Warps Per SM                                                      warp                          26,13
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4915200 transactions, got 18251776 (3.71x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4915200 transactions, got 17399808 (3.54x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4259840 transactions, got 16089088 (3.78x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:47, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.136
    Memory [%]                                                                           %                           8,42
    SOL DRAM                                                                             %                           1,88
    Duration                                                                       usecond                          56,54
    SOL L1/TEX Cache                                                                     %                           6,90
    SOL L2 Cache                                                                         %                           8,42
    SM Active Cycles                                                                 cycle                      73.781,86
    SM [%]                                                                               %                          81,40
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,59
    Mem Busy                                                                             %                           8,42
    Max Bandwidth                                                                        %                           6,54
    L1/TEX Hit Rate                                                                      %                          87,90
    L2 Hit Rate                                                                          %                          54,53
    Mem Pipes Busy                                                                       %                          21,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,23
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,77
    Active Warps Per Scheduler                                                        warp                           6,27
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.27 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,03
    Warp Cycles Per Executed Instruction                                             cycle                         148,75
    Warp Cycles Per Issue Active                                                      warp                         148,03
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.2% of the total average of 148.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,45
    Achieved Active Warps Per SM                                                      warp                          24,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:47, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,27
    SM Frequency                                                             cycle/nsecond                           1,25
    Elapsed Cycles                                                                   cycle                          6.810
    Memory [%]                                                                           %                          33,14
    SOL DRAM                                                                             %                          22,97
    Duration                                                                       usecond                           5,44
    SOL L1/TEX Cache                                                                     %                          40,17
    SOL L2 Cache                                                                         %                          33,14
    SM Active Cycles                                                                 cycle                       5.156,79
    SM [%]                                                                               %                          22,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,40
    Executed Ipc Elapsed                                                        inst/cycle                           0,30
    Issue Slots Busy                                                                     %                          10,34
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,58
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,36
    Mem Busy                                                                             %                          33,14
    Max Bandwidth                                                                        %                          29,65
    L1/TEX Hit Rate                                                                      %                          88,17
    L2 Hit Rate                                                                          %                          65,68
    Mem Pipes Busy                                                                       %                          22,57
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,31
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,69
    Active Warps Per Scheduler                                                        warp                           5,54
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.7 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.54 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,75
    Warp Cycles Per Executed Instruction                                             cycle                          55,95
    Warp Cycles Per Issue Active                                                      warp                          53,75
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 34.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.9% of the total average of 53.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,50
    Achieved Active Warps Per SM                                                      warp                          22,56
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:47, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,17
    SM Frequency                                                             cycle/nsecond                           1,06
    Elapsed Cycles                                                                   cycle                          5.562
    Memory [%]                                                                           %                          25,54
    SOL DRAM                                                                             %                          25,54
    Duration                                                                       usecond                           5,25
    SOL L1/TEX Cache                                                                     %                          22,94
    SOL L2 Cache                                                                         %                          15,56
    SM Active Cycles                                                                 cycle                       4.250,43
    SM [%]                                                                               %                          13,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,61
    Issued Ipc Active                                                           inst/cycle                           0,34
    SM Busy                                                                              %                           8,61
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          38,27
    Mem Busy                                                                             %                          15,56
    Max Bandwidth                                                                        %                          25,54
    L1/TEX Hit Rate                                                                      %                          75,82
    L2 Hit Rate                                                                          %                          12,18
    Mem Pipes Busy                                                                       %                          13,81
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,37
    Issued Warp Per Scheduler                                                                                        0,07
    No Eligible                                                                          %                          92,63
    Active Warps Per Scheduler                                                        warp                           4,70
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.70 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          63,76
    Warp Cycles Per Executed Instruction                                             cycle                          66,29
    Warp Cycles Per Issue Active                                                      warp                          63,76
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 66.9% of the total average of 63.8   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,79
    Achieved Active Warps Per SM                                                      warp                          22,33
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:48, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      2.533.747
    Memory [%]                                                                           %                          23,92
    SOL DRAM                                                                             %                           0,49
    Duration                                                                       msecond                           1,83
    SOL L1/TEX Cache                                                                     %                          47,85
    SOL L2 Cache                                                                         %                           9,88
    SM Active Cycles                                                                 cycle                   2.450.833,86
    SM [%]                                                                               %                          62,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,58
    Executed Ipc Elapsed                                                        inst/cycle                           2,50
    Issue Slots Busy                                                                     %                          64,44
    Issued Ipc Active                                                           inst/cycle                           2,58
    SM Busy                                                                              %                          64,44
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Mbyte/second                         938,63
    Mem Busy                                                                             %                          23,92
    Max Bandwidth                                                                        %                          20,86
    L1/TEX Hit Rate                                                                      %                          94,57
    L2 Hit Rate                                                                          %                          87,91
    Mem Pipes Busy                                                                       %                          20,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          64,46
    Issued Warp Per Scheduler                                                                                        0,64
    No Eligible                                                                          %                          35,54
    Active Warps Per Scheduler                                                        warp                           7,34
    Eligible Warps Per Scheduler                                                      warp                           1,33
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,38
    Warp Cycles Per Executed Instruction                                             cycle                          11,38
    Warp Cycles Per Issue Active                                                      warp                          11,38
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 3.5 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 30.5% of the total average of 11.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.579.264
    Executed Instructions                                                             inst                     88.438.784
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.300,84
    Issued Instructions                                                               inst                     88.440.847
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          87,39
    Achieved Active Warps Per SM                                                      warp                          27,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:48, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        297.340
    Memory [%]                                                                           %                           6,90
    SOL DRAM                                                                             %                           4,85
    Duration                                                                       usecond                         213,73
    SOL L1/TEX Cache                                                                     %                           7,36
    SOL L2 Cache                                                                         %                           6,90
    SM Active Cycles                                                                 cycle                     292.634,57
    SM [%]                                                                               %                          85,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,24
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,93
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.9%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           9,28
    Mem Busy                                                                             %                           5,83
    Max Bandwidth                                                                        %                           6,90
    L1/TEX Hit Rate                                                                      %                          87,77
    L2 Hit Rate                                                                          %                          82,67
    Mem Pipes Busy                                                                       %                          22,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,25
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,75
    Active Warps Per Scheduler                                                        warp                           6,33
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.33 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         149,05
    Warp Cycles Per Executed Instruction                                             cycle                         149,23
    Warp Cycles Per Issue Active                                                      warp                         149,05
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        26,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 97.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.2% of the total average of 149.1  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      12.391,25
    Executed Instructions                                                             inst                        693.910
    Avg. Issued Instructions Per Scheduler                                            inst                      12.406,25
    Issued Instructions                                                               inst                        694.750
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          78,82
    Achieved Active Warps Per SM                                                      warp                          25,22
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:48, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,47
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         20.469
    Memory [%]                                                                           %                          42,71
    SOL DRAM                                                                             %                          38,39
    Duration                                                                       usecond                          15,55
    SOL L1/TEX Cache                                                                     %                          52,47
    SOL L2 Cache                                                                         %                          42,71
    SM Active Cycles                                                                 cycle                      18.589,64
    SM [%]                                                                               %                          30,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,44
    Executed Ipc Elapsed                                                        inst/cycle                           0,40
    Issue Slots Busy                                                                     %                          11,13
    Issued Ipc Active                                                           inst/cycle                           0,45
    SM Busy                                                                              %                          12,85
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          72,40
    Mem Busy                                                                             %                          42,71
    Max Bandwidth                                                                        %                          38,39
    L1/TEX Hit Rate                                                                      %                          87,89
    L2 Hit Rate                                                                          %                          66,62
    Mem Pipes Busy                                                                       %                          30,08
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          11,06
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          88,94
    Active Warps Per Scheduler                                                        warp                           6,40
    Eligible Warps Per Scheduler                                                      warp                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.40 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          57,89
    Warp Cycles Per Executed Instruction                                             cycle                          58,49
    Warp Cycles Per Issue Active                                                      warp                          57,89
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 37.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.8% of the total average of 57.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          2.048
    Executed Instructions                                                             inst                        114.688
    Avg. Issued Instructions Per Scheduler                                            inst                          2.069
    Issued Instructions                                                               inst                        115.864
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          71,15
    Achieved Active Warps Per SM                                                      warp                          22,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:49, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,39
    SM Frequency                                                             cycle/nsecond                           1,28
    Elapsed Cycles                                                                   cycle                         21.513
    Memory [%]                                                                           %                          64,94
    SOL DRAM                                                                             %                          64,94
    Duration                                                                       usecond                          16,70
    SOL L1/TEX Cache                                                                     %                          56,20
    SOL L2 Cache                                                                         %                          56,22
    SM Active Cycles                                                                 cycle                      20.353,21
    SM [%]                                                                               %                          23,86
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,38
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                           9,50
    Issued Ipc Active                                                           inst/cycle                           0,38
    SM Busy                                                                              %                          10,06
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                         115,92
    Mem Busy                                                                             %                          56,22
    Max Bandwidth                                                                        %                          64,94
    L1/TEX Hit Rate                                                                      %                          83,83
    L2 Hit Rate                                                                          %                          54,61
    Mem Pipes Busy                                                                       %                          23,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,29
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,71
    Active Warps Per Scheduler                                                        warp                           5,42
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.42 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          58,39
    Warp Cycles Per Executed Instruction                                             cycle                          58,81
    Warp Cycles Per Issue Active                                                      warp                          58,39
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 77.0% of the total average of 58.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.920
    Executed Instructions                                                             inst                        107.520
    Avg. Issued Instructions Per Scheduler                                            inst                          1.934
    Issued Instructions                                                               inst                        108.304
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          71,62
    Achieved Active Warps Per SM                                                      warp                          22,92
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:49, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,29
    Elapsed Cycles                                                                   cycle                         15.762
    Memory [%]                                                                           %                          34,28
    SOL DRAM                                                                             %                          34,28
    Duration                                                                       usecond                          12,16
    SOL L1/TEX Cache                                                                     %                          32,45
    SOL L2 Cache                                                                         %                          21,51
    SM Active Cycles                                                                 cycle                      14.187,50
    SM [%]                                                                               %                          19,53
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,40
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                          10,02
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                          10,02
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          66,05
    Mem Busy                                                                             %                          21,51
    Max Bandwidth                                                                        %                          34,28
    L1/TEX Hit Rate                                                                      %                          75,73
    L2 Hit Rate                                                                          %                          11,47
    Mem Pipes Busy                                                                       %                          19,53
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,95
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,05
    Active Warps Per Scheduler                                                        warp                           4,30
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.30 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          54,10
    Warp Cycles Per Executed Instruction                                             cycle                          54,64
    Warp Cycles Per Issue Active                                                      warp                          54,10
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 40.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.9% of the total average of 54.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.408
    Executed Instructions                                                             inst                         78.848
    Avg. Issued Instructions Per Scheduler                                            inst                          1.422
    Issued Instructions                                                               inst                         79.632
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,21
    Achieved Active Warps Per SM                                                      warp                          21,83
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:49, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      3.167.568
    Memory [%]                                                                           %                          19,40
    SOL DRAM                                                                             %                           2,47
    Duration                                                                       msecond                           2,29
    SOL L1/TEX Cache                                                                     %                          38,80
    SOL L2 Cache                                                                         %                           8,26
    SM Active Cycles                                                                 cycle                   3.151.519,93
    SM [%]                                                                               %                          49,82
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,00
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          49,96
    Issued Ipc Active                                                           inst/cycle                           2,00
    SM Busy                                                                              %                          49,96
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,75
    Mem Busy                                                                             %                          19,40
    Max Bandwidth                                                                        %                          16,83
    L1/TEX Hit Rate                                                                      %                          94,25
    L2 Hit Rate                                                                          %                          91,02
    Mem Pipes Busy                                                                       %                          16,61
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          49,93
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          50,07
    Active Warps Per Scheduler                                                        warp                           6,50
    Eligible Warps Per Scheduler                                                      warp                           0,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.50 active warps per scheduler, but only an average of 0.97 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          13,01
    Warp Cycles Per Executed Instruction                                             cycle                          13,01
    Warp Cycles Per Issue Active                                                      warp                          13,01
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 5.9 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 45.7% of the total average of 13.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.574.464
    Executed Instructions                                                             inst                     88.169.984
    Avg. Issued Instructions Per Scheduler                                            inst                   1.574.500,82
    Issued Instructions                                                               inst                     88.172.046
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          81,00
    Achieved Active Warps Per SM                                                      warp                          25,92
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:50, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.527
    Memory [%]                                                                           %                           6,51
    SOL DRAM                                                                             %                           1,88
    Duration                                                                       usecond                          56,74
    SOL L1/TEX Cache                                                                     %                           6,90
    SOL L2 Cache                                                                         %                           6,51
    SM Active Cycles                                                                 cycle                      73.850,43
    SM [%]                                                                               %                          80,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.0%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,58
    Mem Busy                                                                             %                           5,47
    Max Bandwidth                                                                        %                           6,51
    L1/TEX Hit Rate                                                                      %                          87,93
    L2 Hit Rate                                                                          %                          83,17
    Mem Pipes Busy                                                                       %                          21,07
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,24
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,76
    Active Warps Per Scheduler                                                        warp                           6,26
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.26 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,50
    Warp Cycles Per Executed Instruction                                             cycle                         148,49
    Warp Cycles Per Issue Active                                                      warp                         147,50
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.5% of the total average of 147.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                       3.104,62
    Issued Instructions                                                               inst                        173.859
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,69
    Achieved Active Warps Per SM                                                      warp                          24,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:50, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,33
    SM Frequency                                                             cycle/nsecond                           1,22
    Elapsed Cycles                                                                   cycle                          6.667
    Memory [%]                                                                           %                          34,09
    SOL DRAM                                                                             %                          21,75
    Duration                                                                       usecond                           5,47
    SOL L1/TEX Cache                                                                     %                          40,48
    SOL L2 Cache                                                                         %                          34,09
    SM Active Cycles                                                                 cycle                       5.256,21
    SM [%]                                                                               %                          23,06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,31
    Issue Slots Busy                                                                     %                          10,14
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,36
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,12
    Mem Busy                                                                             %                          34,09
    Max Bandwidth                                                                        %                          27,85
    L1/TEX Hit Rate                                                                      %                          87,96
    L2 Hit Rate                                                                          %                          69,94
    Mem Pipes Busy                                                                       %                          23,06
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,90
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          90,10
    Active Warps Per Scheduler                                                        warp                           5,22
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.22 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,73
    Warp Cycles Per Executed Instruction                                             cycle                          54,89
    Warp Cycles Per Issue Active                                                      warp                          52,73
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 33.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.3% of the total average of 52.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 22.0%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,24
    Achieved Active Warps Per SM                                                      warp                          21,84
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:50, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,26
    Elapsed Cycles                                                                   cycle                          5.875
    Memory [%]                                                                           %                          24,11
    SOL DRAM                                                                             %                          24,11
    Duration                                                                       usecond                           4,64
    SOL L1/TEX Cache                                                                     %                          21,74
    SOL L2 Cache                                                                         %                          16,31
    SM Active Cycles                                                                 cycle                       4.246,29
    SM [%]                                                                               %                          13,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,24
    Issue Slots Busy                                                                     %                           8,62
    Issued Ipc Active                                                           inst/cycle                           0,34
    SM Busy                                                                              %                           8,62
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          45,97
    Mem Busy                                                                             %                          15,80
    Max Bandwidth                                                                        %                          24,11
    L1/TEX Hit Rate                                                                      %                          75,83
    L2 Hit Rate                                                                          %                          11,10
    Mem Pipes Busy                                                                       %                          13,09
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,64
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,36
    Active Warps Per Scheduler                                                        warp                           5,70
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.70 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          65,97
    Warp Cycles Per Executed Instruction                                             cycle                          68,59
    Warp Cycles Per Issue Active                                                      warp                          65,97
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 66.2% of the total average of 66.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,47
    Achieved Active Warps Per SM                                                      warp                          22,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:51, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      2.477.250
    Memory [%]                                                                           %                          47,78
    SOL DRAM                                                                             %                           0,80
    Duration                                                                       msecond                           1,81
    SOL L1/TEX Cache                                                                     %                          89,21
    SOL L2 Cache                                                                         %                           3,76
    SM Active Cycles                                                                 cycle                   2.703.314,43
    SM [%]                                                                               %                          60,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 5% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,22
    Executed Ipc Elapsed                                                        inst/cycle                           2,43
    Issue Slots Busy                                                                     %                          55,55
    Issued Ipc Active                                                           inst/cycle                           2,22
    SM Busy                                                                              %                          55,55
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,53
    Mem Busy                                                                             %                          44,60
    Max Bandwidth                                                                        %                          47,78
    L1/TEX Hit Rate                                                                      %                          98,84
    L2 Hit Rate                                                                          %                          93,78
    Mem Pipes Busy                                                                       %                          47,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          61,86
    Issued Warp Per Scheduler                                                                                        0,62
    No Eligible                                                                          %                          38,14
    Active Warps Per Scheduler                                                        warp                           6,61
    Eligible Warps Per Scheduler                                                      warp                           1,35
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,68
    Warp Cycles Per Executed Instruction                                             cycle                          10,68
    Warp Cycles Per Issue Active                                                      warp                          10,68
    Avg. Active Threads Per Warp                                                                                    26,59
    Avg. Not Predicated Off Threads Per Warp                                                                        24,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 4.6 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 43.2% of the total average of 10.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.501.568
    Executed Instructions                                                             inst                     84.087.808
    Avg. Issued Instructions Per Scheduler                                            inst                   1.501.604,73
    Issued Instructions                                                               inst                     84.089.865
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          81,86
    Achieved Active Warps Per SM                                                      warp                          26,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4915200 transactions, got 18251776 (3.71x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4915200 transactions, got 17399808 (3.54x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4259840 transactions, got 16089088 (3.78x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:51, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.348
    Memory [%]                                                                           %                           8,49
    SOL DRAM                                                                             %                           5,38
    Duration                                                                       usecond                          56,54
    SOL L1/TEX Cache                                                                     %                           6,92
    SOL L2 Cache                                                                         %                           8,49
    SM Active Cycles                                                                 cycle                      73.942,21
    SM [%]                                                                               %                          81,23
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,19
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,93
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.9%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          10,24
    Mem Busy                                                                             %                           6,63
    Max Bandwidth                                                                        %                           8,49
    L1/TEX Hit Rate                                                                      %                          87,91
    L2 Hit Rate                                                                          %                          68,87
    Mem Pipes Busy                                                                       %                          21,13
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,23
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,77
    Active Warps Per Scheduler                                                        warp                           6,28
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.28 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,36
    Warp Cycles Per Executed Instruction                                             cycle                         149,09
    Warp Cycles Per Issue Active                                                      warp                         148,36
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 94.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.8% of the total average of 148.4  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,42
    Achieved Active Warps Per SM                                                      warp                          24,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:51, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,23
    Elapsed Cycles                                                                   cycle                          6.436
    Memory [%]                                                                           %                          35,15
    SOL DRAM                                                                             %                          21,78
    Duration                                                                       usecond                           5,22
    SOL L1/TEX Cache                                                                     %                          42,76
    SOL L2 Cache                                                                         %                          35,15
    SM Active Cycles                                                                 cycle                       5.292,50
    SM [%]                                                                               %                          23,89
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,32
    Issue Slots Busy                                                                     %                          10,07
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                          11,29
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          38,99
    Mem Busy                                                                             %                          35,15
    Max Bandwidth                                                                        %                          29,76
    L1/TEX Hit Rate                                                                      %                          87,93
    L2 Hit Rate                                                                          %                          66,81
    Mem Pipes Busy                                                                       %                          23,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,36
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,64
    Active Warps Per Scheduler                                                        warp                           5,58
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.58 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,83
    Warp Cycles Per Executed Instruction                                             cycle                          56,03
    Warp Cycles Per Issue Active                                                      warp                          53,83
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 35.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.0% of the total average of 53.8   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,31
    Achieved Active Warps Per SM                                                      warp                          22,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:51, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,58
    SM Frequency                                                             cycle/nsecond                           1,23
    Elapsed Cycles                                                                   cycle                          5.668
    Memory [%]                                                                           %                          21,52
    SOL DRAM                                                                             %                          21,52
    Duration                                                                       usecond                           4,61
    SOL L1/TEX Cache                                                                     %                          22,53
    SOL L2 Cache                                                                         %                          15,24
    SM Active Cycles                                                                 cycle                       4.163,71
    SM [%]                                                                               %                          13,56
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,34
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,79
    Issued Ipc Active                                                           inst/cycle                           0,35
    SM Busy                                                                              %                           8,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,60
    Mem Busy                                                                             %                          15,24
    Max Bandwidth                                                                        %                          21,52
    L1/TEX Hit Rate                                                                      %                          75,89
    L2 Hit Rate                                                                          %                          13,60
    Mem Pipes Busy                                                                       %                          13,56
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,83
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,17
    Active Warps Per Scheduler                                                        warp                           5,50
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.3 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.50 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          62,28
    Warp Cycles Per Executed Instruction                                             cycle                          64,76
    Warp Cycles Per Issue Active                                                      warp                          62,28
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 41.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 67.2% of the total average of 62.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,87
    Achieved Active Warps Per SM                                                      warp                          22,36
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:52, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,86
    Elapsed Cycles                                                                   cycle                      3.421.218
    Memory [%]                                                                           %                          17,49
    SOL DRAM                                                                             %                           4,20
    Duration                                                                       msecond                           1,83
    SOL L1/TEX Cache                                                                     %                          34,98
    SOL L2 Cache                                                                         %                           6,53
    SM Active Cycles                                                                 cycle                   2.450.469,50
    SM [%]                                                                               %                          46,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,58
    Executed Ipc Elapsed                                                        inst/cycle                           1,85
    Issue Slots Busy                                                                     %                          64,45
    Issued Ipc Active                                                           inst/cycle                           2,58
    SM Busy                                                                              %                          64,45
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           8,04
    Mem Busy                                                                             %                          17,49
    Max Bandwidth                                                                        %                          15,45
    L1/TEX Hit Rate                                                                      %                          94,57
    L2 Hit Rate                                                                          %                          98,74
    Mem Pipes Busy                                                                       %                          15,45
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          64,47
    Issued Warp Per Scheduler                                                                                        0,64
    No Eligible                                                                          %                          35,53
    Active Warps Per Scheduler                                                        warp                           7,00
    Eligible Warps Per Scheduler                                                      warp                           1,33
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,85
    Warp Cycles Per Executed Instruction                                             cycle                          10,85
    Warp Cycles Per Issue Active                                                      warp                          10,85
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 3.5 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 32.0% of the total average of 10.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.579.264
    Executed Instructions                                                             inst                     88.438.784
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.301,38
    Issued Instructions                                                               inst                     88.440.877
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          87,39
    Achieved Active Warps Per SM                                                      warp                          27,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:52, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        297.450
    Memory [%]                                                                           %                           6,90
    SOL DRAM                                                                             %                           3,30
    Duration                                                                       usecond                         213,82
    SOL L1/TEX Cache                                                                     %                           7,37
    SOL L2 Cache                                                                         %                           6,90
    SM Active Cycles                                                                 cycle                     292.744,43
    SM [%]                                                                               %                          85,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,24
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,90
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.9%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,32
    Mem Busy                                                                             %                           5,81
    Max Bandwidth                                                                        %                           6,90
    L1/TEX Hit Rate                                                                      %                          87,78
    L2 Hit Rate                                                                          %                          82,74
    Mem Pipes Busy                                                                       %                          22,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,25
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,75
    Active Warps Per Scheduler                                                        warp                           6,33
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.33 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,99
    Warp Cycles Per Executed Instruction                                             cycle                         149,22
    Warp Cycles Per Issue Active                                                      warp                         148,99
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        26,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 97.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.2% of the total average of 149.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      12.391,25
    Executed Instructions                                                             inst                        693.910
    Avg. Issued Instructions Per Scheduler                                            inst                      12.410,36
    Issued Instructions                                                               inst                        694.980
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          79,18
    Achieved Active Warps Per SM                                                      warp                          25,34
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:52, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                         20.886
    Memory [%]                                                                           %                          42,18
    SOL DRAM                                                                             %                          40,17
    Duration                                                                       usecond                          15,52
    SOL L1/TEX Cache                                                                     %                          51,99
    SOL L2 Cache                                                                         %                          42,18
    SM Active Cycles                                                                 cycle                      19.030,50
    SM [%]                                                                               %                          29,48
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,43
    Executed Ipc Elapsed                                                        inst/cycle                           0,39
    Issue Slots Busy                                                                     %                          10,87
    Issued Ipc Active                                                           inst/cycle                           0,43
    SM Busy                                                                              %                          12,56
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          74,21
    Mem Busy                                                                             %                          42,18
    Max Bandwidth                                                                        %                          40,17
    L1/TEX Hit Rate                                                                      %                          87,91
    L2 Hit Rate                                                                          %                          69,37
    Mem Pipes Busy                                                                       %                          29,48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,97
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,03
    Active Warps Per Scheduler                                                        warp                           5,58
    Eligible Warps Per Scheduler                                                      warp                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.1 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.58 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          50,88
    Warp Cycles Per Executed Instruction                                             cycle                          51,40
    Warp Cycles Per Issue Active                                                      warp                          50,88
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 38.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.8% of the total average of 50.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          2.048
    Executed Instructions                                                             inst                        114.688
    Avg. Issued Instructions Per Scheduler                                            inst                          2.069
    Issued Instructions                                                               inst                        115.864
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          71,11
    Achieved Active Warps Per SM                                                      warp                          22,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:53, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,46
    SM Frequency                                                             cycle/nsecond                           1,36
    Elapsed Cycles                                                                   cycle                         22.458
    Memory [%]                                                                           %                          67,43
    SOL DRAM                                                                             %                          67,43
    Duration                                                                       usecond                          16,45
    SOL L1/TEX Cache                                                                     %                          54,09
    SOL L2 Cache                                                                         %                          56,38
    SM Active Cycles                                                                 cycle                      20.194,64
    SM [%]                                                                               %                          22,86
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,38
    Executed Ipc Elapsed                                                        inst/cycle                           0,34
    Issue Slots Busy                                                                     %                           9,58
    Issued Ipc Active                                                           inst/cycle                           0,38
    SM Busy                                                                              %                          10,14
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                         126,27
    Mem Busy                                                                             %                          56,38
    Max Bandwidth                                                                        %                          67,43
    L1/TEX Hit Rate                                                                      %                          83,84
    L2 Hit Rate                                                                          %                          47,17
    Mem Pipes Busy                                                                       %                          22,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,59
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          90,41
    Active Warps Per Scheduler                                                        warp                           5,86
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.86 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          61,07
    Warp Cycles Per Executed Instruction                                             cycle                          61,52
    Warp Cycles Per Issue Active                                                      warp                          61,07
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 44.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 73.1% of the total average of 61.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.920
    Executed Instructions                                                             inst                        107.520
    Avg. Issued Instructions Per Scheduler                                            inst                          1.934
    Issued Instructions                                                               inst                        108.304
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          71,76
    Achieved Active Warps Per SM                                                      warp                          22,96
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:53, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,42
    SM Frequency                                                             cycle/nsecond                           1,29
    Elapsed Cycles                                                                   cycle                         15.573
    Memory [%]                                                                           %                          36,72
    SOL DRAM                                                                             %                          36,72
    Duration                                                                       usecond                          12,03
    SOL L1/TEX Cache                                                                     %                          32,86
    SOL L2 Cache                                                                         %                          21,79
    SM Active Cycles                                                                 cycle                      14.271,43
    SM [%]                                                                               %                          19,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                           9,96
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                           9,96
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          66,75
    Mem Busy                                                                             %                          21,79
    Max Bandwidth                                                                        %                          36,72
    L1/TEX Hit Rate                                                                      %                          75,73
    L2 Hit Rate                                                                          %                          10,39
    Mem Pipes Busy                                                                       %                          19,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,04
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,96
    Active Warps Per Scheduler                                                        warp                           4,27
    Eligible Warps Per Scheduler                                                      warp                           0,09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.27 active warps per scheduler, but only an average of 0.09 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,15
    Warp Cycles Per Executed Instruction                                             cycle                          53,68
    Warp Cycles Per Issue Active                                                      warp                          53,15
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 40.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.9% of the total average of 53.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.408
    Executed Instructions                                                             inst                         78.848
    Avg. Issued Instructions Per Scheduler                                            inst                          1.422
    Issued Instructions                                                               inst                         79.632
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,47
    Achieved Active Warps Per SM                                                      warp                          21,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:53, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,36
    SM Frequency                                                             cycle/nsecond                           1,25
    Elapsed Cycles                                                                   cycle                      3.172.024
    Memory [%]                                                                           %                          19,36
    SOL DRAM                                                                             %                           0,83
    Duration                                                                       msecond                           2,52
    SOL L1/TEX Cache                                                                     %                          38,72
    SOL L2 Cache                                                                         %                           7,48
    SM Active Cycles                                                                 cycle                   3.501.018,14
    SM [%]                                                                               %                          49,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,80
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          44,97
    Issued Ipc Active                                                           inst/cycle                           1,80
    SM Busy                                                                              %                          44,97
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,44
    Mem Busy                                                                             %                          19,36
    Max Bandwidth                                                                        %                          16,92
    L1/TEX Hit Rate                                                                      %                          94,32
    L2 Hit Rate                                                                          %                          96,23
    Mem Pipes Busy                                                                       %                          16,60
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          49,84
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          50,16
    Active Warps Per Scheduler                                                        warp                           6,47
    Eligible Warps Per Scheduler                                                      warp                           0,96
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.47 active warps per scheduler, but only an average of 0.96 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,99
    Warp Cycles Per Executed Instruction                                             cycle                          12,99
    Warp Cycles Per Issue Active                                                      warp                          12,99
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.8 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 52.7% of the total average of 13.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.574.464
    Executed Instructions                                                             inst                     88.169.984
    Avg. Issued Instructions Per Scheduler                                            inst                   1.574.500,88
    Issued Instructions                                                               inst                     88.172.049
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          78,02
    Achieved Active Warps Per SM                                                      warp                          24,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:54, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.054
    Memory [%]                                                                           %                           8,56
    SOL DRAM                                                                             %                           1,88
    Duration                                                                       usecond                          56,54
    SOL L1/TEX Cache                                                                     %                           6,94
    SOL L2 Cache                                                                         %                           8,56
    SM Active Cycles                                                                 cycle                      73.792,79
    SM [%]                                                                               %                          81,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,59
    Mem Busy                                                                             %                           5,59
    Max Bandwidth                                                                        %                           8,56
    L1/TEX Hit Rate                                                                      %                          87,88
    L2 Hit Rate                                                                          %                          81,72
    Mem Pipes Busy                                                                       %                          21,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,24
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,76
    Active Warps Per Scheduler                                                        warp                           6,26
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.26 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,89
    Warp Cycles Per Executed Instruction                                             cycle                         148,61
    Warp Cycles Per Issue Active                                                      warp                         147,89
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.4% of the total average of 147.9  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,74
    Achieved Active Warps Per SM                                                      warp                          24,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:54, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,36
    SM Frequency                                                             cycle/nsecond                           1,21
    Elapsed Cycles                                                                   cycle                          6.507
    Memory [%]                                                                           %                          37,50
    SOL DRAM                                                                             %                          21,79
    Duration                                                                       usecond                           5,38
    SOL L1/TEX Cache                                                                     %                          41,73
    SOL L2 Cache                                                                         %                          37,50
    SM Active Cycles                                                                 cycle                       5.341,57
    SM [%]                                                                               %                          23,63
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,38
    Executed Ipc Elapsed                                                        inst/cycle                           0,32
    Issue Slots Busy                                                                     %                           9,98
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                          11,18
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,85
    Mem Busy                                                                             %                          37,50
    Max Bandwidth                                                                        %                          29,62
    L1/TEX Hit Rate                                                                      %                          87,95
    L2 Hit Rate                                                                          %                          60,74
    Mem Pipes Busy                                                                       %                          23,63
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,26
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,74
    Active Warps Per Scheduler                                                        warp                           5,59
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.7 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.59 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          54,42
    Warp Cycles Per Executed Instruction                                             cycle                          56,65
    Warp Cycles Per Issue Active                                                      warp                          54,42
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 35.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.6% of the total average of 54.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,04
    Achieved Active Warps Per SM                                                      warp                          22,41
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:54, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,52
    SM Frequency                                                             cycle/nsecond                           1,45
    Elapsed Cycles                                                                   cycle                          6.983
    Memory [%]                                                                           %                          30,37
    SOL DRAM                                                                             %                          30,37
    Duration                                                                       usecond                           4,80
    SOL L1/TEX Cache                                                                     %                          18,28
    SOL L2 Cache                                                                         %                          15,18
    SM Active Cycles                                                                 cycle                          4.227
    SM [%]                                                                               %                          11,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,20
    Issue Slots Busy                                                                     %                           8,66
    Issued Ipc Active                                                           inst/cycle                           0,35
    SM Busy                                                                              %                           8,66
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          59,09
    Mem Busy                                                                             %                          12,35
    Max Bandwidth                                                                        %                          30,37
    L1/TEX Hit Rate                                                                      %                          75,81
    L2 Hit Rate                                                                          %                          13,22
    Mem Pipes Busy                                                                       %                          11,01
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,68
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,32
    Active Warps Per Scheduler                                                        warp                           5,40
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.40 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          62,28
    Warp Cycles Per Executed Instruction                                             cycle                          64,75
    Warp Cycles Per Issue Active                                                      warp                          62,28
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 67.6% of the total average of 62.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,09
    Achieved Active Warps Per SM                                                      warp                          22,43
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:55, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      2.480.743
    Memory [%]                                                                           %                          47,72
    SOL DRAM                                                                             %                           0,77
    Duration                                                                       msecond                           1,81
    SOL L1/TEX Cache                                                                     %                          88,95
    SOL L2 Cache                                                                         %                           5,12
    SM Active Cycles                                                                 cycle                   2.427.830,86
    SM [%]                                                                               %                          60,70
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 5% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,47
    Executed Ipc Elapsed                                                        inst/cycle                           2,43
    Issue Slots Busy                                                                     %                          61,85
    Issued Ipc Active                                                           inst/cycle                           2,47
    SM Busy                                                                              %                          61,85
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,49
    Mem Busy                                                                             %                          44,47
    Max Bandwidth                                                                        %                          47,72
    L1/TEX Hit Rate                                                                      %                          99,08
    L2 Hit Rate                                                                          %                          68,93
    Mem Pipes Busy                                                                       %                          47,72
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          61,83
    Issued Warp Per Scheduler                                                                                        0,62
    No Eligible                                                                          %                          38,17
    Active Warps Per Scheduler                                                        warp                           7,25
    Eligible Warps Per Scheduler                                                      warp                           1,35
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,73
    Warp Cycles Per Executed Instruction                                             cycle                          11,73
    Warp Cycles Per Issue Active                                                      warp                          11,73
    Avg. Active Threads Per Warp                                                                                    26,59
    Avg. Not Predicated Off Threads Per Warp                                                                        24,47
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.501.568
    Executed Instructions                                                             inst                     84.087.808
    Avg. Issued Instructions Per Scheduler                                            inst                   1.501.604,88
    Issued Instructions                                                               inst                     84.089.873
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          82,60
    Achieved Active Warps Per SM                                                      warp                          26,43
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4915200 transactions, got 18251776 (3.71x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4915200 transactions, got 17399808 (3.54x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4259840 transactions, got 16089088 (3.78x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:55, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                         78.579
    Memory [%]                                                                           %                           6,49
    SOL DRAM                                                                             %                           1,95
    Duration                                                                       usecond                          56,51
    SOL L1/TEX Cache                                                                     %                           6,88
    SOL L2 Cache                                                                         %                           6,49
    SM Active Cycles                                                                 cycle                      73.812,43
    SM [%]                                                                               %                          80,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,71
    Mem Busy                                                                             %                           5,50
    Max Bandwidth                                                                        %                           6,49
    L1/TEX Hit Rate                                                                      %                          87,89
    L2 Hit Rate                                                                          %                          82,70
    Mem Pipes Busy                                                                       %                          21,06
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,23
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,77
    Active Warps Per Scheduler                                                        warp                           6,27
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.27 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,00
    Warp Cycles Per Executed Instruction                                             cycle                         148,72
    Warp Cycles Per Issue Active                                                      warp                         148,00
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.3% of the total average of 148.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,70
    Achieved Active Warps Per SM                                                      warp                          24,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:55, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,38
    SM Frequency                                                             cycle/nsecond                           1,26
    Elapsed Cycles                                                                   cycle                          6.635
    Memory [%]                                                                           %                          33,83
    SOL DRAM                                                                             %                          21,77
    Duration                                                                       usecond                           5,28
    SOL L1/TEX Cache                                                                     %                          40,94
    SOL L2 Cache                                                                         %                          33,83
    SM Active Cycles                                                                 cycle                       5.190,64
    SM [%]                                                                               %                          23,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,31
    Issue Slots Busy                                                                     %                          10,27
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,51
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          38,51
    Mem Busy                                                                             %                          33,83
    Max Bandwidth                                                                        %                          30,47
    L1/TEX Hit Rate                                                                      %                          87,98
    L2 Hit Rate                                                                          %                          65,96
    Mem Pipes Busy                                                                       %                          23,17
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,47
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,53
    Active Warps Per Scheduler                                                        warp                           5,37
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.37 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          51,33
    Warp Cycles Per Executed Instruction                                             cycle                          53,44
    Warp Cycles Per Issue Active                                                      warp                          51,33
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 33.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 66.1% of the total average of 51.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.4%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,65
    Achieved Active Warps Per SM                                                      warp                          22,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:55, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,33
    SM Frequency                                                             cycle/nsecond                           1,21
    Elapsed Cycles                                                                   cycle                          5.596
    Memory [%]                                                                           %                          25,60
    SOL DRAM                                                                             %                          25,60
    Duration                                                                       usecond                           4,61
    SOL L1/TEX Cache                                                                     %                          22,82
    SOL L2 Cache                                                                         %                          15,64
    SM Active Cycles                                                                 cycle                       4.223,14
    SM [%]                                                                               %                          13,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,67
    Issued Ipc Active                                                           inst/cycle                           0,35
    SM Busy                                                                              %                           8,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,69
    Mem Busy                                                                             %                          15,41
    Max Bandwidth                                                                        %                          25,60
    L1/TEX Hit Rate                                                                      %                          75,85
    L2 Hit Rate                                                                          %                          12,40
    Mem Pipes Busy                                                                       %                          13,73
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,58
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,42
    Active Warps Per Scheduler                                                        warp                           5,29
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.29 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          61,68
    Warp Cycles Per Executed Instruction                                             cycle                          64,14
    Warp Cycles Per Issue Active                                                      warp                          61,68
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 68.8% of the total average of 61.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,05
    Achieved Active Warps Per SM                                                      warp                          22,42
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:56, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      2.534.067
    Memory [%]                                                                           %                          24,04
    SOL DRAM                                                                             %                           0,49
    Duration                                                                       msecond                           1,83
    SOL L1/TEX Cache                                                                     %                          48,08
    SOL L2 Cache                                                                         %                           9,08
    SM Active Cycles                                                                 cycle                   2.697.632,57
    SM [%]                                                                               %                          62,43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,34
    Executed Ipc Elapsed                                                        inst/cycle                           2,50
    Issue Slots Busy                                                                     %                          58,54
    Issued Ipc Active                                                           inst/cycle                           2,34
    SM Busy                                                                              %                          58,54
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Mbyte/second                         937,73
    Mem Busy                                                                             %                          24,04
    Max Bandwidth                                                                        %                          20,85
    L1/TEX Hit Rate                                                                      %                          94,57
    L2 Hit Rate                                                                          %                          98,72
    Mem Pipes Busy                                                                       %                          20,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          64,46
    Issued Warp Per Scheduler                                                                                        0,64
    No Eligible                                                                          %                          35,54
    Active Warps Per Scheduler                                                        warp                           6,99
    Eligible Warps Per Scheduler                                                      warp                           1,33
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,85
    Warp Cycles Per Executed Instruction                                             cycle                          10,85
    Warp Cycles Per Issue Active                                                      warp                          10,85
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 4.6 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 42.1% of the total average of 10.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.579.264
    Executed Instructions                                                             inst                     88.438.784
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.301,27
    Issued Instructions                                                               inst                     88.440.871
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          87,39
    Achieved Active Warps Per SM                                                      warp                          27,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:56, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        297.164
    Memory [%]                                                                           %                           6,89
    SOL DRAM                                                                             %                           6,57
    Duration                                                                       usecond                         213,79
    SOL L1/TEX Cache                                                                     %                           7,37
    SOL L2 Cache                                                                         %                           6,89
    SM Active Cycles                                                                 cycle                     292.755,14
    SM [%]                                                                               %                          85,70
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,24
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,89
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.9%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          12,56
    Mem Busy                                                                             %                           5,84
    Max Bandwidth                                                                        %                           6,89
    L1/TEX Hit Rate                                                                      %                          87,76
    L2 Hit Rate                                                                          %                          82,40
    Mem Pipes Busy                                                                       %                          22,30
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,25
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,75
    Active Warps Per Scheduler                                                        warp                           6,31
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.31 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,58
    Warp Cycles Per Executed Instruction                                             cycle                         148,83
    Warp Cycles Per Issue Active                                                      warp                         148,58
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        26,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 97.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.4% of the total average of 148.6  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      12.391,25
    Executed Instructions                                                             inst                        693.910
    Avg. Issued Instructions Per Scheduler                                            inst                      12.411,50
    Issued Instructions                                                               inst                        695.044
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          79,18
    Achieved Active Warps Per SM                                                      warp                          25,34
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:56, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,55
    SM Frequency                                                             cycle/nsecond                           1,43
    Elapsed Cycles                                                                   cycle                         22.165
    Memory [%]                                                                           %                          47,98
    SOL DRAM                                                                             %                          47,98
    Duration                                                                       usecond                          15,46
    SOL L1/TEX Cache                                                                     %                          48,78
    SOL L2 Cache                                                                         %                          40,57
    SM Active Cycles                                                                 cycle                      18.719,79
    SM [%]                                                                               %                          27,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,44
    Executed Ipc Elapsed                                                        inst/cycle                           0,37
    Issue Slots Busy                                                                     %                          11,05
    Issued Ipc Active                                                           inst/cycle                           0,44
    SM Busy                                                                              %                          12,76
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          95,10
    Mem Busy                                                                             %                          40,57
    Max Bandwidth                                                                        %                          47,98
    L1/TEX Hit Rate                                                                      %                          87,89
    L2 Hit Rate                                                                          %                          64,13
    Mem Pipes Busy                                                                       %                          27,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          11,10
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          88,90
    Active Warps Per Scheduler                                                        warp                           5,57
    Eligible Warps Per Scheduler                                                      warp                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.57 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          50,17
    Warp Cycles Per Executed Instruction                                             cycle                          50,68
    Warp Cycles Per Issue Active                                                      warp                          50,17
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 36.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 72.7% of the total average of 50.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          2.048
    Executed Instructions                                                             inst                        114.688
    Avg. Issued Instructions Per Scheduler                                            inst                          2.069
    Issued Instructions                                                               inst                        115.864
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,80
    Achieved Active Warps Per SM                                                      warp                          22,34
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:31:57, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,41
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         21.762
    Memory [%]                                                                           %                          64,49
    SOL DRAM                                                                             %                          64,49
    Duration                                                                       usecond                          16,58
    SOL L1/TEX Cache                                                                     %                          55,78
    SOL L2 Cache                                                                         %                          56,50
    SM Active Cycles                                                                 cycle                         20.676
    SM [%]                                                                               %                          23,60
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,37
    Executed Ipc Elapsed                                                        inst/cycle                           0,35
    Issue Slots Busy                                                                     %                           9,35
    Issued Ipc Active                                                           inst/cycle                           0,37
    SM Busy                                                                              %                           9,91
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                         116,64
    Mem Busy                                                                             %                          56,50
    Max Bandwidth                                                                        %                          64,49
    L1/TEX Hit Rate                                                                      %                          83,84
    L2 Hit Rate                                                                          %                          51,19
    Mem Pipes Busy                                                                       %                          23,60
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,40
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,60
    Active Warps Per Scheduler                                                        warp                           5,61
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.61 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          59,68
    Warp Cycles Per Executed Instruction                                             cycle                          60,12
    Warp Cycles Per Issue Active                                                      warp                          59,68
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.8% of the total average of 59.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.920
    Executed Instructions                                                             inst                        107.520
    Avg. Issued Instructions Per Scheduler                                            inst                          1.934
    Issued Instructions                                                               inst                        108.304
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          71,46
    Achieved Active Warps Per SM                                                      warp                          22,87
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:57, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,75
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                         15.698
    Memory [%]                                                                           %                          30,07
    SOL DRAM                                                                             %                          30,07
    Duration                                                                       usecond                          11,90
    SOL L1/TEX Cache                                                                     %                          32,60
    SOL L2 Cache                                                                         %                          23,66
    SM Active Cycles                                                                 cycle                      14.193,64
    SM [%]                                                                               %                          19,61
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,40
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                          10,02
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                          10,02
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          67,46
    Mem Busy                                                                             %                          23,66
    Max Bandwidth                                                                        %                          30,07
    L1/TEX Hit Rate                                                                      %                          75,75
    L2 Hit Rate                                                                          %                           9,36
    Mem Pipes Busy                                                                       %                          19,61
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,98
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          90,02
    Active Warps Per Scheduler                                                        warp                           5,54
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.54 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          55,47
    Warp Cycles Per Executed Instruction                                             cycle                          56,02
    Warp Cycles Per Issue Active                                                      warp                          55,47
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 40.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 73.2% of the total average of 55.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.408
    Executed Instructions                                                             inst                         78.848
    Avg. Issued Instructions Per Scheduler                                            inst                          1.422
    Issued Instructions                                                               inst                         79.632
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,42
    Achieved Active Warps Per SM                                                      warp                          21,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:57, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      3.169.816
    Memory [%]                                                                           %                          19,33
    SOL DRAM                                                                             %                           0,81
    Duration                                                                       msecond                           2,28
    SOL L1/TEX Cache                                                                     %                          38,65
    SOL L2 Cache                                                                         %                           9,26
    SM Active Cycles                                                                 cycle                   3.161.873,21
    SM [%]                                                                               %                          49,80
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,99
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          49,80
    Issued Ipc Active                                                           inst/cycle                           1,99
    SM Busy                                                                              %                          49,80
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,60
    Mem Busy                                                                             %                          19,33
    Max Bandwidth                                                                        %                          16,78
    L1/TEX Hit Rate                                                                      %                          94,23
    L2 Hit Rate                                                                          %                          96,21
    Mem Pipes Busy                                                                       %                          16,61
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          49,88
    Issued Warp Per Scheduler                                                                                        0,50
    No Eligible                                                                          %                          50,12
    Active Warps Per Scheduler                                                        warp                           6,46
    Eligible Warps Per Scheduler                                                      warp                           0,97
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.46 active warps per scheduler, but only an average of 0.97 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,95
    Warp Cycles Per Executed Instruction                                             cycle                          12,95
    Warp Cycles Per Issue Active                                                      warp                          12,95
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.0 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 46.2% of the total average of 13.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.574.464
    Executed Instructions                                                             inst                     88.169.984
    Avg. Issued Instructions Per Scheduler                                            inst                   1.574.501,36
    Issued Instructions                                                               inst                     88.172.076
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          80,88
    Achieved Active Warps Per SM                                                      warp                          25,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:58, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.061
    Memory [%]                                                                           %                           6,55
    SOL DRAM                                                                             %                           1,89
    Duration                                                                       usecond                          56,54
    SOL L1/TEX Cache                                                                     %                           6,95
    SOL L2 Cache                                                                         %                           6,55
    SM Active Cycles                                                                 cycle                      73.845,36
    SM [%]                                                                               %                          81,49
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.0%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,59
    Mem Busy                                                                             %                           5,51
    Max Bandwidth                                                                        %                           6,55
    L1/TEX Hit Rate                                                                      %                          87,92
    L2 Hit Rate                                                                          %                          83,57
    Mem Pipes Busy                                                                       %                          21,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,22
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,78
    Active Warps Per Scheduler                                                        warp                           6,24
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.24 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,76
    Warp Cycles Per Executed Instruction                                             cycle                         148,48
    Warp Cycles Per Issue Active                                                      warp                         147,76
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.4% of the total average of 147.8  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,86
    Achieved Active Warps Per SM                                                      warp                          24,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:58, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,34
    SM Frequency                                                             cycle/nsecond                           1,26
    Elapsed Cycles                                                                   cycle                          6.733
    Memory [%]                                                                           %                          34,29
    SOL DRAM                                                                             %                          27,25
    Duration                                                                       usecond                           5,34
    SOL L1/TEX Cache                                                                     %                          40,67
    SOL L2 Cache                                                                         %                          34,29
    SM Active Cycles                                                                 cycle                       5.225,86
    SM [%]                                                                               %                          22,83
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,30
    Issue Slots Busy                                                                     %                          10,20
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,43
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          46,78
    Mem Busy                                                                             %                          34,29
    Max Bandwidth                                                                        %                          29,44
    L1/TEX Hit Rate                                                                      %                          87,93
    L2 Hit Rate                                                                          %                          64,49
    Mem Pipes Busy                                                                       %                          22,83
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,36
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,64
    Active Warps Per Scheduler                                                        warp                           5,46
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.46 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,73
    Warp Cycles Per Executed Instruction                                             cycle                          54,89
    Warp Cycles Per Issue Active                                                      warp                          52,73
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 34.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.9% of the total average of 52.7   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,27
    Achieved Active Warps Per SM                                                      warp                          22,17
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:58, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         764,23
    SM Frequency                                                             cycle/usecond                         713,10
    Elapsed Cycles                                                                   cycle                          5.617
    Memory [%]                                                                           %                          26,12
    SOL DRAM                                                                             %                          26,12
    Duration                                                                       usecond                           7,87
    SOL L1/TEX Cache                                                                     %                          22,72
    SOL L2 Cache                                                                         %                          15,56
    SM Active Cycles                                                                 cycle                       4.261,43
    SM [%]                                                                               %                          13,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,59
    Issued Ipc Active                                                           inst/cycle                           0,34
    SM Busy                                                                              %                           8,59
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          25,55
    Mem Busy                                                                             %                          15,35
    Max Bandwidth                                                                        %                          26,12
    L1/TEX Hit Rate                                                                      %                          75,82
    L2 Hit Rate                                                                          %                          27,63
    Mem Pipes Busy                                                                       %                          13,68
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,27
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,73
    Active Warps Per Scheduler                                                        warp                           5,15
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.1 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.15 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          62,34
    Warp Cycles Per Executed Instruction                                             cycle                          64,82
    Warp Cycles Per Issue Active                                                      warp                          62,34
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 68.2% of the total average of 62.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 21.3%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,90
    Achieved Active Warps Per SM                                                      warp                          22,05
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:31:59, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,59
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      2.478.230
    Memory [%]                                                                           %                          47,78
    SOL DRAM                                                                             %                           1,15
    Duration                                                                       msecond                           1,80
    SOL L1/TEX Cache                                                                     %                          89,06
    SOL L2 Cache                                                                         %                           6,38
    SM Active Cycles                                                                 cycle                   2.428.592,57
    SM [%]                                                                               %                          60,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 5% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,47
    Executed Ipc Elapsed                                                        inst/cycle                           2,43
    Issue Slots Busy                                                                     %                          61,83
    Issued Ipc Active                                                           inst/cycle                           2,47
    SM Busy                                                                              %                          61,83
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,35
    Mem Busy                                                                             %                          44,53
    Max Bandwidth                                                                        %                          47,78
    L1/TEX Hit Rate                                                                      %                          98,84
    L2 Hit Rate                                                                          %                          68,03
    Mem Pipes Busy                                                                       %                          47,78
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          56,95
    Issued Warp Per Scheduler                                                                                        0,57
    No Eligible                                                                          %                          43,05
    Active Warps Per Scheduler                                                        warp                           6,71
    Eligible Warps Per Scheduler                                                      warp                           1,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 1.8 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.71 active warps per scheduler, but only an average of 1.24 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,79
    Warp Cycles Per Executed Instruction                                             cycle                          11,79
    Warp Cycles Per Issue Active                                                      warp                          11,79
    Avg. Active Threads Per Warp                                                                                    26,59
    Avg. Not Predicated Off Threads Per Warp                                                                        24,47
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.501.568
    Executed Instructions                                                             inst                     84.087.808
    Avg. Issued Instructions Per Scheduler                                            inst                   1.501.604,88
    Issued Instructions                                                               inst                     84.089.873
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          82,58
    Achieved Active Warps Per SM                                                      warp                          26,43
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4915200 transactions, got 18251776 (3.71x) at PC 0x7f58a7265590           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4915200 transactions, got 17399808 (3.54x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4259840 transactions, got 16089088 (3.78x) at PC 0x7f58a7265580           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7265fa0                 

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:59, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         78.360
    Memory [%]                                                                           %                           6,52
    SOL DRAM                                                                             %                           1,93
    Duration                                                                       usecond                          56,70
    SOL L1/TEX Cache                                                                     %                           6,92
    SOL L2 Cache                                                                         %                           6,52
    SM Active Cycles                                                                 cycle                      73.792,71
    SM [%]                                                                               %                          81,20
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 45% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,20
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.1%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,67
    Mem Busy                                                                             %                           5,49
    Max Bandwidth                                                                        %                           6,52
    L1/TEX Hit Rate                                                                      %                          87,87
    L2 Hit Rate                                                                          %                          83,86
    Mem Pipes Busy                                                                       %                          21,12
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,23
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,77
    Active Warps Per Scheduler                                                        warp                           6,25
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.25 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         147,90
    Warp Cycles Per Executed Instruction                                             cycle                         148,62
    Warp Cycles Per Issue Active                                                      warp                         147,90
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 95.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.3% of the total average of 147.9  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          3.084
    Executed Instructions                                                             inst                        172.704
    Avg. Issued Instructions Per Scheduler                                            inst                          3.099
    Issued Instructions                                                               inst                        173.544
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          77,57
    Achieved Active Warps Per SM                                                      warp                          24,82
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a72623c0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a7262670                 

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:31:59, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,38
    SM Frequency                                                             cycle/nsecond                           1,28
    Elapsed Cycles                                                                   cycle                          6.635
    Memory [%]                                                                           %                          33,86
    SOL DRAM                                                                             %                          27,23
    Duration                                                                       usecond                           5,18
    SOL L1/TEX Cache                                                                     %                          41,37
    SOL L2 Cache                                                                         %                          33,86
    SM Active Cycles                                                                 cycle                       5.186,79
    SM [%]                                                                               %                          23,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,31
    Issue Slots Busy                                                                     %                          10,28
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,52
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          48,19
    Mem Busy                                                                             %                          33,86
    Max Bandwidth                                                                        %                          28,30
    L1/TEX Hit Rate                                                                      %                          87,93
    L2 Hit Rate                                                                          %                          69,47
    Mem Pipes Busy                                                                       %                          23,16
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,25
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,75
    Active Warps Per Scheduler                                                        warp                           5,44
    Eligible Warps Per Scheduler                                                      warp                           0,15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.8 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.44 active warps per scheduler, but only an average of 0.15 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,08
    Warp Cycles Per Executed Instruction                                             cycle                          55,25
    Warp Cycles Per Issue Active                                                      warp                          53,08
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 33.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 63.5% of the total average of 53.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            512
    Executed Instructions                                                             inst                         28.672
    Avg. Issued Instructions Per Scheduler                                            inst                            533
    Issued Instructions                                                               inst                         29.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 20.4%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,64
    Achieved Active Warps Per SM                                                      warp                          22,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725edc0                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725ede0                 

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:31:59, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,54
    SM Frequency                                                             cycle/nsecond                           1,24
    Elapsed Cycles                                                                   cycle                          5.694
    Memory [%]                                                                           %                          22,31
    SOL DRAM                                                                             %                          22,31
    Duration                                                                       usecond                           4,58
    SOL L1/TEX Cache                                                                     %                          22,43
    SOL L2 Cache                                                                         %                          15,50
    SM Active Cycles                                                                 cycle                       4.264,71
    SM [%]                                                                               %                          13,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,33
    Executed Ipc Elapsed                                                        inst/cycle                           0,25
    Issue Slots Busy                                                                     %                           8,58
    Issued Ipc Active                                                           inst/cycle                           0,34
    SM Busy                                                                              %                           8,58
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          43,94
    Mem Busy                                                                             %                          15,50
    Max Bandwidth                                                                        %                          22,31
    L1/TEX Hit Rate                                                                      %                          75,82
    L2 Hit Rate                                                                          %                          11,09
    Mem Pipes Busy                                                                       %                          13,50
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,69
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          91,31
    Active Warps Per Scheduler                                                        warp                           5,66
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.66 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          65,15
    Warp Cycles Per Executed Instruction                                             cycle                          67,74
    Warp Cycles Per Issue Active                                                      warp                          65,15
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 64.6% of the total average of 65.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                            352
    Executed Instructions                                                             inst                         19.712
    Avg. Issued Instructions Per Scheduler                                            inst                            366
    Issued Instructions                                                               inst                         20.496
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                         256
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         50.176
    Waves Per SM                                                                                                     4,57
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 31 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 21.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          68,70
    Achieved Active Warps Per SM                                                      warp                          21,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6400 transactions, got 26240 (4.10x) at PC 0x7f58a725bc80                 

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:00, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      2.535.268
    Memory [%]                                                                           %                          23,62
    SOL DRAM                                                                             %                           5,28
    Duration                                                                       msecond                           1,83
    SOL L1/TEX Cache                                                                     %                          47,24
    SOL L2 Cache                                                                         %                           8,79
    SM Active Cycles                                                                 cycle                   2.450.965,57
    SM [%]                                                                               %                          62,45
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,58
    Executed Ipc Elapsed                                                        inst/cycle                           2,50
    Issue Slots Busy                                                                     %                          64,44
    Issued Ipc Active                                                           inst/cycle                           2,58
    SM Busy                                                                              %                          64,44
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          10,12
    Mem Busy                                                                             %                          23,62
    Max Bandwidth                                                                        %                          20,85
    L1/TEX Hit Rate                                                                      %                          94,57
    L2 Hit Rate                                                                          %                          98,77
    Mem Pipes Busy                                                                       %                          20,85
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          64,45
    Issued Warp Per Scheduler                                                                                        0,64
    No Eligible                                                                          %                          35,55
    Active Warps Per Scheduler                                                        warp                           6,99
    Eligible Warps Per Scheduler                                                      warp                           1,33
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,85
    Warp Cycles Per Executed Instruction                                             cycle                          10,85
    Warp Cycles Per Issue Active                                                      warp                          10,85
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        25,67
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 3.5 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 32.0% of the total average of 10.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.579.264
    Executed Instructions                                                             inst                     88.438.784
    Avg. Issued Instructions Per Scheduler                                            inst                   1.579.300,86
    Issued Instructions                                                               inst                     88.440.848
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                              5
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          87,39
    Achieved Active Warps Per SM                                                      warp                          27,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 6553600 transactions, got 26869760 (4.10x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7265fa0               

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:00, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        297.779
    Memory [%]                                                                           %                           6,88
    SOL DRAM                                                                             %                           6,09
    Duration                                                                       usecond                         213,82
    SOL L1/TEX Cache                                                                     %                           7,34
    SOL L2 Cache                                                                         %                           6,88
    SM Active Cycles                                                                 cycle                     292.854,43
    SM [%]                                                                               %                          85,55
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 47% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,24
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,86
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.9%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          11,64
    Mem Busy                                                                             %                           5,82
    Max Bandwidth                                                                        %                           6,88
    L1/TEX Hit Rate                                                                      %                          87,78
    L2 Hit Rate                                                                          %                          82,60
    Mem Pipes Busy                                                                       %                          22,27
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,25
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,75
    Active Warps Per Scheduler                                                        warp                           6,32
    Eligible Warps Per Scheduler                                                      warp                           0,07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.32 active warps per scheduler, but only an average of 0.07 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         148,87
    Warp Cycles Per Executed Instruction                                             cycle                         149,10
    Warp Cycles Per Issue Active                                                      warp                         148,87
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                        26,02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 97.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.2% of the total average of 148.9  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      12.391,25
    Executed Instructions                                                             inst                        693.910
    Avg. Issued Instructions Per Scheduler                                            inst                      12.410,66
    Issued Instructions                                                               inst                        694.997
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             12
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          78,94
    Achieved Active Warps Per SM                                                      warp                          25,26
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a72623c0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a7262670               

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:00, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         20.692
    Memory [%]                                                                           %                          42,38
    SOL DRAM                                                                             %                          37,08
    Duration                                                                       usecond                          15,55
    SOL L1/TEX Cache                                                                     %                          52,16
    SOL L2 Cache                                                                         %                          42,38
    SM Active Cycles                                                                 cycle                      18.442,50
    SM [%]                                                                               %                          29,76
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,44
    Executed Ipc Elapsed                                                        inst/cycle                           0,40
    Issue Slots Busy                                                                     %                          11,22
    Issued Ipc Active                                                           inst/cycle                           0,45
    SM Busy                                                                              %                          12,96
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          72,65
    Mem Busy                                                                             %                          42,38
    Max Bandwidth                                                                        %                          37,08
    L1/TEX Hit Rate                                                                      %                          87,87
    L2 Hit Rate                                                                          %                          66,67
    Mem Pipes Busy                                                                       %                          29,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          11,01
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          88,99
    Active Warps Per Scheduler                                                        warp                           5,53
    Eligible Warps Per Scheduler                                                      warp                           0,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.1 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.53 active warps per scheduler, but only an average of 0.14 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          50,25
    Warp Cycles Per Executed Instruction                                             cycle                          50,77
    Warp Cycles Per Issue Active                                                      warp                          50,25
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 36.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 71.9% of the total average of 50.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          2.048
    Executed Instructions                                                             inst                        114.688
    Avg. Issued Instructions Per Scheduler                                            inst                          2.069
    Issued Instructions                                                               inst                        115.864
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          70,46
    Achieved Active Warps Per SM                                                      warp                          22,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725edc0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725ede0               

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:32:00, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         21.758
    Memory [%]                                                                           %                          62,98
    SOL DRAM                                                                             %                          62,98
    Duration                                                                       usecond                          16,58
    SOL L1/TEX Cache                                                                     %                          55,66
    SOL L2 Cache                                                                         %                          55,68
    SM Active Cycles                                                                 cycle                      20.755,93
    SM [%]                                                                               %                          23,59
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis report section to see      
          where the memory system bottleneck is. Check memory replay (coalescing) metrics to make sure you're           
          efficiently utilizing the bytes transferred. Also consider whether it is possible to do more work per memory  
          access (kernel fusion) or whether there are values you can (re)compute.                                       

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,37
    Executed Ipc Elapsed                                                        inst/cycle                           0,35
    Issue Slots Busy                                                                     %                           9,32
    Issued Ipc Active                                                           inst/cycle                           0,37
    SM Busy                                                                              %                           9,87
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                         117,03
    Mem Busy                                                                             %                          55,68
    Max Bandwidth                                                                        %                          62,98
    L1/TEX Hit Rate                                                                      %                          83,84
    L2 Hit Rate                                                                          %                          49,64
    Mem Pipes Busy                                                                       %                          23,59
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,50
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,50
    Active Warps Per Scheduler                                                        warp                           5,00
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.00 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          58,79
    Warp Cycles Per Executed Instruction                                             cycle                          59,22
    Warp Cycles Per Issue Active                                                      warp                          58,79
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 46.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 79.2% of the total average of 58.8   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.920
    Executed Instructions                                                             inst                        107.520
    Avg. Issued Instructions Per Scheduler                                            inst                          1.934
    Issued Instructions                                                               inst                        108.304
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          71,83
    Achieved Active Warps Per SM                                                      warp                          22,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d490               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4a0               
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725d4d0               

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:01, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                         15.706
    Memory [%]                                                                           %                          36,31
    SOL DRAM                                                                             %                          36,31
    Duration                                                                       usecond                          11,97
    SOL L1/TEX Cache                                                                     %                          32,59
    SOL L2 Cache                                                                         %                          21,65
    SM Active Cycles                                                                 cycle                      14.260,29
    SM [%]                                                                               %                          19,60
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                           9,97
    Issued Ipc Active                                                           inst/cycle                           0,40
    SM Busy                                                                              %                           9,97
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          67,10
    Mem Busy                                                                             %                          21,59
    Max Bandwidth                                                                        %                          36,31
    L1/TEX Hit Rate                                                                      %                          75,73
    L2 Hit Rate                                                                          %                          20,24
    Mem Pipes Busy                                                                       %                          19,60
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,57
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          90,43
    Active Warps Per Scheduler                                                        warp                           5,10
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.10 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,27
    Warp Cycles Per Executed Instruction                                             cycle                          53,80
    Warp Cycles Per Issue Active                                                      warp                          53,27
    Avg. Active Threads Per Warp                                                                                       28
    Avg. Not Predicated Off Threads Per Warp                                                                           28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 41.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 77.5% of the total average of 53.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                          1.408
    Executed Instructions                                                             inst                         78.848
    Avg. Issued Instructions Per Scheduler                                            inst                          1.422
    Issued Instructions                                                               inst                         79.632
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        196
    Grid Size                                                                                                       1.024
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        200.704
    Waves Per SM                                                                                                    18,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 196    
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             28
    Theoretical Occupancy                                                                %                          87,50
    Achieved Occupancy                                                                   %                          69,09
    Achieved Active Warps Per SM                                                      warp                          22,11
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 25600 transactions, got 104960 (4.10x) at PC 0x7f58a725bc80               

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:02, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,44
    Elapsed Cycles                                                                   cycle                      7.244.582
    Memory [%]                                                                           %                          21,57
    SOL DRAM                                                                             %                           3,27
    Duration                                                                       msecond                           5,02
    SOL L1/TEX Cache                                                                     %                          43,13
    SOL L2 Cache                                                                         %                           5,88
    SM Active Cycles                                                                 cycle                      6.900.302
    SM [%]                                                                               %                          49,78
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,09
    Executed Ipc Elapsed                                                        inst/cycle                           1,99
    Issue Slots Busy                                                                     %                          52,15
    Issued Ipc Active                                                           inst/cycle                           2,09
    SM Busy                                                                              %                          52,15
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           6,27
    Mem Busy                                                                             %                          21,57
    Max Bandwidth                                                                        %                          16,60
    L1/TEX Hit Rate                                                                      %                          94,83
    L2 Hit Rate                                                                          %                          89,47
    Mem Pipes Busy                                                                       %                          16,60
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          52,96
    Issued Warp Per Scheduler                                                                                        0,53
    No Eligible                                                                          %                          47,04
    Active Warps Per Scheduler                                                        warp                           7,50
    Eligible Warps Per Scheduler                                                      warp                           0,87
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 1.9 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.50 active warps per scheduler, but only an average of 0.87 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,17
    Warp Cycles Per Executed Instruction                                             cycle                          14,17
    Warp Cycles Per Issue Active                                                      warp                          14,17
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 7.6 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 53.8% of the total average of 14.2   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.5 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   3.598.774,86
    Executed Instructions                                                             inst                    201.531.392
    Avg. Issued Instructions Per Scheduler                                            inst                   3.598.813,68
    Issued Instructions                                                               inst                    201.533.566
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          92,48
    Achieved Active Warps Per SM                                                      warp                          29,59
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14680064 transactions, got 48234496 (3.29x) at PC 0x7f58a7265650          
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:02, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        170.594
    Memory [%]                                                                           %                           3,42
    SOL DRAM                                                                             %                           1,80
    Duration                                                                       usecond                         123,10
    SOL L1/TEX Cache                                                                     %                           3,52
    SOL L2 Cache                                                                         %                           3,42
    SM Active Cycles                                                                 cycle                     167.613,43
    SM [%]                                                                               %                          85,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 41% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,25
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.8%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,43
    Mem Busy                                                                             %                           3,42
    Max Bandwidth                                                                        %                           3,36
    L1/TEX Hit Rate                                                                      %                          73,69
    L2 Hit Rate                                                                          %                         129,90
    Mem Pipes Busy                                                                       %                          22,22
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,26
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,74
    Active Warps Per Scheduler                                                        warp                           7,54
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.54 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         177,21
    Warp Cycles Per Executed Instruction                                             cycle                         177,59
    Warp Cycles Per Issue Active                                                      warp                         177,21
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 96.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 54.7% of the total average of 177.2  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 71.7 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 40.5% of the total average of 177.2 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       7.108,71
    Executed Instructions                                                             inst                        398.088
    Avg. Issued Instructions Per Scheduler                                            inst                       7.123,73
    Issued Instructions                                                               inst                        398.929
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          94,19
    Achieved Active Warps Per SM                                                      warp                          30,14
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:02, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,41
    SM Frequency                                                             cycle/nsecond                           1,25
    Elapsed Cycles                                                                   cycle                         10.975
    Memory [%]                                                                           %                          41,01
    SOL DRAM                                                                             %                          26,34
    Duration                                                                       usecond                           8,80
    SOL L1/TEX Cache                                                                     %                          40,08
    SOL L2 Cache                                                                         %                          41,01
    SM Active Cycles                                                                 cycle                       9.645,43
    SM [%]                                                                               %                          32,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,49
    Executed Ipc Elapsed                                                        inst/cycle                           0,43
    Issue Slots Busy                                                                     %                          12,36
    Issued Ipc Active                                                           inst/cycle                           0,49
    SM Busy                                                                              %                          14,16
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          47,57
    Mem Busy                                                                             %                          41,01
    Max Bandwidth                                                                        %                          37,60
    L1/TEX Hit Rate                                                                      %                          72,21
    L2 Hit Rate                                                                          %                          64,82
    Mem Pipes Busy                                                                       %                          32,03
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          12,21
    Issued Warp Per Scheduler                                                                                        0,12
    No Eligible                                                                          %                          87,79
    Active Warps Per Scheduler                                                        warp                           5,50
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 8.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.50 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          45,09
    Warp Cycles Per Executed Instruction                                             cycle                          45,93
    Warp Cycles Per Issue Active                                                      warp                          45,09
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 30.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 67.4% of the total average of 45.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.170,29
    Executed Instructions                                                             inst                         65.536
    Avg. Issued Instructions Per Scheduler                                            inst                       1.192,04
    Issued Instructions                                                               inst                         66.754
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          67,72
    Achieved Active Warps Per SM                                                      warp                          21,67
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725ede0                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:03, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      2.071.347
    Memory [%]                                                                           %                          19,02
    SOL DRAM                                                                             %                           5,67
    Duration                                                                       msecond                           1,49
    SOL L1/TEX Cache                                                                     %                          38,04
    SOL L2 Cache                                                                         %                           6,07
    SM Active Cycles                                                                 cycle                   2.066.978,64
    SM [%]                                                                               %                          43,51
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,74
    Executed Ipc Elapsed                                                        inst/cycle                           1,74
    Issue Slots Busy                                                                     %                          43,53
    Issued Ipc Active                                                           inst/cycle                           1,74
    SM Busy                                                                              %                          43,53
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          10,88
    Mem Busy                                                                             %                          19,02
    Max Bandwidth                                                                        %                          14,51
    L1/TEX Hit Rate                                                                      %                          93,78
    L2 Hit Rate                                                                          %                         129,30
    Mem Pipes Busy                                                                       %                          14,51
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          42,90
    Issued Warp Per Scheduler                                                                                        0,43
    No Eligible                                                                          %                          57,10
    Active Warps Per Scheduler                                                        warp                           6,04
    Eligible Warps Per Scheduler                                                      warp                           0,68
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.3 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.04 active warps per scheduler, but only an average of 0.68 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,09
    Warp Cycles Per Executed Instruction                                             cycle                          14,09
    Warp Cycles Per Issue Active                                                      warp                          14,09
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 7.7 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 54.4% of the total average of 14.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.5 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                     899.693,71
    Executed Instructions                                                             inst                     50.382.848
    Avg. Issued Instructions Per Scheduler                                            inst                     899.732,80
    Issued Instructions                                                               inst                     50.385.037
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 23.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          76,83
    Achieved Active Warps Per SM                                                      warp                          24,58
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3670016 transactions, got 12058624 (3.29x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7265fa0                  

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:03, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                         44.751
    Memory [%]                                                                           %                           3,23
    SOL DRAM                                                                             %                           1,66
    Duration                                                                       usecond                          33,25
    SOL L1/TEX Cache                                                                     %                           3,36
    SOL L2 Cache                                                                         %                           3,23
    SM Active Cycles                                                                 cycle                      42.613,21
    SM [%]                                                                               %                          81,41
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 39% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,22
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,39
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.4%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,15
    Mem Busy                                                                             %                           3,23
    Max Bandwidth                                                                        %                           3,22
    L1/TEX Hit Rate                                                                      %                          74,56
    L2 Hit Rate                                                                          %                          72,67
    Mem Pipes Busy                                                                       %                          21,20
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,24
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,76
    Active Warps Per Scheduler                                                        warp                           7,02
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.02 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         165,58
    Warp Cycles Per Executed Instruction                                             cycle                         166,96
    Warp Cycles Per Issue Active                                                      warp                         165,58
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 93.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.3% of the total average of 165.6  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 62.1 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 37.5% of the total average of 165.6 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.781,50
    Executed Instructions                                                             inst                         99.764
    Avg. Issued Instructions Per Scheduler                                            inst                       1.796,36
    Issued Instructions                                                               inst                        100.596
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,20
    Achieved Active Warps Per SM                                                      warp                          27,90
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a72623c0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7262670                  

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:03, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,30
    SM Frequency                                                             cycle/nsecond                           1,34
    Elapsed Cycles                                                                   cycle                          5.152
    Memory [%]                                                                           %                          28,32
    SOL DRAM                                                                             %                          28,32
    Duration                                                                       usecond                           3,84
    SOL L1/TEX Cache                                                                     %                          28,92
    SOL L2 Cache                                                                         %                          21,81
    SM Active Cycles                                                                 cycle                       3.035,14
    SM [%]                                                                               %                          17,05
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,23
    Issue Slots Busy                                                                     %                          10,36
    Issued Ipc Active                                                           inst/cycle                           0,41
    SM Busy                                                                              %                          11,25
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          47,12
    Mem Busy                                                                             %                          21,81
    Max Bandwidth                                                                        %                          28,32
    L1/TEX Hit Rate                                                                      %                          73,59
    L2 Hit Rate                                                                          %                          65,30
    Mem Pipes Busy                                                                       %                          17,05
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,77
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,23
    Active Warps Per Scheduler                                                        warp                           7,05
    Eligible Warps Per Scheduler                                                      warp                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.3 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.05 active warps per scheduler, but only an average of 0.21 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          65,45
    Warp Cycles Per Executed Instruction                                             cycle                          70,35
    Warp Cycles Per Issue Active                                                      warp                          65,45
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 30.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 45.8% of the total average of 65.4   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         292,57
    Executed Instructions                                                             inst                         16.384
    Avg. Issued Instructions Per Scheduler                                            inst                         314,48
    Issued Instructions                                                               inst                         17.611
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 30.6%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          69,36
    Achieved Active Warps Per SM                                                      warp                          22,19
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725edc0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725ede0                  

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:03, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,32
    SM Frequency                                                             cycle/nsecond                           1,32
    Elapsed Cycles                                                                   cycle                          4.851
    Memory [%]                                                                           %                          22,08
    SOL DRAM                                                                             %                          22,08
    Duration                                                                       usecond                           3,68
    SOL L1/TEX Cache                                                                     %                          15,52
    SOL L2 Cache                                                                         %                          10,17
    SM Active Cycles                                                                 cycle                       2.827,64
    SM [%]                                                                               %                           9,05
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,28
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           7,61
    Issued Ipc Active                                                           inst/cycle                           0,30
    SM Busy                                                                              %                           7,61
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          37,36
    Mem Busy                                                                             %                          10,17
    Max Bandwidth                                                                        %                          22,08
    L1/TEX Hit Rate                                                                      %                          49,15
    L2 Hit Rate                                                                          %                          18,21
    Mem Pipes Busy                                                                       %                           9,05
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,92
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,08
    Active Warps Per Scheduler                                                        warp                           5,78
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.78 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          72,94
    Warp Cycles Per Executed Instruction                                             cycle                          77,98
    Warp Cycles Per Issue Active                                                      warp                          72,94
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 41.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.3% of the total average of 72.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         201,14
    Executed Instructions                                                             inst                         11.264
    Avg. Issued Instructions Per Scheduler                                            inst                         215,05
    Issued Instructions                                                               inst                         12.043
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 34.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          65,17
    Achieved Active Warps Per SM                                                      warp                          20,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725bc80                  

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:04, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,29
    Elapsed Cycles                                                                   cycle                      2.915.431
    Memory [%]                                                                           %                          46,37
    SOL DRAM                                                                             %                           2,43
    Duration                                                                       msecond                           2,26
    SOL L1/TEX Cache                                                                     %                          57,69
    SOL L2 Cache                                                                         %                           2,31
    SM Active Cycles                                                                 cycle                   2.797.108,36
    SM [%]                                                                               %                          58,96
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 4% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,45
    Executed Ipc Elapsed                                                        inst/cycle                           2,36
    Issue Slots Busy                                                                     %                          61,30
    Issued Ipc Active                                                           inst/cycle                           2,45
    SM Busy                                                                              %                          61,30
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,34
    Mem Busy                                                                             %                          28,84
    Max Bandwidth                                                                        %                          46,37
    L1/TEX Hit Rate                                                                      %                          98,44
    L2 Hit Rate                                                                          %                          71,30
    Mem Pipes Busy                                                                       %                          46,37
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          60,86
    Issued Warp Per Scheduler                                                                                        0,61
    No Eligible                                                                          %                          39,14
    Active Warps Per Scheduler                                                        warp                           6,69
    Eligible Warps Per Scheduler                                                      warp                           1,56
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          10,99
    Warp Cycles Per Executed Instruction                                             cycle                          10,99
    Warp Cycles Per Issue Active                                                      warp                          10,99
    Avg. Active Threads Per Warp                                                                                    22,18
    Avg. Not Predicated Off Threads Per Warp                                                                        19,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 22.2 threads being active per cycle. This is further reduced    
          to 20.0 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.714.688
    Executed Instructions                                                             inst                     96.022.528
    Avg. Issued Instructions Per Scheduler                                            inst                   1.714.726,89
    Issued Instructions                                                               inst                     96.024.706
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          84,27
    Achieved Active Warps Per SM                                                      warp                          26,97
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4194304 transactions, got 8192000 (1.95x) at PC 0x7f58a7265580            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4980736 transactions, got 8290304 (1.66x) at PC 0x7f58a7265590            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4980736 transactions, got 8290304 (1.66x) at PC 0x7f58a7265650            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7265fa0                  

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:04, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           2,72
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                         45.468
    Memory [%]                                                                           %                           5,57
    SOL DRAM                                                                             %                           2,55
    Duration                                                                       usecond                          32,58
    SOL L1/TEX Cache                                                                     %                           3,29
    SOL L2 Cache                                                                         %                           5,57
    SM Active Cycles                                                                 cycle                      42.611,07
    SM [%]                                                                               %                          80,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 38% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,22
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,40
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.4%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           8,61
    Mem Busy                                                                             %                           5,57
    Max Bandwidth                                                                        %                           3,15
    L1/TEX Hit Rate                                                                      %                          74,51
    L2 Hit Rate                                                                          %                          41,63
    Mem Pipes Busy                                                                       %                          20,87
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,24
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,76
    Active Warps Per Scheduler                                                        warp                           8,02
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          8.02 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         189,07
    Warp Cycles Per Executed Instruction                                             cycle                         190,63
    Warp Cycles Per Issue Active                                                      warp                         189,07
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 93.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 49.3% of the total average of 189.1  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 61.7 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 32.6% of the total average of 189.1 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.781,50
    Executed Instructions                                                             inst                         99.764
    Avg. Issued Instructions Per Scheduler                                            inst                       1.796,25
    Issued Instructions                                                               inst                        100.590
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,29
    Achieved Active Warps Per SM                                                      warp                          27,93
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a72623c0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7262670                  

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:04, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,44
    SM Frequency                                                             cycle/nsecond                           1,13
    Elapsed Cycles                                                                   cycle                          4.401
    Memory [%]                                                                           %                          25,95
    SOL DRAM                                                                             %                          14,51
    Duration                                                                       usecond                           3,90
    SOL L1/TEX Cache                                                                     %                          29,20
    SOL L2 Cache                                                                         %                          25,95
    SM Active Cycles                                                                 cycle                       3.006,29
    SM [%]                                                                               %                          19,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,27
    Issue Slots Busy                                                                     %                          10,46
    Issued Ipc Active                                                           inst/cycle                           0,42
    SM Busy                                                                              %                          11,35
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          26,79
    Mem Busy                                                                             %                          25,95
    Max Bandwidth                                                                        %                          20,64
    L1/TEX Hit Rate                                                                      %                          73,74
    L2 Hit Rate                                                                          %                          61,93
    Mem Pipes Busy                                                                       %                          19,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,86
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,14
    Active Warps Per Scheduler                                                        warp                           5,65
    Eligible Warps Per Scheduler                                                      warp                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.65 active warps per scheduler, but only an average of 0.21 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,00
    Warp Cycles Per Executed Instruction                                             cycle                          55,89
    Warp Cycles Per Issue Active                                                      warp                          52,00
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 29.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 55.9% of the total average of 52.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         292,57
    Executed Instructions                                                             inst                         16.384
    Avg. Issued Instructions Per Scheduler                                            inst                         314,46
    Issued Instructions                                                               inst                         17.610
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 31.3%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,71
    Achieved Active Warps Per SM                                                      warp                          21,99
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725edc0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725ede0                  

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:05, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,14
    Elapsed Cycles                                                                   cycle                          4.478
    Memory [%]                                                                           %                          13,34
    SOL DRAM                                                                             %                          13,34
    Duration                                                                       usecond                           3,94
    SOL L1/TEX Cache                                                                     %                          15,62
    SOL L2 Cache                                                                         %                          11,02
    SM Active Cycles                                                                 cycle                       2.810,07
    SM [%]                                                                               %                           9,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,29
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           7,65
    Issued Ipc Active                                                           inst/cycle                           0,31
    SM Busy                                                                              %                           7,65
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          25,55
    Mem Busy                                                                             %                          11,02
    Max Bandwidth                                                                        %                          13,34
    L1/TEX Hit Rate                                                                      %                          49,24
    L2 Hit Rate                                                                          %                          44,28
    Mem Pipes Busy                                                                       %                           9,81
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,55
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,45
    Active Warps Per Scheduler                                                        warp                           6,05
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 13.2 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.05 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          80,15
    Warp Cycles Per Executed Instruction                                             cycle                          85,68
    Warp Cycles Per Issue Active                                                      warp                          80,15
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 54.0% of the total average of 80.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         201,14
    Executed Instructions                                                             inst                         11.264
    Avg. Issued Instructions Per Scheduler                                            inst                         215,04
    Issued Instructions                                                               inst                         12.042
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 32.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          67,84
    Achieved Active Warps Per SM                                                      warp                          21,71
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725bc80                  

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:05, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,38
    SM Frequency                                                             cycle/nsecond                           1,05
    Elapsed Cycles                                                                   cycle                      2.743.696
    Memory [%]                                                                           %                          21,94
    SOL DRAM                                                                             %                           1,00
    Duration                                                                       msecond                           2,61
    SOL L1/TEX Cache                                                                     %                          29,47
    SOL L2 Cache                                                                         %                           2,66
    SM Active Cycles                                                                 cycle                   2.551.124,64
    SM [%]                                                                               %                          65,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,82
    Executed Ipc Elapsed                                                        inst/cycle                           2,63
    Issue Slots Busy                                                                     %                          70,61
    Issued Ipc Active                                                           inst/cycle                           2,82
    SM Busy                                                                              %                          70,61
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,76
    Mem Busy                                                                             %                          14,73
    Max Bandwidth                                                                        %                          21,94
    L1/TEX Hit Rate                                                                      %                          96,89
    L2 Hit Rate                                                                          %                          87,34
    Mem Pipes Busy                                                                       %                          21,94
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          70,65
    Issued Warp Per Scheduler                                                                                        0,71
    No Eligible                                                                          %                          29,35
    Active Warps Per Scheduler                                                        warp                           7,93
    Eligible Warps Per Scheduler                                                      warp                           1,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,23
    Warp Cycles Per Executed Instruction                                             cycle                          11,23
    Warp Cycles Per Issue Active                                                      warp                          11,23
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.5 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.801.216
    Executed Instructions                                                             inst                    100.868.096
    Avg. Issued Instructions Per Scheduler                                            inst                   1.801.255,18
    Issued Instructions                                                               inst                    100.870.290
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          99,05
    Achieved Active Warps Per SM                                                      warp                          31,70
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 13631488 (1.86x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:05, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        170.632
    Memory [%]                                                                           %                           5,63
    SOL DRAM                                                                             %                           1,78
    Duration                                                                       usecond                         122,94
    SOL L1/TEX Cache                                                                     %                           3,53
    SOL L2 Cache                                                                         %                           5,63
    SM Active Cycles                                                                 cycle                     167.660,14
    SM [%]                                                                               %                          85,34
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 41% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,25
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.8%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,40
    Mem Busy                                                                             %                           3,38
    Max Bandwidth                                                                        %                           5,63
    L1/TEX Hit Rate                                                                      %                          73,74
    L2 Hit Rate                                                                          %                          72,35
    Mem Pipes Busy                                                                       %                          22,22
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,26
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,74
    Active Warps Per Scheduler                                                        warp                           7,52
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.52 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         176,49
    Warp Cycles Per Executed Instruction                                             cycle                         176,86
    Warp Cycles Per Issue Active                                                      warp                         176,49
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 96.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 54.9% of the total average of 176.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 71.3 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 40.4% of the total average of 176.5 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       7.108,71
    Executed Instructions                                                             inst                        398.088
    Avg. Issued Instructions Per Scheduler                                            inst                       7.123,48
    Issued Instructions                                                               inst                        398.915
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          93,61
    Achieved Active Warps Per SM                                                      warp                          29,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:06, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,41
    SM Frequency                                                             cycle/nsecond                           1,23
    Elapsed Cycles                                                                   cycle                         10.579
    Memory [%]                                                                           %                          83,80
    SOL DRAM                                                                             %                          33,20
    Duration                                                                       usecond                           8,61
    SOL L1/TEX Cache                                                                     %                          41,57
    SOL L2 Cache                                                                         %                          83,80
    SM Active Cycles                                                                 cycle                       9.302,71
    SM [%]                                                                               %                          33,25
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,50
    Executed Ipc Elapsed                                                        inst/cycle                           0,44
    Issue Slots Busy                                                                     %                          12,82
    Issued Ipc Active                                                           inst/cycle                           0,51
    SM Busy                                                                              %                          14,68
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          60,03
    Mem Busy                                                                             %                          41,92
    Max Bandwidth                                                                        %                          83,80
    L1/TEX Hit Rate                                                                      %                          72,33
    L2 Hit Rate                                                                          %                          66,66
    Mem Pipes Busy                                                                       %                          33,25
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          12,89
    Issued Warp Per Scheduler                                                                                        0,13
    No Eligible                                                                          %                          87,11
    Active Warps Per Scheduler                                                        warp                           7,13
    Eligible Warps Per Scheduler                                                      warp                           0,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 7.8 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.13 active warps per scheduler, but only an average of 0.17 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          55,32
    Warp Cycles Per Executed Instruction                                             cycle                          56,36
    Warp Cycles Per Issue Active                                                      warp                          55,32
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 29.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 53.3% of the total average of 55.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.170,29
    Executed Instructions                                                             inst                         65.536
    Avg. Issued Instructions Per Scheduler                                            inst                       1.192,34
    Issued Instructions                                                               inst                         66.771
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,33
    Achieved Active Warps Per SM                                                      warp                          21,87
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725ede0                

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:32:06, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,27
    SM Frequency                                                             cycle/nsecond                           1,13
    Elapsed Cycles                                                                   cycle                         11.723
    Memory [%]                                                                           %                          51,16
    SOL DRAM                                                                             %                          51,16
    Duration                                                                       usecond                          10,34
    SOL L1/TEX Cache                                                                     %                          35,70
    SOL L2 Cache                                                                         %                          49,50
    SM Active Cycles                                                                 cycle                       9.815,64
    SM [%]                                                                               %                          25,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,45
    Executed Ipc Elapsed                                                        inst/cycle                           0,37
    Issue Slots Busy                                                                     %                          11,32
    Issued Ipc Active                                                           inst/cycle                           0,45
    SM Busy                                                                              %                          11,92
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          83,12
    Mem Busy                                                                             %                          49,50
    Max Bandwidth                                                                        %                          51,16
    L1/TEX Hit Rate                                                                      %                          48,57
    L2 Hit Rate                                                                          %                          48,15
    Mem Pipes Busy                                                                       %                          25,00
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,97
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,03
    Active Warps Per Scheduler                                                        warp                           5,43
    Eligible Warps Per Scheduler                                                      warp                           0,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.1 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.43 active warps per scheduler, but only an average of 0.13 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          49,52
    Warp Cycles Per Executed Instruction                                             cycle                          50,14
    Warp Cycles Per Issue Active                                                      warp                          49,52
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 36.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.3% of the total average of 49.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.097,14
    Executed Instructions                                                             inst                         61.440
    Avg. Issued Instructions Per Scheduler                                            inst                       1.110,86
    Issued Instructions                                                               inst                         62.208
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          72,09
    Achieved Active Warps Per SM                                                      warp                          23,07
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d490                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d4a0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d4d0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:06, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,58
    SM Frequency                                                             cycle/nsecond                           1,33
    Elapsed Cycles                                                                   cycle                         11.579
    Memory [%]                                                                           %                          22,90
    SOL DRAM                                                                             %                          22,90
    Duration                                                                       usecond                           8,67
    SOL L1/TEX Cache                                                                     %                          18,76
    SOL L2 Cache                                                                         %                          16,37
    SM Active Cycles                                                                 cycle                       9.358,57
    SM [%]                                                                               %                          15,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,34
    Executed Ipc Elapsed                                                        inst/cycle                           0,28
    Issue Slots Busy                                                                     %                           8,74
    Issued Ipc Active                                                           inst/cycle                           0,35
    SM Busy                                                                              %                           8,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          46,30
    Mem Busy                                                                             %                          16,32
    Max Bandwidth                                                                        %                          22,90
    L1/TEX Hit Rate                                                                      %                          47,16
    L2 Hit Rate                                                                          %                          19,74
    Mem Pipes Busy                                                                       %                          15,18
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,06
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,94
    Active Warps Per Scheduler                                                        warp                           4,70
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.70 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          51,95
    Warp Cycles Per Executed Instruction                                             cycle                          52,84
    Warp Cycles Per Issue Active                                                      warp                          51,95
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 39.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 76.7% of the total average of 51.9   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         804,57
    Executed Instructions                                                             inst                         45.056
    Avg. Issued Instructions Per Scheduler                                            inst                         818,38
    Issued Instructions                                                               inst                         45.829
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,09
    Achieved Active Warps Per SM                                                      warp                          19,23
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:07, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,46
    Elapsed Cycles                                                                   cycle                      4.316.417
    Memory [%]                                                                           %                          13,91
    SOL DRAM                                                                             %                           1,88
    Duration                                                                       msecond                           2,94
    SOL L1/TEX Cache                                                                     %                          19,57
    SOL L2 Cache                                                                         %                           3,16
    SM Active Cycles                                                                 cycle                   4.086.709,79
    SM [%]                                                                               %                          41,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,76
    Executed Ipc Elapsed                                                        inst/cycle                           1,67
    Issue Slots Busy                                                                     %                          44,01
    Issued Ipc Active                                                           inst/cycle                           1,76
    SM Busy                                                                              %                          44,01
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,61
    Mem Busy                                                                             %                           9,79
    Max Bandwidth                                                                        %                          13,91
    L1/TEX Hit Rate                                                                      %                          96,31
    L2 Hit Rate                                                                          %                          86,56
    Mem Pipes Busy                                                                       %                          13,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          44,69
    Issued Warp Per Scheduler                                                                                        0,45
    No Eligible                                                                          %                          55,31
    Active Warps Per Scheduler                                                        warp                           6,26
    Eligible Warps Per Scheduler                                                      warp                           1,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.26 active warps per scheduler, but only an average of 1.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,01
    Warp Cycles Per Executed Instruction                                             cycle                          14,01
    Warp Cycles Per Issue Active                                                      warp                          14,01
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.1 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 43.3% of the total average of 14.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.5 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.798.473,14
    Executed Instructions                                                             inst                    100.714.496
    Avg. Issued Instructions Per Scheduler                                            inst                   1.798.515,34
    Issued Instructions                                                               inst                    100.716.859
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 22.6%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,39
    Achieved Active Warps Per SM                                                      warp                          24,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 13631488 (1.86x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7265fa0                  

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:07, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                         45.604
    Memory [%]                                                                           %                           3,16
    SOL DRAM                                                                             %                           1,69
    Duration                                                                       usecond                          33,28
    SOL L1/TEX Cache                                                                     %                           3,29
    SOL L2 Cache                                                                         %                           3,16
    SM Active Cycles                                                                 cycle                      59.750,43
    SM [%]                                                                               %                          79,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 38% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,12
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           3,02
    Issued Ipc Active                                                           inst/cycle                           0,12
    SM Busy                                                                              %                          60,90
    ---------------------------------------------------------------------- --------------- ------------------------------
          FP64 is the highest-utilized pipeline (60.9%). It executes 64-bit floating point operations. The pipeline is  
          well-utilized and might become a bottleneck if more work is added.                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,21
    Mem Busy                                                                             %                           3,16
    Max Bandwidth                                                                        %                           3,14
    L1/TEX Hit Rate                                                                      %                          74,65
    L2 Hit Rate                                                                          %                          73,40
    Mem Pipes Busy                                                                       %                          20,81
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,26
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,74
    Active Warps Per Scheduler                                                        warp                           7,03
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.03 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         164,94
    Warp Cycles Per Executed Instruction                                             cycle                         167,06
    Warp Cycles Per Issue Active                                                      warp                         164,94
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 195.6 cycles being stalled waiting for a scoreboard dependency on  
          a L1TEX (local, global, surface, texture) operation. This represents about 118.6% of the total average of     
          164.9 cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses  
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 61.7 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 37.4% of the total average of 164.9 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.781,50
    Executed Instructions                                                             inst                         99.764
    Avg. Issued Instructions Per Scheduler                                            inst                       1.804,34
    Issued Instructions                                                               inst                        101.043
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86,79
    Achieved Active Warps Per SM                                                      warp                          27,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a72623c0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7262670                  

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:07, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,42
    SM Frequency                                                             cycle/usecond                         906,65
    Elapsed Cycles                                                                   cycle                          4.526
    Memory [%]                                                                           %                          25,20
    SOL DRAM                                                                             %                          14,07
    Duration                                                                       usecond                           4,99
    SOL L1/TEX Cache                                                                     %                          29,17
    SOL L2 Cache                                                                         %                          25,20
    SM Active Cycles                                                                 cycle                       3.008,64
    SM [%]                                                                               %                          19,39
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,26
    Issue Slots Busy                                                                     %                          10,45
    Issued Ipc Active                                                           inst/cycle                           0,42
    SM Busy                                                                              %                          11,35
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          25,62
    Mem Busy                                                                             %                          25,20
    Max Bandwidth                                                                        %                          20,82
    L1/TEX Hit Rate                                                                      %                          73,70
    L2 Hit Rate                                                                          %                          74,18
    Mem Pipes Busy                                                                       %                          19,39
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,21
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,79
    Active Warps Per Scheduler                                                        warp                           4,84
    Eligible Warps Per Scheduler                                                      warp                           0,18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.84 active warps per scheduler, but only an average of 0.18 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,58
    Warp Cycles Per Executed Instruction                                             cycle                          56,49
    Warp Cycles Per Issue Active                                                      warp                          52,58
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 30.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 57.5% of the total average of 52.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         292,57
    Executed Instructions                                                             inst                         16.384
    Avg. Issued Instructions Per Scheduler                                            inst                         314,30
    Issued Instructions                                                               inst                         17.601
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 27.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          72,21
    Achieved Active Warps Per SM                                                      warp                          23,11
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725edc0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725ede0                  

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:07, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,80
    SM Frequency                                                             cycle/nsecond                           1,17
    Elapsed Cycles                                                                   cycle                          4.555
    Memory [%]                                                                           %                          11,29
    SOL DRAM                                                                             %                          11,29
    Duration                                                                       usecond                           3,90
    SOL L1/TEX Cache                                                                     %                          15,78
    SOL L2 Cache                                                                         %                          10,49
    SM Active Cycles                                                                 cycle                       2.781,21
    SM [%]                                                                               %                           9,64
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,29
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           7,73
    Issued Ipc Active                                                           inst/cycle                           0,31
    SM Busy                                                                              %                           7,73
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          26,06
    Mem Busy                                                                             %                          10,49
    Max Bandwidth                                                                        %                          11,29
    L1/TEX Hit Rate                                                                      %                          49,33
    L2 Hit Rate                                                                          %                          18,87
    Mem Pipes Busy                                                                       %                           9,64
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,02
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,98
    Active Warps Per Scheduler                                                        warp                           5,41
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.41 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          67,46
    Warp Cycles Per Executed Instruction                                             cycle                          72,09
    Warp Cycles Per Issue Active                                                      warp                          67,46
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 67.3% of the total average of 67.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         201,14
    Executed Instructions                                                             inst                         11.264
    Avg. Issued Instructions Per Scheduler                                            inst                         214,95
    Issued Instructions                                                               inst                         12.037
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 29.0%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          71,03
    Achieved Active Warps Per SM                                                      warp                          22,73
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725bc80                  

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:08, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      3.109.125
    Memory [%]                                                                           %                          43,48
    SOL DRAM                                                                             %                           5,41
    Duration                                                                       msecond                           2,26
    SOL L1/TEX Cache                                                                     %                          54,07
    SOL L2 Cache                                                                         %                           5,89
    SM Active Cycles                                                                 cycle                   2.822.613,29
    SM [%]                                                                               %                          55,28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 3% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,43
    Executed Ipc Elapsed                                                        inst/cycle                           2,21
    Issue Slots Busy                                                                     %                          60,75
    Issued Ipc Active                                                           inst/cycle                           2,43
    SM Busy                                                                              %                          60,75
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           9,71
    Mem Busy                                                                             %                          27,04
    Max Bandwidth                                                                        %                          43,48
    L1/TEX Hit Rate                                                                      %                          98,45
    L2 Hit Rate                                                                          %                          48,65
    Mem Pipes Busy                                                                       %                          43,48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          60,71
    Issued Warp Per Scheduler                                                                                        0,61
    No Eligible                                                                          %                          39,29
    Active Warps Per Scheduler                                                        warp                           7,24
    Eligible Warps Per Scheduler                                                      warp                           1,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,92
    Warp Cycles Per Executed Instruction                                             cycle                          11,92
    Warp Cycles Per Issue Active                                                      warp                          11,92
    Avg. Active Threads Per Warp                                                                                    22,18
    Avg. Not Predicated Off Threads Per Warp                                                                        19,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 22.2 threads being active per cycle. This is further reduced    
          to 20.0 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.714.688
    Executed Instructions                                                             inst                     96.022.528
    Avg. Issued Instructions Per Scheduler                                            inst                   1.714.726,88
    Issued Instructions                                                               inst                     96.024.705
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          83,46
    Achieved Active Warps Per SM                                                      warp                          26,71
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4194304 transactions, got 8192000 (1.95x) at PC 0x7f58a7265580            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4980736 transactions, got 8290304 (1.66x) at PC 0x7f58a7265590            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4980736 transactions, got 8290304 (1.66x) at PC 0x7f58a7265650            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7265fa0                  

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:08, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         45.704
    Memory [%]                                                                           %                           3,15
    SOL DRAM                                                                             %                           1,72
    Duration                                                                       usecond                          33,18
    SOL L1/TEX Cache                                                                     %                           3,29
    SOL L2 Cache                                                                         %                           3,15
    SM Active Cycles                                                                 cycle                      42.630,93
    SM [%]                                                                               %                          79,72
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 38% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,21
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.4%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,25
    Mem Busy                                                                             %                           3,15
    Max Bandwidth                                                                        %                           3,12
    L1/TEX Hit Rate                                                                      %                          74,79
    L2 Hit Rate                                                                          %                          73,91
    Mem Pipes Busy                                                                       %                          20,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,24
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,76
    Active Warps Per Scheduler                                                        warp                           7,01
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.01 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         165,33
    Warp Cycles Per Executed Instruction                                             cycle                         166,72
    Warp Cycles Per Issue Active                                                      warp                         165,33
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 93.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.4% of the total average of 165.3  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 62.0 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 37.5% of the total average of 165.3 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.781,50
    Executed Instructions                                                             inst                         99.764
    Avg. Issued Instructions Per Scheduler                                            inst                       1.796,52
    Issued Instructions                                                               inst                        100.605
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,14
    Achieved Active Warps Per SM                                                      warp                          27,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a72623c0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7262670                  

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:08, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,45
    SM Frequency                                                             cycle/nsecond                           1,17
    Elapsed Cycles                                                                   cycle                          4.546
    Memory [%]                                                                           %                          24,80
    SOL DRAM                                                                             %                          14,52
    Duration                                                                       usecond                           3,87
    SOL L1/TEX Cache                                                                     %                          29,67
    SOL L2 Cache                                                                         %                          24,80
    SM Active Cycles                                                                 cycle                       2.957,79
    SM [%]                                                                               %                          19,32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,40
    Executed Ipc Elapsed                                                        inst/cycle                           0,26
    Issue Slots Busy                                                                     %                          10,63
    Issued Ipc Active                                                           inst/cycle                           0,43
    SM Busy                                                                              %                          11,54
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          27,02
    Mem Busy                                                                             %                          24,80
    Max Bandwidth                                                                        %                          19,49
    L1/TEX Hit Rate                                                                      %                          73,79
    L2 Hit Rate                                                                          %                          65,89
    Mem Pipes Busy                                                                       %                          19,32
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,68
    Issued Warp Per Scheduler                                                                                        0,11
    No Eligible                                                                          %                          89,32
    Active Warps Per Scheduler                                                        warp                           5,66
    Eligible Warps Per Scheduler                                                      warp                           0,21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.4 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.66 active warps per scheduler, but only an average of 0.21 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,00
    Warp Cycles Per Executed Instruction                                             cycle                          56,95
    Warp Cycles Per Issue Active                                                      warp                          53,00
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 29.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.0% of the total average of 53.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         292,57
    Executed Instructions                                                             inst                         16.384
    Avg. Issued Instructions Per Scheduler                                            inst                         314,34
    Issued Instructions                                                               inst                         17.603
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 28.9%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          71,06
    Achieved Active Warps Per SM                                                      warp                          22,74
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725edc0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725ede0                  

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:09, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,32
    SM Frequency                                                             cycle/nsecond                           1,23
    Elapsed Cycles                                                                   cycle                          4.637
    Memory [%]                                                                           %                          15,72
    SOL DRAM                                                                             %                          15,72
    Duration                                                                       usecond                           3,78
    SOL L1/TEX Cache                                                                     %                          15,87
    SOL L2 Cache                                                                         %                          10,30
    SM Active Cycles                                                                 cycle                       2.764,50
    SM [%]                                                                               %                           9,47
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,29
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           7,85
    Issued Ipc Active                                                           inst/cycle                           0,31
    SM Busy                                                                              %                           7,85
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          26,60
    Mem Busy                                                                             %                          10,30
    Max Bandwidth                                                                        %                          15,72
    L1/TEX Hit Rate                                                                      %                          49,76
    L2 Hit Rate                                                                          %                          19,29
    Mem Pipes Busy                                                                       %                           9,47
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,01
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,99
    Active Warps Per Scheduler                                                        warp                           5,38
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.38 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          67,15
    Warp Cycles Per Executed Instruction                                             cycle                          72,49
    Warp Cycles Per Issue Active                                                      warp                          67,15
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 41.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 62.4% of the total average of 67.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         201,14
    Executed Instructions                                                             inst                         11.264
    Avg. Issued Instructions Per Scheduler                                            inst                         217,14
    Issued Instructions                                                               inst                         12.160
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 31.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,50
    Achieved Active Warps Per SM                                                      warp                          21,92
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725bc80                  

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:09, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                      2.738.721
    Memory [%]                                                                           %                          21,98
    SOL DRAM                                                                             %                           1,21
    Duration                                                                       msecond                           1,97
    SOL L1/TEX Cache                                                                     %                          29,96
    SOL L2 Cache                                                                         %                           7,21
    SM Active Cycles                                                                 cycle                   3.255.871,93
    SM [%]                                                                               %                          65,89
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,21
    Executed Ipc Elapsed                                                        inst/cycle                           2,64
    Issue Slots Busy                                                                     %                          55,32
    Issued Ipc Active                                                           inst/cycle                           2,21
    SM Busy                                                                              %                          55,32
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,33
    Mem Busy                                                                             %                          14,98
    Max Bandwidth                                                                        %                          21,98
    L1/TEX Hit Rate                                                                      %                          96,89
    L2 Hit Rate                                                                          %                          41,10
    Mem Pipes Busy                                                                       %                          21,98
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          65,59
    Issued Warp Per Scheduler                                                                                        0,66
    No Eligible                                                                          %                          34,41
    Active Warps Per Scheduler                                                        warp                           9,86
    Eligible Warps Per Scheduler                                                      warp                           1,77
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          15,03
    Warp Cycles Per Executed Instruction                                             cycle                          15,03
    Warp Cycles Per Issue Active                                                      warp                          15,03
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 5.1 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 34.1% of the total average of 15.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.5 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.801.216
    Executed Instructions                                                             inst                    100.868.096
    Avg. Issued Instructions Per Scheduler                                            inst                   1.801.255,07
    Issued Instructions                                                               inst                    100.870.284
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          93,33
    Achieved Active Warps Per SM                                                      warp                          29,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 13631488 (1.86x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:10, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,50
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                        170.833
    Memory [%]                                                                           %                           4,74
    SOL DRAM                                                                             %                           2,25
    Duration                                                                       usecond                         122,66
    SOL L1/TEX Cache                                                                     %                           3,54
    SOL L2 Cache                                                                         %                           4,74
    SM Active Cycles                                                                 cycle                     167.687,43
    SM [%]                                                                               %                          85,24
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 41% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,25
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.8%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,32
    Mem Busy                                                                             %                           4,74
    Max Bandwidth                                                                        %                           3,34
    L1/TEX Hit Rate                                                                      %                          73,70
    L2 Hit Rate                                                                          %                          51,33
    Mem Pipes Busy                                                                       %                          22,19
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,26
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,74
    Active Warps Per Scheduler                                                        warp                           7,52
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.52 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         176,49
    Warp Cycles Per Executed Instruction                                             cycle                         176,86
    Warp Cycles Per Issue Active                                                      warp                         176,49
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 96.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 54.9% of the total average of 176.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 71.0 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 40.2% of the total average of 176.5 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       7.108,71
    Executed Instructions                                                             inst                        398.088
    Avg. Issued Instructions Per Scheduler                                            inst                       7.123,75
    Issued Instructions                                                               inst                        398.930
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          93,79
    Achieved Active Warps Per SM                                                      warp                          30,01
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:10, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,37
    SM Frequency                                                             cycle/nsecond                           1,30
    Elapsed Cycles                                                                   cycle                         11.304
    Memory [%]                                                                           %                          39,80
    SOL DRAM                                                                             %                          27,46
    Duration                                                                       usecond                           8,67
    SOL L1/TEX Cache                                                                     %                          38,92
    SOL L2 Cache                                                                         %                          39,80
    SM Active Cycles                                                                 cycle                       9.277,43
    SM [%]                                                                               %                          31,12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,50
    Executed Ipc Elapsed                                                        inst/cycle                           0,41
    Issue Slots Busy                                                                     %                          12,85
    Issued Ipc Active                                                           inst/cycle                           0,51
    SM Busy                                                                              %                          14,72
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          48,24
    Mem Busy                                                                             %                          39,80
    Max Bandwidth                                                                        %                          32,67
    L1/TEX Hit Rate                                                                      %                          72,30
    L2 Hit Rate                                                                          %                          65,72
    Mem Pipes Busy                                                                       %                          31,12
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          12,56
    Issued Warp Per Scheduler                                                                                        0,13
    No Eligible                                                                          %                          87,44
    Active Warps Per Scheduler                                                        warp                           5,31
    Eligible Warps Per Scheduler                                                      warp                           0,16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 8.0 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.31 active warps per scheduler, but only an average of 0.16 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          42,29
    Warp Cycles Per Executed Instruction                                             cycle                          43,08
    Warp Cycles Per Issue Active                                                      warp                          42,29
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 29.9 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 70.7% of the total average of 42.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.170,29
    Executed Instructions                                                             inst                         65.536
    Avg. Issued Instructions Per Scheduler                                            inst                       1.192,02
    Issued Instructions                                                               inst                         66.753
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          69,39
    Achieved Active Warps Per SM                                                      warp                          22,21
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725ede0                

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:32:10, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,29
    Elapsed Cycles                                                                   cycle                         11.705
    Memory [%]                                                                           %                          49,90
    SOL DRAM                                                                             %                          46,79
    Duration                                                                       usecond                           9,09
    SOL L1/TEX Cache                                                                     %                          35,93
    SOL L2 Cache                                                                         %                          49,90
    SM Active Cycles                                                                 cycle                      10.668,21
    SM [%]                                                                               %                          25,03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,41
    Executed Ipc Elapsed                                                        inst/cycle                           0,38
    Issue Slots Busy                                                                     %                          10,41
    Issued Ipc Active                                                           inst/cycle                           0,42
    SM Busy                                                                              %                          10,97
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          88,57
    Mem Busy                                                                             %                          49,90
    Max Bandwidth                                                                        %                          46,79
    L1/TEX Hit Rate                                                                      %                          64,93
    L2 Hit Rate                                                                          %                          51,50
    Mem Pipes Busy                                                                       %                          25,03
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,43
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,57
    Active Warps Per Scheduler                                                        warp                           5,16
    Eligible Warps Per Scheduler                                                      warp                           0,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.16 active warps per scheduler, but only an average of 0.13 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          49,49
    Warp Cycles Per Executed Instruction                                             cycle                          50,11
    Warp Cycles Per Issue Active                                                      warp                          49,49
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 39.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 79.5% of the total average of 49.5   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.097,14
    Executed Instructions                                                             inst                         61.440
    Avg. Issued Instructions Per Scheduler                                            inst                       1.110,91
    Issued Instructions                                                               inst                         62.211
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          69,65
    Achieved Active Warps Per SM                                                      warp                          22,29
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d490                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d4a0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d4d0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:10, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,37
    SM Frequency                                                             cycle/nsecond                           1,27
    Elapsed Cycles                                                                   cycle                         11.056
    Memory [%]                                                                           %                          26,36
    SOL DRAM                                                                             %                          26,36
    Duration                                                                       usecond                           8,70
    SOL L1/TEX Cache                                                                     %                          19,12
    SOL L2 Cache                                                                         %                          17,14
    SM Active Cycles                                                                 cycle                       9.181,29
    SM [%]                                                                               %                          15,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,35
    Executed Ipc Elapsed                                                        inst/cycle                           0,29
    Issue Slots Busy                                                                     %                           8,91
    Issued Ipc Active                                                           inst/cycle                           0,36
    SM Busy                                                                              %                           8,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          46,14
    Mem Busy                                                                             %                          17,11
    Max Bandwidth                                                                        %                          26,36
    L1/TEX Hit Rate                                                                      %                          47,14
    L2 Hit Rate                                                                          %                          19,30
    Mem Pipes Busy                                                                       %                          15,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,12
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,88
    Active Warps Per Scheduler                                                        warp                           4,81
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 11.0 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.81 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,76
    Warp Cycles Per Executed Instruction                                             cycle                          53,67
    Warp Cycles Per Issue Active                                                      warp                          52,76
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 39.5 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 74.9% of the total average of 52.8   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         804,57
    Executed Instructions                                                             inst                         45.056
    Avg. Issued Instructions Per Scheduler                                            inst                         818,50
    Issued Instructions                                                               inst                         45.836
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          60,74
    Achieved Active Warps Per SM                                                      warp                          19,44
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725bc80                

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:11, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,31
    Elapsed Cycles                                                                   cycle                      4.088.014
    Memory [%]                                                                           %                          14,70
    SOL DRAM                                                                             %                           0,93
    Duration                                                                       msecond                           3,12
    SOL L1/TEX Cache                                                                     %                          20,67
    SOL L2 Cache                                                                         %                           3,53
    SM Active Cycles                                                                 cycle                   4.082.826,79
    SM [%]                                                                               %                          44,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,76
    Executed Ipc Elapsed                                                        inst/cycle                           1,76
    Issue Slots Busy                                                                     %                          44,05
    Issued Ipc Active                                                           inst/cycle                           1,76
    SM Busy                                                                              %                          44,05
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           1,79
    Mem Busy                                                                             %                          10,33
    Max Bandwidth                                                                        %                          14,70
    L1/TEX Hit Rate                                                                      %                          96,25
    L2 Hit Rate                                                                          %                          50,34
    Mem Pipes Busy                                                                       %                          14,70
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          45,70
    Issued Warp Per Scheduler                                                                                        0,46
    No Eligible                                                                          %                          54,30
    Active Warps Per Scheduler                                                        warp                           6,45
    Eligible Warps Per Scheduler                                                      warp                           1,13
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 2.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          6.45 active warps per scheduler, but only an average of 1.13 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          14,11
    Warp Cycles Per Executed Instruction                                             cycle                          14,11
    Warp Cycles Per Issue Active                                                      warp                          14,11
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.0 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 42.6% of the total average of 14.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.5 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                   1.798.473,14
    Executed Instructions                                                             inst                    100.714.496
    Avg. Issued Instructions Per Scheduler                                            inst                      1.798.512
    Issued Instructions                                                               inst                    100.716.672
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 22.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          77,18
    Achieved Active Warps Per SM                                                      warp                          24,70
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 13631488 (1.86x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7265fa0                  

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:11, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,39
    Elapsed Cycles                                                                   cycle                         45.815
    Memory [%]                                                                           %                           3,15
    SOL DRAM                                                                             %                           1,67
    Duration                                                                       usecond                          32,99
    SOL L1/TEX Cache                                                                     %                           3,29
    SOL L2 Cache                                                                         %                           3,15
    SM Active Cycles                                                                 cycle                         42.616
    SM [%]                                                                               %                          79,53
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 38% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,23
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,39
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.4%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,17
    Mem Busy                                                                             %                           3,15
    Max Bandwidth                                                                        %                           3,13
    L1/TEX Hit Rate                                                                      %                          74,62
    L2 Hit Rate                                                                          %                          73,08
    Mem Pipes Busy                                                                       %                          20,71
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,26
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,74
    Active Warps Per Scheduler                                                        warp                           7,02
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.5 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.02 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         164,95
    Warp Cycles Per Executed Instruction                                             cycle                         167,04
    Warp Cycles Per Issue Active                                                      warp                         164,95
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 92.7 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.2% of the total average of 165.0  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 61.6 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 37.3% of the total average of 165.0 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.781,50
    Executed Instructions                                                             inst                         99.764
    Avg. Issued Instructions Per Scheduler                                            inst                       1.804,09
    Issued Instructions                                                               inst                        101.029
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,34
    Achieved Active Warps Per SM                                                      warp                          27,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a72623c0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7262670                  

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:11, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,38
    SM Frequency                                                             cycle/usecond                         894,41
    Elapsed Cycles                                                                   cycle                          4.494
    Memory [%]                                                                           %                          25,04
    SOL DRAM                                                                             %                          12,04
    Duration                                                                       usecond                           5,02
    SOL L1/TEX Cache                                                                     %                          29,26
    SOL L2 Cache                                                                         %                          25,04
    SM Active Cycles                                                                 cycle                       2.999,36
    SM [%]                                                                               %                          19,53
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,26
    Issue Slots Busy                                                                     %                          10,49
    Issued Ipc Active                                                           inst/cycle                           0,42
    SM Busy                                                                              %                          11,38
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          21,20
    Mem Busy                                                                             %                          25,04
    Max Bandwidth                                                                        %                          21,36
    L1/TEX Hit Rate                                                                      %                          73,76
    L2 Hit Rate                                                                          %                          75,68
    Mem Pipes Busy                                                                       %                          19,53
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,44
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,56
    Active Warps Per Scheduler                                                        warp                           5,44
    Eligible Warps Per Scheduler                                                      warp                           0,20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.44 active warps per scheduler, but only an average of 0.20 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          52,10
    Warp Cycles Per Executed Instruction                                             cycle                          56,01
    Warp Cycles Per Issue Active                                                      warp                          52,10
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 31.4 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 60.3% of the total average of 52.1   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         292,57
    Executed Instructions                                                             inst                         16.384
    Avg. Issued Instructions Per Scheduler                                            inst                         314,50
    Issued Instructions                                                               inst                         17.612
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 28.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          71,92
    Achieved Active Warps Per SM                                                      warp                          23,01
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725edc0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725ede0                  

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:12, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,37
    SM Frequency                                                             cycle/nsecond                           1,78
    Elapsed Cycles                                                                   cycle                          6.501
    Memory [%]                                                                           %                          19,37
    SOL DRAM                                                                             %                          19,37
    Duration                                                                       usecond                           3,65
    SOL L1/TEX Cache                                                                     %                          15,49
    SOL L2 Cache                                                                         %                           7,37
    SM Active Cycles                                                                 cycle                       2.833,07
    SM [%]                                                                               %                           6,75
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,28
    Executed Ipc Elapsed                                                        inst/cycle                           0,12
    Issue Slots Busy                                                                     %                           7,59
    Issued Ipc Active                                                           inst/cycle                           0,30
    SM Busy                                                                              %                           7,59
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          33,92
    Mem Busy                                                                             %                           7,37
    Max Bandwidth                                                                        %                          19,37
    L1/TEX Hit Rate                                                                      %                          49,11
    L2 Hit Rate                                                                          %                          21,13
    Mem Pipes Busy                                                                       %                           6,75
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           7,79
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          92,21
    Active Warps Per Scheduler                                                        warp                           5,38
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.8 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.38 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          69,03
    Warp Cycles Per Executed Instruction                                             cycle                          73,81
    Warp Cycles Per Issue Active                                                      warp                          69,03
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 45.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 65.2% of the total average of 69.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         201,14
    Executed Instructions                                                             inst                         11.264
    Avg. Issued Instructions Per Scheduler                                            inst                         215,07
    Issued Instructions                                                               inst                         12.044
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 31.0%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,96
    Achieved Active Warps Per SM                                                      warp                          22,07
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725bc80                  

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:12, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,51
    SM Frequency                                                             cycle/nsecond                           1,37
    Elapsed Cycles                                                                   cycle                      2.889.104
    Memory [%]                                                                           %                          46,80
    SOL DRAM                                                                             %                           2,43
    Duration                                                                       msecond                           2,10
    SOL L1/TEX Cache                                                                     %                          58,20
    SOL L2 Cache                                                                         %                           6,44
    SM Active Cycles                                                                 cycle                   3.060.083,07
    SM [%]                                                                               %                          59,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 4% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,24
    Executed Ipc Elapsed                                                        inst/cycle                           2,38
    Issue Slots Busy                                                                     %                          56,04
    Issued Ipc Active                                                           inst/cycle                           2,24
    SM Busy                                                                              %                          56,04
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           4,68
    Mem Busy                                                                             %                          29,10
    Max Bandwidth                                                                        %                          46,80
    L1/TEX Hit Rate                                                                      %                          98,46
    L2 Hit Rate                                                                          %                          34,51
    Mem Pipes Busy                                                                       %                          46,80
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          60,02
    Issued Warp Per Scheduler                                                                                        0,60
    No Eligible                                                                          %                          39,98
    Active Warps Per Scheduler                                                        warp                           7,23
    Eligible Warps Per Scheduler                                                      warp                           1,55
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          12,04
    Warp Cycles Per Executed Instruction                                             cycle                          12,04
    Warp Cycles Per Issue Active                                                      warp                          12,04
    Avg. Active Threads Per Warp                                                                                    22,18
    Avg. Not Predicated Off Threads Per Warp                                                                        19,99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 4.2 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 34.8% of the total average of 12.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 22.2 threads being active per cycle. This is further reduced    
          to 20.0 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.714.688
    Executed Instructions                                                             inst                     96.022.528
    Avg. Issued Instructions Per Scheduler                                            inst                   1.714.726,80
    Issued Instructions                                                               inst                     96.024.701
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          83,95
    Achieved Active Warps Per SM                                                      warp                          26,86
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 4194304 transactions, got 8192000 (1.95x) at PC 0x7f58a7265580            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4980736 transactions, got 8290304 (1.66x) at PC 0x7f58a7265590            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 4980736 transactions, got 8290304 (1.66x) at PC 0x7f58a7265650            
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7265fa0                  

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:12, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,46
    SM Frequency                                                             cycle/nsecond                           1,36
    Elapsed Cycles                                                                   cycle                         45.547
    Memory [%]                                                                           %                           3,17
    SOL DRAM                                                                             %                           1,78
    Duration                                                                       usecond                          33,38
    SOL L1/TEX Cache                                                                     %                           3,29
    SOL L2 Cache                                                                         %                           3,17
    SM Active Cycles                                                                 cycle                      42.681,36
    SM [%]                                                                               %                          80,01
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 38% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,16
    Issue Slots Busy                                                                     %                           4,21
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          85,26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (85.3%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           3,33
    Mem Busy                                                                             %                           3,17
    Max Bandwidth                                                                        %                           3,17
    L1/TEX Hit Rate                                                                      %                          74,57
    L2 Hit Rate                                                                          %                         135,73
    Mem Pipes Busy                                                                       %                          20,83
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,24
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,76
    Active Warps Per Scheduler                                                        warp                           7,03
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.6 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.03 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         165,55
    Warp Cycles Per Executed Instruction                                             cycle                         166,93
    Warp Cycles Per Issue Active                                                      warp                         165,55
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,81
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 93.2 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 56.3% of the total average of 165.6  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 61.9 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 37.4% of the total average of 165.6 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.781,50
    Executed Instructions                                                             inst                         99.764
    Avg. Issued Instructions Per Scheduler                                            inst                       1.796,32
    Issued Instructions                                                               inst                        100.594
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          87,10
    Achieved Active Warps Per SM                                                      warp                          27,87
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a72623c0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a7262670                  

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:13, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,27
    SM Frequency                                                             cycle/nsecond                           1,13
    Elapsed Cycles                                                                   cycle                          4.443
    Memory [%]                                                                           %                          25,11
    SOL DRAM                                                                             %                          16,39
    Duration                                                                       usecond                           3,94
    SOL L1/TEX Cache                                                                     %                          29,22
    SOL L2 Cache                                                                         %                          25,11
    SM Active Cycles                                                                 cycle                       3.003,71
    SM [%]                                                                               %                          19,76
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 1% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,39
    Executed Ipc Elapsed                                                        inst/cycle                           0,26
    Issue Slots Busy                                                                     %                          10,47
    Issued Ipc Active                                                           inst/cycle                           0,42
    SM Busy                                                                              %                          11,36
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          26,60
    Mem Busy                                                                             %                          25,11
    Max Bandwidth                                                                        %                          20,81
    L1/TEX Hit Rate                                                                      %                          74,15
    L2 Hit Rate                                                                          %                          76,30
    Mem Pipes Busy                                                                       %                          19,76
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          10,42
    Issued Warp Per Scheduler                                                                                        0,10
    No Eligible                                                                          %                          89,58
    Active Warps Per Scheduler                                                        warp                           5,62
    Eligible Warps Per Scheduler                                                      warp                           0,20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 9.6 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.62 active warps per scheduler, but only an average of 0.20 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,95
    Warp Cycles Per Executed Instruction                                             cycle                          57,99
    Warp Cycles Per Issue Active                                                      warp                          53,95
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 29.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 55.0% of the total average of 54.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         292,57
    Executed Instructions                                                             inst                         16.384
    Avg. Issued Instructions Per Scheduler                                            inst                         314,48
    Issued Instructions                                                               inst                         17.611
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 30.5%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          69,53
    Achieved Active Warps Per SM                                                      warp                          22,25
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725edc0                  
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725ede0                  

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:13, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,30
    SM Frequency                                                             cycle/nsecond                           1,19
    Elapsed Cycles                                                                   cycle                          4.441
    Memory [%]                                                                           %                          16,15
    SOL DRAM                                                                             %                          16,15
    Duration                                                                       usecond                           3,74
    SOL L1/TEX Cache                                                                     %                          15,74
    SOL L2 Cache                                                                         %                          10,71
    SM Active Cycles                                                                 cycle                       2.787,29
    SM [%]                                                                               %                           9,88
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,29
    Executed Ipc Elapsed                                                        inst/cycle                           0,18
    Issue Slots Busy                                                                     %                           7,79
    Issued Ipc Active                                                           inst/cycle                           0,31
    SM Busy                                                                              %                           7,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          26,86
    Mem Busy                                                                             %                          10,71
    Max Bandwidth                                                                        %                          16,15
    L1/TEX Hit Rate                                                                      %                          49,76
    L2 Hit Rate                                                                          %                          19,30
    Mem Pipes Busy                                                                       %                           9,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           8,03
    Issued Warp Per Scheduler                                                                                        0,08
    No Eligible                                                                          %                          91,97
    Active Warps Per Scheduler                                                        warp                           5,49
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 12.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.49 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          68,34
    Warp Cycles Per Executed Instruction                                             cycle                          73,78
    Warp Cycles Per Issue Active                                                      warp                          68,34
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 42.6 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 62.3% of the total average of 68.3   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         201,14
    Executed Instructions                                                             inst                         11.264
    Avg. Issued Instructions Per Scheduler                                            inst                         217,14
    Issued Instructions                                                               inst                         12.160
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                         512
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                         25.088
    Waves Per SM                                                                                                     2,29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 63 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 31.9%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid.                                                                                                       

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          68,10
    Achieved Active Warps Per SM                                                      warp                          21,79
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 3584 transactions, got 6656 (1.86x) at PC 0x7f58a725bc80                  

  execute3DconvolutionCuda(float*, float*, float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:13, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,40
    SM Frequency                                                             cycle/nsecond                           1,29
    Elapsed Cycles                                                                   cycle                      2.747.456
    Memory [%]                                                                           %                          21,92
    SOL DRAM                                                                             %                           1,22
    Duration                                                                       msecond                           2,12
    SOL L1/TEX Cache                                                                     %                          29,46
    SOL L2 Cache                                                                         %                           2,66
    SM Active Cycles                                                                 cycle                   2.551.361,43
    SM [%]                                                                               %                          65,69
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis report section to see     
          what the compute pipelines are spending their time doing. Also, consider whether any computation is           
          redundant and could be reduced or moved to look-up tables.                                                    

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 2% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           2,82
    Executed Ipc Elapsed                                                        inst/cycle                           2,63
    Issue Slots Busy                                                                     %                          70,60
    Issued Ipc Active                                                           inst/cycle                           2,82
    SM Busy                                                                              %                          70,60
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                           2,18
    Mem Busy                                                                             %                          14,73
    Max Bandwidth                                                                        %                          21,92
    L1/TEX Hit Rate                                                                      %                          96,89
    L2 Hit Rate                                                                          %                          87,44
    Mem Pipes Busy                                                                       %                          21,92
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          70,56
    Issued Warp Per Scheduler                                                                                        0,71
    No Eligible                                                                          %                          29,44
    Active Warps Per Scheduler                                                        warp                           7,92
    Eligible Warps Per Scheduler                                                      warp                           1,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,23
    Warp Cycles Per Executed Instruction                                             cycle                          11,23
    Warp Cycles Per Issue Active                                                      warp                          11,23
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.5 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      1.801.216
    Executed Instructions                                                             inst                    100.868.096
    Avg. Issued Instructions Per Scheduler                                            inst                   1.801.254,93
    Issued Instructions                                                               inst                    100.870.276
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             55
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             18
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          99,06
    Achieved Active Warps Per SM                                                      warp                          31,70
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 7340032 transactions, got 13631488 (1.86x) at PC 0x7f58a7265650           
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7265fa0                

  executeBnNormLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:14, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        170.714
    Memory [%]                                                                           %                           8,51
    SOL DRAM                                                                             %                           8,51
    Duration                                                                       usecond                         123,14
    SOL L1/TEX Cache                                                                     %                           3,54
    SOL L2 Cache                                                                         %                           3,89
    SM Active Cycles                                                                 cycle                     167.705,43
    SM [%]                                                                               %                          85,31
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Compute Workload Analysis section.                                        

    WRN   The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 41% of its fp64 peak performance. If Compute Workload  
          Analysis determines that this kernel is fp64 bound, consider using 32-bit precision floating point            
          operations to improve its performance.                                                                        

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,17
    Executed Ipc Elapsed                                                        inst/cycle                           0,17
    Issue Slots Busy                                                                     %                           4,25
    Issued Ipc Active                                                           inst/cycle                           0,17
    SM Busy                                                                              %                          86,74
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   FP64 is the highest-utilized pipeline (86.7%). It executes 64-bit floating point operations. The pipeline is  
          over-utilized and likely a performance bottleneck.                                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          16,23
    Mem Busy                                                                             %                           3,89
    Max Bandwidth                                                                        %                           8,51
    L1/TEX Hit Rate                                                                      %                          73,48
    L2 Hit Rate                                                                          %                          72,91
    Mem Pipes Busy                                                                       %                          22,21
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           4,27
    Issued Warp Per Scheduler                                                                                        0,04
    No Eligible                                                                          %                          95,73
    Active Warps Per Scheduler                                                        warp                           7,53
    Eligible Warps Per Scheduler                                                      warp                           0,08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 23.4 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          7.53 active warps per scheduler, but only an average of 0.08 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                         176,48
    Warp Cycles Per Executed Instruction                                             cycle                         177,04
    Warp Cycles Per Issue Active                                                      warp                         176,48
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        22,79
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 96.8 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 54.8% of the total average of 176.5  
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   On average each warp of this kernel spends 71.4 cycles being stalled waiting for the L1TEX instruction queue  
          to be not full. This represents about 40.4% of the total average of 176.5 cycles between issuing two          
          instructions. This stall reason is high in cases of extreme utilization of the L1TEX pipeline. If             
          applicable, consider combining multiple lower-width memory operations into fewer wider memory operations and  
          try interleaving memory operations and math instructions.                                                     
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 24.5 threads being active per cycle. This is further reduced    
          to 22.8 threads per warp due to predication. The compiler may use predication to avoid an actual branch.      
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       7.108,71
    Executed Instructions                                                             inst                        398.088
    Avg. Issued Instructions Per Scheduler                                            inst                       7.131,30
    Issued Instructions                                                               inst                        399.353
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             22
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             42
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          93,48
    Achieved Active Warps Per SM                                                      warp                          29,91
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a72623c0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a7262670                

  executeScaleLayerCUDA(float*, float*, float*, int, int), 2023-Mar-21 16:32:14, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,53
    SM Frequency                                                             cycle/nsecond                           1,24
    Elapsed Cycles                                                                   cycle                         11.194
    Memory [%]                                                                           %                          40,15
    SOL DRAM                                                                             %                          23,62
    Duration                                                                       usecond                           9,02
    SOL L1/TEX Cache                                                                     %                          39,10
    SOL L2 Cache                                                                         %                          40,15
    SM Active Cycles                                                                 cycle                       9.561,21
    SM [%]                                                                               %                          31,43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 1% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,49
    Executed Ipc Elapsed                                                        inst/cycle                           0,42
    Issue Slots Busy                                                                     %                          12,47
    Issued Ipc Active                                                           inst/cycle                           0,50
    SM Busy                                                                              %                          14,28
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          46,31
    Mem Busy                                                                             %                          40,15
    Max Bandwidth                                                                        %                          33,02
    L1/TEX Hit Rate                                                                      %                          72,43
    L2 Hit Rate                                                                          %                          65,18
    Mem Pipes Busy                                                                       %                          31,43
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          12,73
    Issued Warp Per Scheduler                                                                                        0,13
    No Eligible                                                                          %                          87,27
    Active Warps Per Scheduler                                                        warp                           5,43
    Eligible Warps Per Scheduler                                                      warp                           0,17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 7.9 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          5.43 active warps per scheduler, but only an average of 0.17 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          42,63
    Warp Cycles Per Executed Instruction                                             cycle                          43,43
    Warp Cycles Per Issue Active                                                      warp                          42,63
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 31.1 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 73.0% of the total average of 42.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.170,29
    Executed Instructions                                                             inst                         65.536
    Avg. Issued Instructions Per Scheduler                                            inst                       1.192,16
    Issued Instructions                                                               inst                         66.761
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          69,49
    Achieved Active Warps Per SM                                                      warp                          22,24
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725edc0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725ede0                

  executeEltWiseLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:32:14, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,29
    SM Frequency                                                             cycle/nsecond                           1,21
    Elapsed Cycles                                                                   cycle                         12.274
    Memory [%]                                                                           %                          48,07
    SOL DRAM                                                                             %                          48,07
    Duration                                                                       usecond                          10,11
    SOL L1/TEX Cache                                                                     %                          34,33
    SOL L2 Cache                                                                         %                          47,54
    SM Active Cycles                                                                 cycle                       9.821,21
    SM [%]                                                                               %                          23,88
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,45
    Executed Ipc Elapsed                                                        inst/cycle                           0,36
    Issue Slots Busy                                                                     %                          11,31
    Issued Ipc Active                                                           inst/cycle                           0,45
    SM Busy                                                                              %                          11,92
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          79,44
    Mem Busy                                                                             %                          47,54
    Max Bandwidth                                                                        %                          48,07
    L1/TEX Hit Rate                                                                      %                             65
    L2 Hit Rate                                                                          %                          46,94
    Mem Pipes Busy                                                                       %                          23,88
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,38
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,62
    Active Warps Per Scheduler                                                        warp                           4,84
    Eligible Warps Per Scheduler                                                      warp                           0,11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.7 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.84 active warps per scheduler, but only an average of 0.11 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          51,60
    Warp Cycles Per Executed Instruction                                             cycle                          52,26
    Warp Cycles Per Issue Active                                                      warp                          51,60
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 36.0 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 69.8% of the total average of 51.6   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                       1.097,14
    Executed Instructions                                                             inst                         61.440
    Avg. Issued Instructions Per Scheduler                                            inst                       1.111,02
    Issued Instructions                                                               inst                         62.217
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          70,68
    Achieved Active Warps Per SM                                                      warp                          22,62
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d490                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d4a0                
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725d4d0                

  executeReLULayerCUDA(float*, int), 2023-Mar-21 16:32:14, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,41
    SM Frequency                                                             cycle/nsecond                           1,26
    Elapsed Cycles                                                                   cycle                         11.067
    Memory [%]                                                                           %                          25,53
    SOL DRAM                                                                             %                          25,53
    Duration                                                                       usecond                           8,74
    SOL L1/TEX Cache                                                                     %                          18,95
    SOL L2 Cache                                                                         %                          17,08
    SM Active Cycles                                                                 cycle                       9.326,64
    SM [%]                                                                               %                          15,89
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved 0% of 
          this device's fp32 peak performance and 0% of its fp64 peak performance.                                      

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,35
    Executed Ipc Elapsed                                                        inst/cycle                           0,29
    Issue Slots Busy                                                                     %                           8,77
    Issued Ipc Active                                                           inst/cycle                           0,35
    SM Busy                                                                              %                           8,77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   All pipelines are under-utilized. Either this kernel is very small or it doesn't issue enough warps per       
          scheduler. Check the Launch Statistics and Scheduler Statistics sections for further details.                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          45,97
    Mem Busy                                                                             %                          17,08
    Max Bandwidth                                                                        %                          25,53
    L1/TEX Hit Rate                                                                      %                          47,21
    L2 Hit Rate                                                                          %                          19,36
    Mem Pipes Busy                                                                       %                          15,89
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                           9,16
    Issued Warp Per Scheduler                                                                                        0,09
    No Eligible                                                                          %                          90,84
    Active Warps Per Scheduler                                                        warp                           4,86
    Eligible Warps Per Scheduler                                                      warp                           0,10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 10.9 cycles. This might leave hardware resources underutilized and may lead to    
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          4.86 active warps per scheduler, but only an average of 0.10 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          53,00
    Warp Cycles Per Executed Instruction                                             cycle                          53,90
    Warp Cycles Per Issue Active                                                      warp                          53,00
    Avg. Active Threads Per Warp                                                                                    24,50
    Avg. Not Predicated Off Threads Per Warp                                                                        24,50
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 43.3 cycles being stalled waiting for a scoreboard dependency on a 
          L1TEX (local, global, surface, texture) operation. This represents about 81.8% of the total average of 53.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                         804,57
    Executed Instructions                                                             inst                         45.056
    Avg. Issued Instructions Per Scheduler                                            inst                         818,32
    Issued Instructions                                                               inst                         45.826
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         49
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        100.352
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 49     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             64
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             16
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          64,18
    Achieved Active Warps Per SM                                                      warp                          20,54
    ---------------------------------------------------------------------- --------------- ------------------------------

    WRN   Uncoalesced global access, expected 14336 transactions, got 26624 (1.86x) at PC 0x7f58a725bc80                

  poolingAverageCUDA(float*, float*, int, int, int, int, int, int, int, int), 2023-Mar-21 16:32:15, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,48
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                         55.543
    Memory [%]                                                                           %                          26,40
    SOL DRAM                                                                             %                           5,94
    Duration                                                                       usecond                          40,16
    SOL L1/TEX Cache                                                                     %                          28,21
    SOL L2 Cache                                                                         %                          10,76
    SM Active Cycles                                                                 cycle                      51.864,14
    SM [%]                                                                               %                          28,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           1,24
    Executed Ipc Elapsed                                                        inst/cycle                           1,16
    Issue Slots Busy                                                                     %                          30,93
    Issued Ipc Active                                                           inst/cycle                           1,24
    SM Busy                                                                              %                          30,93
    ---------------------------------------------------------------------- --------------- ------------------------------
          No pipeline is over-utilized.                                                                                 

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          11,25
    Mem Busy                                                                             %                          13,21
    Max Bandwidth                                                                        %                          26,40
    L1/TEX Hit Rate                                                                      %                          85,47
    L2 Hit Rate                                                                          %                          61,12
    Mem Pipes Busy                                                                       %                          26,40
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          31,45
    Issued Warp Per Scheduler                                                                                        0,31
    No Eligible                                                                          %                          68,55
    Active Warps Per Scheduler                                                        warp                           3,76
    Eligible Warps Per Scheduler                                                      warp                           0,39
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 3.2 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          3.76 active warps per scheduler, but only an average of 0.39 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          11,96
    Warp Cycles Per Executed Instruction                                             cycle                          11,98
    Warp Cycles Per Issue Active                                                      warp                          11,96
    Avg. Active Threads Per Warp                                                                                        1
    Avg. Not Predicated Off Threads Per Warp                                                                         0,91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 6.1 cycles being stalled waiting for a scoreboard dependency on a  
          L1TEX (local, global, surface, texture) operation. This represents about 51.2% of the total average of 12.0   
          cycles between issuing two instructions. To reduce the number of cycles waiting on L1TEX data accesses        
          verify the memory access patterns are optimal for the target architecture, attempt to increase cache hit      
          rates by increasing data locality or by changing the cache configuration, and consider moving frequently      
          used data to shared memory.                                                                                   
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 1.0 threads being active per cycle. This is further reduced to  
          0.9 threads per warp due to predication. The compiler may use predication to avoid an actual branch.          
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                      16.018,29
    Executed Instructions                                                             inst                        897.024
    Avg. Issued Instructions Per Scheduler                                            inst                      16.041,54
    Issued Instructions                                                               inst                        898.326
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                          1
    Grid Size                                                                                                       2.048
    Registers Per Thread                                                   register/thread                             44
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          2.048
    Waves Per SM                                                                                                     9,14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             40
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             32
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          46,54
    Achieved Active Warps Per SM                                                      warp                          14,89
    ---------------------------------------------------------------------- --------------- ------------------------------

  executeFCLayerCUDA(float*, float*, float*, int), 2023-Mar-21 16:32:15, Context 1, Stream 7
    Section: GPU Speed Of Light
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1,49
    SM Frequency                                                             cycle/nsecond                           1,38
    Elapsed Cycles                                                                   cycle                        762.884
    Memory [%]                                                                           %                          76,95
    SOL DRAM                                                                             %                           7,83
    Duration                                                                       usecond                         551,01
    SOL L1/TEX Cache                                                                     %                          77,86
    SOL L2 Cache                                                                         %                           5,14
    SM Active Cycles                                                                 cycle                     751.686,07
    SM [%]                                                                               %                          76,95
    ---------------------------------------------------------------------- --------------- ------------------------------
    OK    Compute and Memory are well-balanced: To reduce runtime, both computation and memory traffic must be reduced. 
          Check both the Compute Workload Analysis and Memory Workload Analysis report sections.                        

    OK    The ratio of peak float (fp32) to double (fp64) performance on this device is 32:1. The kernel achieved       
          close to 0% of this device's fp32 peak performance and 0% of its fp64 peak performance.                       

    Section: Compute Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Executed Ipc Active                                                         inst/cycle                           0,67
    Executed Ipc Elapsed                                                        inst/cycle                           0,66
    Issue Slots Busy                                                                     %                          16,80
    Issued Ipc Active                                                           inst/cycle                           0,67
    SM Busy                                                                              %                          25,96
    ---------------------------------------------------------------------- --------------- ------------------------------
          LSU is the highest-utilized pipeline (77.9%). It executes load/store memory operations. The pipeline is       
          well-utilized and might become a bottleneck if more work is added.                                            

    Section: Memory Workload Analysis
    ---------------------------------------------------------------------- --------------- ------------------------------
    Memory Throughput                                                         Gbyte/second                          14,92
    Mem Busy                                                                             %                          38,47
    Max Bandwidth                                                                        %                          76,95
    L1/TEX Hit Rate                                                                      %                          93,47
    L2 Hit Rate                                                                          %                          94,41
    Mem Pipes Busy                                                                       %                          76,95
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Scheduler Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Instructions Per Active Issue Slot                                          inst/cycle                              1
    One or More Eligible                                                                 %                          16,90
    Issued Warp Per Scheduler                                                                                        0,17
    No Eligible                                                                          %                          83,10
    Active Warps Per Scheduler                                                        warp                           3,76
    Eligible Warps Per Scheduler                                                      warp                           0,35
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Every scheduler is capable of issuing one instruction per cycle, but for this kernel each scheduler only      
          issues an instruction every 5.9 cycles. This might leave hardware resources underutilized and may lead to     
          less optimal performance. Out of the maximum of 8 warps per scheduler, this kernel allocates an average of    
          3.76 active warps per scheduler, but only an average of 0.35 warps were eligible per cycle. Eligible warps    
          are the subset of active warps that are ready to issue their next instruction. Every cycle with no eligible   
          warp results in no instruction being issued and the issue slot remains unused. To increase the number of      
          eligible warps either increase the number of active warps or reduce the time the active warps are stalled.    

    Section: Warp State Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Warp Cycles Per Issued Instruction                                               cycle                          22,22
    Warp Cycles Per Executed Instruction                                             cycle                          22,22
    Warp Cycles Per Issue Active                                                      warp                          22,22
    Avg. Active Threads Per Warp                                                                                        1
    Avg. Not Predicated Off Threads Per Warp                                                                         1,00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   On average each warp of this kernel spends 11.8 cycles being stalled waiting for the local/global instruction 
          queue to be not full. This represents about 53.0% of the total average of 22.2 cycles between issuing two     
          instructions. Typically this stall occurs only when executing local or global memory instructions extremely   
          frequently. If applicable, consider combining multiple lower-width memory operations into fewer wider memory  
          operations and try interleaving memory operations and math instructions.                                      
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   Instructions are executed in warps, which are groups of 32 threads. Optimal instruction throughput is         
          achieved if all 32 threads of a warp execute the same instruction. The chosen launch configuration, early     
          thread completion, and divergent flow control can significantly lower the number of active threads in a warp  
          per cycle. This kernel achieves an average of 1.0 threads being active per cycle. This is further reduced to  
          1.0 threads per warp due to predication. The compiler may use predication to avoid an actual branch.          
          Instead, all instructions are scheduled, but a per-thread condition code or predicate controls which threads  
          execute the instructions. Try to avoid different execution paths within a warp when possible. In addition,    
          ensure your kernel makes use of Independent Thread Scheduling, which allows a warp to reconverge after a      
          data-dependent conditional block by explicitly calling __syncwarp().                                          

    Section: Instruction Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Avg. Executed Instructions Per Scheduler                                          inst                     126.267,86
    Executed Instructions                                                             inst                      7.071.000
    Avg. Issued Instructions Per Scheduler                                            inst                     126.277,68
    Issued Instructions                                                               inst                      7.071.550
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                          1
    Grid Size                                                                                                       1.000
    Registers Per Thread                                                   register/thread                             43
    Shared Memory Configuration Size                                                 Kbyte                          32,77
    Driver Shared Memory Per Block                                              byte/block                              0
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          1.000
    Waves Per SM                                                                                                     4,46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 1      
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance. This is particularly beneficial to      
          kernels that frequently call __syncthreads().                                                                 

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             16
    Block Limit Registers                                                            block                             40
    Block Limit Shared Mem                                                           block                             16
    Block Limit Warps                                                                block                             32
    Theoretical Active Warps per SM                                                   warp                             16
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                          46,69
    Achieved Active Warps Per SM                                                      warp                          14,94
    ---------------------------------------------------------------------- --------------- ------------------------------

